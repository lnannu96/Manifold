{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypersurface_tf import *\n",
    "from generate_h import *\n",
    "from biholoNN import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0, z1, z2, z3, z4 = sp.symbols('z0, z1, z2, z3, z4')\n",
    "Z = [z0,z1,z2,z3,z4]\n",
    "f = z0**5 + z1**5 + z2**5 + z3**5 + z4**5 + 0.5*z0*z1*z2*z3*z4\n",
    "np.random.seed(123)\n",
    "HS = Hypersurface(Z, f, 10000)\n",
    "np.random.seed(124)\n",
    "HS_test = Hypersurface(Z, f, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a0145620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a1858048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a1842e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a18b9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a18b99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a00e6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a00e6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a18b9d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a0187b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a00d5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83a01872f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380401400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380407400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83804078c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380371bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83803b3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838037a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838037ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380368c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83802e7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838032b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838028ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380285ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380259ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838026c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838026c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380203730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380255d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83801b2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83801b2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83801948c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83801696a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f838016e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8380125400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83800e7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83800e7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "train_set = generate_dataset(HS)\n",
    "test_set = generate_dataset(HS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.shuffle(500000).batch(1000)\n",
    "test_set = test_set.shuffle(50000).batch(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KahlerPotential(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KahlerPotential, self).__init__()\n",
    "        self.biholomorphic = Biholomorphic()\n",
    "        #self.layer1 = WidthOneDense()\n",
    "        #self.layer1 = Dense(25, 1, activation=None)\n",
    "        self.layer1 = Dense(25,500, activation=tf.square)\n",
    "        self.layer2 = Dense(500,500, activation=tf.square)\n",
    "        #self.layer3 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        #self.layer4 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        #self.layer5 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        #self.g = ComplexG(70)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.biholomorphic(inputs)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        #x = self.layer3(x)\n",
    "        #x = self.layer4(x)\n",
    "        #x = self.layer5(x)\n",
    "        #x = self.g(x)\n",
    "        #x = tf.linalg.diag_part(tf.matmul(x, x, adjoint_b=True))\n",
    "        #x = tf.math.log(x)\n",
    "        x = tf.reduce_sum(x, 1)\n",
    "        x = tf.math.log(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KahlerPotential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def volume_form(x, Omega_Omegabar, mass, restriction):\n",
    "\n",
    "    kahler_metric = complex_hessian(tf.math.real(model(x)), x)\n",
    "    volume_form = tf.math.real(tf.linalg.det(tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True))))\n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
    "    #factor = tf.constant(35.1774, dtype=tf.complex64)\n",
    "    return volume_form / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.3250\n",
      "test_loss: 0.050744288\n",
      "step 0: loss = 0.0524\n",
      "test_loss: 0.03756032\n",
      "step 0: loss = 0.0365\n",
      "test_loss: 0.031715397\n",
      "step 0: loss = 0.0307\n",
      "test_loss: 0.027932554\n",
      "step 0: loss = 0.0262\n",
      "test_loss: 0.026691275\n",
      "step 0: loss = 0.0267\n",
      "test_loss: 0.024220778\n",
      "step 0: loss = 0.0236\n",
      "test_loss: 0.023064254\n",
      "step 0: loss = 0.0225\n",
      "test_loss: 0.02187635\n",
      "step 0: loss = 0.0223\n",
      "test_loss: 0.02144316\n",
      "step 0: loss = 0.0213\n",
      "test_loss: 0.02050266\n",
      "step 0: loss = 0.0202\n",
      "test_loss: 0.019202689\n",
      "step 0: loss = 0.0183\n",
      "test_loss: 0.019057862\n",
      "step 0: loss = 0.0178\n",
      "test_loss: 0.018288774\n",
      "step 0: loss = 0.0182\n",
      "test_loss: 0.018188179\n",
      "step 0: loss = 0.0184\n",
      "test_loss: 0.018325953\n",
      "step 0: loss = 0.0182\n",
      "test_loss: 0.016554203\n",
      "step 0: loss = 0.0156\n",
      "test_loss: 0.016850324\n",
      "step 0: loss = 0.0160\n",
      "test_loss: 0.016012104\n",
      "step 0: loss = 0.0152\n",
      "test_loss: 0.015910357\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.015737806\n",
      "step 0: loss = 0.0140\n",
      "test_loss: 0.015022068\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.015779754\n",
      "step 0: loss = 0.0148\n",
      "test_loss: 0.0154933985\n",
      "step 0: loss = 0.0153\n",
      "test_loss: 0.015235739\n",
      "step 0: loss = 0.0137\n",
      "test_loss: 0.014662683\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.014255246\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.014595227\n",
      "step 0: loss = 0.0137\n",
      "test_loss: 0.015388734\n",
      "step 0: loss = 0.0151\n",
      "test_loss: 0.015486915\n",
      "step 0: loss = 0.0146\n",
      "test_loss: 0.015297586\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.014180581\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.0140506225\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.014675875\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.01532632\n",
      "step 0: loss = 0.0144\n",
      "test_loss: 0.014111603\n",
      "step 0: loss = 0.0141\n",
      "test_loss: 0.013462865\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.014200878\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.014072197\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.013003896\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.013559929\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.0130886175\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013022358\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.012666038\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013092754\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013528408\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.012660069\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.0137336925\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.013407831\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.012604767\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.012533832\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012580866\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012769389\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.012150381\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012083945\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012204673\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.011931006\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.0124243125\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012045719\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012196082\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012516472\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.011932011\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012031176\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.011651386\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.011368865\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01114558\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012091329\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.0114550805\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.012026762\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012173258\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011259957\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011749941\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.011912459\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.010998218\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010965334\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011281275\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.010897734\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011281771\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011268173\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.010976227\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011700244\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01106377\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011522807\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011011812\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011592715\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.0109255435\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011007135\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011059542\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011091905\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.010475537\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011135651\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.010484799\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010752674\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011387504\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.010740204\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.0110075595\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010679714\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.010301729\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010655652\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010591558\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010891821\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.0105643105\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010559683\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.010995588\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.010233203\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010649762\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010982395\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010108504\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011246171\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.0102260625\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010193327\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010125426\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010335428\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010347481\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010760276\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.010635828\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010503217\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.010101828\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010678792\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010198168\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.011708014\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.010141399\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010473767\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010655159\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010339067\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011084491\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010103706\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010096016\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010297259\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.010792308\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.010418456\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009775649\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.009905072\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010035729\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010028899\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010005943\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010502319\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010399051\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.009798786\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009868616\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010231162\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010387429\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.009872885\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.010018053\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.0097045\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010155916\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010124353\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.0103303455\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01073938\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.009739674\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.0100501655\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010462698\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009858485\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010225145\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010122545\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.009718795\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009859768\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.00987297\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009932478\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.009732206\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.01041937\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.009710931\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009630075\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010112766\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009876864\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009980184\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.0096839275\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009367825\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009866017\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009892116\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.009682055\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.009901634\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.0098124035\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009744189\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009501888\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009350961\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009405907\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009741335\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.009879663\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.0096405065\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.01019082\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009743019\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009621295\n",
      "step 0: loss = 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.010153398\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009432168\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009629483\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009806812\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010067311\n",
      "step 0: loss = 0.0097\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "epochs = 6000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(train_set):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "            loss = weighted_MAPE(Omega_Omegabar, omega, mass)  \n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "            #print(model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            print(\"step %d: loss = %.4f\" % (step, loss))\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_loss_old = 100\n",
    "    total_mass = 0\n",
    "    \n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(test_set):\n",
    "        omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "        mass_sum = tf.reduce_sum(mass)\n",
    "        test_loss += weighted_MAPE(Omega_Omegabar, omega, mass) * mass_sum\n",
    "        total_mass += mass_sum\n",
    "   \n",
    "    test_loss = test_loss / total_mass\n",
    "    print(\"test_loss:\", test_loss.numpy())\n",
    "    \n",
    "    # This part doesn't work right now\n",
    "    #if test_loss > test_loss_old:\n",
    "    #    break\n",
    "    #test_loss_old = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some debugging tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.functionoptimizer.apply_gradients(zip(grads, vars)\n",
    "def volume_form(x, Omega_Omegabar, mass, restriction):\n",
    "\n",
    "    kahler_metric = complex_hessian(tf.math.real(model(x)), x)\n",
    "    volume_form = tf.linalg.det(tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True)))\n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
    "    #factor = tf.constant(4.380538, dtype=tf.complex64)\n",
    "    return  volume_form/factor\n",
    "    #return factor\n",
    "for step, (points, Omega_Omegabar, mass, restriction) in enumerate(dataset):\n",
    "    omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "    \n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    print('omega', omega)\n",
    "    print('OO',Omega_Omegabar)\n",
    "    print(tf.cast(tf.abs(Omega_Omegabar -  omega), dtype=tf.complex64) / Omega_Omegabar)\n",
    "   # print(mass/tf.reduce_sum(mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 15) dtype=complex64, numpy=\n",
      "array([[ 2.2768168e+00+1.6352530e+00j,  5.8658237e+00-4.2718673e-01j,\n",
      "         5.3873414e-01-1.7244281e-01j, -3.9534414e-01+7.2521999e-02j,\n",
      "        -1.8923687e-02+1.1802919e-02j, -3.8347977e-01-2.2627316e-01j,\n",
      "        -7.6662725e-01+8.0790210e-01j,  2.6793966e-01+6.7697294e-02j,\n",
      "        -4.4106621e-01-1.5242220e-01j, -1.6198709e+00-5.7326740e-01j,\n",
      "         2.8095651e+00+8.1460869e-01j, -1.1343197e+00-2.5883400e+00j,\n",
      "        -4.6649609e+00+1.1073344e+00j,  1.7060937e-01-2.2714563e-02j,\n",
      "         8.5827917e-01-7.9530555e-01j],\n",
      "       [ 1.9180773e+00+4.4432992e-01j, -1.7982172e+00+1.0105304e+00j,\n",
      "        -6.0589733e+00-8.5629034e-01j,  2.9838247e+00-3.7910095e-01j,\n",
      "         2.8432586e+00+9.5829725e-01j, -4.8352519e-01-4.6606249e-01j,\n",
      "        -1.7036586e+00-9.6777737e-01j, -3.2158126e-03+1.6477600e-03j,\n",
      "         1.7850419e+00+6.1775154e-01j,  4.3784446e-01-8.8729739e-02j,\n",
      "         2.8238079e-01+1.9228293e-01j, -2.9208440e-01+1.6115788e-01j,\n",
      "        -2.7304552e+00+1.0982864e+00j, -1.3929390e+00+3.4327587e-01j,\n",
      "        -3.5853200e+00-1.3666987e-01j],\n",
      "       [-1.4581397e+00+1.9110115e+00j, -1.7909920e-01+3.6252013e-01j,\n",
      "        -1.1931094e+00+3.0919951e-01j,  7.2101420e-01-1.2520562e+00j,\n",
      "        -5.5755311e-01-2.0128660e-02j,  3.1300583e+00-2.7365923e-01j,\n",
      "         4.9949604e-01-5.2422490e+00j, -1.7338538e-01+2.4592508e-02j,\n",
      "         1.9228923e+00-6.3471007e-01j,  3.0070311e-01+5.4850805e-01j,\n",
      "         1.8207195e+00-1.2229290e+00j, -4.6268797e+00-1.4987248e+00j,\n",
      "         1.1876729e+00+3.0295810e-01j, -7.5662631e-01+1.2398404e-01j,\n",
      "         3.7306695e+00+1.6974617e+00j],\n",
      "       [ 1.5903249e-01-2.4123290e-01j,  4.2902447e-02+8.1711315e-02j,\n",
      "        -3.3539832e-01+3.9116329e-01j, -2.4176884e+00+1.5029418e-02j,\n",
      "        -4.5817409e+00+8.9052248e-01j, -4.5735011e+00+3.7343332e-01j,\n",
      "         2.3762546e-02-4.5621830e-01j, -1.9385403e-01+8.9566067e-02j,\n",
      "         4.0899768e+00-1.5305756e-02j, -2.5236410e-01+9.8926350e-02j,\n",
      "        -2.1313027e-01-2.0266116e-02j,  2.7595261e-02+4.9135927e-03j,\n",
      "         4.4409629e-02+1.6594049e-01j, -5.0119634e+00+7.1290761e-02j,\n",
      "        -3.5859435e-03+2.7132857e-01j],\n",
      "       [ 2.8225083e+00-1.9472898e+00j, -1.9300312e-01+1.2453795e-01j,\n",
      "        -7.0934814e-01-1.3123615e-01j, -3.2763820e+00+1.2321837e+00j,\n",
      "         1.0924923e+00-7.1551239e-01j,  6.0893261e-01+3.7527627e-01j,\n",
      "         1.0850860e+00-8.6598074e-01j,  4.2221852e-02+8.6574353e-02j,\n",
      "        -2.4428689e+00-5.7877851e-01j,  5.8101020e+00-3.2419884e-01j,\n",
      "         4.1471138e+00+9.2794955e-02j,  1.2292573e+00+7.8488910e-01j,\n",
      "        -1.2955481e-01-9.0879291e-01j, -2.4329317e+00-7.5963151e-01j,\n",
      "         8.8978034e-01+5.8874261e-01j]], dtype=complex64)>\n",
      "<tf.Variable 'Variable:0' shape=(15, 15) dtype=complex64, numpy=\n",
      "array([[ 4.48537874e+00-5.30717336e-02j,  3.97880413e-02-8.86093974e-02j,\n",
      "        -5.31146526e-02+2.45492142e-02j,  8.67075175e-02-1.01624019e-01j,\n",
      "        -1.85670733e-01-6.91963136e-02j, -1.48487300e-01-6.05651662e-02j,\n",
      "         1.20190650e-01-1.69870649e-02j, -5.21362424e-02+1.12177646e-02j,\n",
      "        -9.27942619e-03-8.68658349e-02j,  1.54285967e-01-1.91998314e-02j,\n",
      "         5.47923846e-03+3.80867757e-02j,  3.08177918e-01+2.94221759e-01j,\n",
      "        -1.75426140e-01+1.19707145e-01j, -1.02277972e-01-1.52171299e-01j,\n",
      "        -1.69872731e-01-1.57393202e-01j],\n",
      "       [-5.20558469e-02+1.35510653e-01j,  4.76845026e+00-1.03557847e-01j,\n",
      "        -3.10402393e-01-2.63872325e-01j, -3.83945145e-02-8.85578468e-02j,\n",
      "        -6.10975474e-02-5.13151139e-02j,  3.30757163e-02-6.16653822e-02j,\n",
      "        -6.88735908e-03+3.06749791e-01j,  5.53110726e-02+3.24442722e-02j,\n",
      "         5.61661236e-02-9.50987190e-02j,  3.09128780e-02-1.52821139e-01j,\n",
      "        -5.20106591e-02-6.28411546e-02j,  7.88327605e-02+3.26288608e-03j,\n",
      "         2.27459460e-01+5.63018508e-02j,  8.88381824e-02-2.21358798e-02j,\n",
      "        -2.27249622e-01-5.98294660e-02j],\n",
      "       [-8.53944421e-02-1.59421653e-01j, -4.13616151e-01+3.89929742e-01j,\n",
      "         4.94551754e+00+4.43636924e-02j,  1.50215358e-01+4.44892310e-02j,\n",
      "        -1.41069680e-01+1.37919381e-01j,  4.76978607e-02+3.27756219e-02j,\n",
      "         3.87099892e-01-3.87359917e-01j,  2.56092846e-03+2.12033968e-02j,\n",
      "        -3.92926149e-02-7.29754344e-02j, -1.58888400e-01+7.86960423e-02j,\n",
      "        -1.02544896e-01+3.43110152e-02j, -1.23513997e-01+1.75399467e-01j,\n",
      "         8.80063027e-02+7.74727017e-02j, -4.35849488e-01-7.28005618e-02j,\n",
      "         2.04764962e-01+3.01671684e-01j],\n",
      "       [ 1.15745574e-01+1.57252774e-01j, -1.34361401e-01+5.97085431e-03j,\n",
      "        -1.57307282e-01-2.38582008e-02j,  4.51907349e+00+9.55896154e-02j,\n",
      "        -2.30961278e-01-1.77684844e-01j, -4.40963022e-02+1.08772136e-01j,\n",
      "         1.72351792e-01-3.85349840e-01j,  1.27901202e-02-2.35390174e-03j,\n",
      "         4.82990772e-01-4.60580401e-02j, -7.62113333e-02+4.24391218e-02j,\n",
      "         4.44995686e-02+1.28467217e-01j,  4.94761541e-02-1.91863418e-01j,\n",
      "        -6.11173883e-02+1.82351992e-01j, -1.56536192e-01-3.34206402e-01j,\n",
      "        -2.64782637e-01+9.08263773e-02j],\n",
      "       [-3.49517226e-01+4.60335091e-02j,  1.31304011e-01+1.01816170e-02j,\n",
      "        -3.40697199e-01-1.68635607e-01j, -5.71821369e-02+1.61503091e-01j,\n",
      "         4.63839626e+00+1.15938382e-02j,  6.46486878e-02-9.14678499e-02j,\n",
      "        -3.66927534e-02+1.30854309e-01j,  3.99125144e-02-9.48923826e-03j,\n",
      "         1.12672292e-01-1.14765264e-01j, -1.40039295e-01-4.60513979e-02j,\n",
      "         1.43637145e-02-1.35932982e-01j, -1.13129027e-01-5.67088183e-03j,\n",
      "        -5.44985309e-02-1.37464151e-01j,  2.69388884e-01-2.30145697e-02j,\n",
      "        -5.95672801e-02+1.25840053e-01j],\n",
      "       [-4.16479334e-02+4.21791933e-02j,  2.05890760e-02+2.97590904e-02j,\n",
      "         1.83426924e-02+1.32056922e-01j, -1.38517901e-01+1.10309437e-01j,\n",
      "         6.92991614e-02+5.72190918e-02j,  4.63341808e+00-9.73349288e-02j,\n",
      "         2.43234590e-01+1.41646847e-01j,  7.56485062e-03-4.06649448e-02j,\n",
      "         2.42830552e-02-5.73686250e-02j, -8.83598477e-02-5.31893317e-03j,\n",
      "        -1.07734889e-01+3.14638652e-02j, -1.21181324e-01-1.96566097e-02j,\n",
      "        -4.81016561e-02+2.78094318e-04j,  1.52766019e-01+1.74600426e-02j,\n",
      "        -3.01439971e-01-3.85408252e-02j],\n",
      "       [ 3.00037742e-01-6.98629916e-02j, -4.49373275e-02-1.61733106e-01j,\n",
      "         2.56243914e-01+6.09023511e-01j,  1.36562020e-01+2.60854691e-01j,\n",
      "        -2.74651754e-03-1.08257674e-01j,  1.03100389e-01-2.59782612e-01j,\n",
      "         4.71440935e+00+3.64487455e-03j,  3.80301401e-02-3.25144790e-02j,\n",
      "         9.35852975e-02+5.02375886e-02j,  2.00922623e-01-1.79778919e-01j,\n",
      "        -1.75713956e-01-1.36633992e-01j, -2.38222659e-01-1.92321986e-01j,\n",
      "        -1.23847418e-01-2.11267114e-01j,  3.34210247e-01-1.15863480e-01j,\n",
      "         2.37649888e-01-4.49349672e-01j],\n",
      "       [-1.66156478e-02-7.40435254e-03j,  4.84454557e-02-4.18997854e-02j,\n",
      "        -2.20417902e-02-1.80865303e-02j,  2.84999199e-02+1.54592039e-03j,\n",
      "         1.95790012e-03+9.60797537e-03j, -1.78892480e-03+2.34980136e-02j,\n",
      "         5.60312420e-02+6.79078884e-03j,  1.02035797e+00-1.41587004e-03j,\n",
      "         5.71653470e-02+1.35919440e-03j, -4.11586696e-03+1.70466807e-02j,\n",
      "        -1.22735696e-02+5.34778112e-04j,  2.58589257e-03-8.94873589e-03j,\n",
      "         3.30339633e-02-1.97864827e-02j, -9.78538394e-03+3.22149433e-02j,\n",
      "        -3.68325524e-02+5.54051772e-02j],\n",
      "       [-2.33105617e-04+1.45302713e-01j, -1.40367433e-01-7.84626901e-02j,\n",
      "        -2.98394740e-01+2.03740776e-01j,  4.79328364e-01+1.82237089e-01j,\n",
      "         8.17002635e-03+2.04623297e-01j,  3.38333040e-01+8.51498097e-02j,\n",
      "         1.94009811e-01-3.49350661e-01j,  1.14320517e-01-2.17770189e-02j,\n",
      "         4.51932383e+00+1.78256646e-01j,  1.14981748e-01+1.48429707e-01j,\n",
      "         5.64091764e-02-1.75696075e-01j, -3.98885965e-01-1.18323140e-01j,\n",
      "         3.33802626e-02-4.43213582e-02j,  6.17789589e-02+1.38245270e-01j,\n",
      "         2.13064000e-01+1.79522529e-01j],\n",
      "       [-7.09886604e-04-1.26861371e-02j, -2.62292355e-01+2.72542089e-01j,\n",
      "        -5.57135046e-02+1.39568806e-01j, -4.03439905e-03+4.15739752e-02j,\n",
      "        -2.80338436e-01+3.21313441e-02j, -1.63199157e-01-8.84823427e-02j,\n",
      "         2.22131297e-01+8.47790092e-02j, -4.71316651e-02-2.76802052e-02j,\n",
      "        -2.04155609e-01-9.45463106e-02j,  4.82785606e+00-9.14236009e-02j,\n",
      "        -6.13764375e-02-3.94683145e-02j,  3.66575152e-01-3.63307834e-01j,\n",
      "         1.35576446e-02+3.57938886e-01j, -2.09227741e-01-5.84533885e-02j,\n",
      "         9.33421105e-02-2.38120303e-01j],\n",
      "       [-4.62606281e-01-2.92114038e-02j, -1.05735824e-01-3.64217255e-03j,\n",
      "        -2.66819566e-01-5.29242568e-02j,  8.31092298e-02+5.24944253e-03j,\n",
      "        -1.63037237e-02+1.26137689e-01j,  5.59939817e-03-1.25258237e-01j,\n",
      "         1.06825724e-01+2.39404127e-01j, -1.50322216e-02-3.76014039e-03j,\n",
      "         7.54148513e-02+2.03093141e-02j,  2.86383659e-01-2.77430087e-01j,\n",
      "         4.48912239e+00-4.42797877e-03j,  4.68228877e-01+1.18662231e-02j,\n",
      "        -1.73990220e-01+1.60518482e-01j, -2.17481717e-01-1.80866912e-01j,\n",
      "        -9.43631157e-02-3.28368872e-01j],\n",
      "       [ 1.39473125e-01-3.72130185e-01j,  5.04988022e-02-1.66483656e-01j,\n",
      "        -4.57128733e-02-1.31300867e-01j,  2.80909566e-03+1.68979898e-01j,\n",
      "         8.12469050e-02+2.91961357e-02j, -4.57474701e-02-3.06981169e-02j,\n",
      "         3.91981453e-02-1.05741225e-01j,  2.10939124e-02-2.54678586e-03j,\n",
      "         6.12901598e-02+2.84539282e-01j,  1.91698879e-01+2.75423944e-01j,\n",
      "        -5.37234508e-02+4.94065508e-02j,  4.68861437e+00-6.97277561e-02j,\n",
      "         1.88950926e-01-3.14086676e-01j, -2.56929696e-02-9.12510138e-03j,\n",
      "        -7.24915490e-02+2.37303257e-01j],\n",
      "       [-5.19249380e-01-8.25218931e-02j,  4.53692585e-01-6.55159131e-02j,\n",
      "         1.70892984e-01-2.90004879e-01j,  1.45027399e-01-1.58730075e-01j,\n",
      "        -1.79294348e-01+1.14760011e-01j, -3.70380431e-02-7.66561106e-02j,\n",
      "        -1.95335552e-01+1.75296322e-01j,  9.01950300e-02+2.10906975e-02j,\n",
      "         9.28890929e-02+1.45167699e-02j,  3.77069503e-01-2.98564043e-02j,\n",
      "         7.31683522e-02+8.59315693e-02j,  1.53700531e-01+3.36694151e-01j,\n",
      "         4.57327032e+00+1.19299643e-01j, -1.22024298e-01+1.21267781e-01j,\n",
      "         8.43100473e-02-1.91762120e-01j],\n",
      "       [-5.13286963e-02+1.19752854e-01j, -4.29707654e-02-1.45511866e-01j,\n",
      "        -4.25873190e-01+3.33982483e-02j, -5.83635420e-02+2.12984264e-01j,\n",
      "         3.29427958e-01-1.09983608e-01j,  7.29476437e-02-1.16220005e-02j,\n",
      "         3.54535788e-01+2.12048709e-01j, -2.34260764e-02-6.92817569e-02j,\n",
      "         1.44652680e-01-1.01296343e-01j, -1.73711032e-01+5.02539426e-02j,\n",
      "        -2.53031403e-02-4.64386865e-02j,  6.10113889e-02+8.44140574e-02j,\n",
      "        -7.20824208e-03-5.15585840e-02j,  4.63824749e+00-2.41747703e-02j,\n",
      "         1.78209066e-01-2.16658525e-02j],\n",
      "       [-9.55702737e-02+2.83877194e-01j, -2.95165628e-01-2.67776310e-01j,\n",
      "         3.08804125e-01-5.71958303e-01j, -2.65512139e-01-2.44255111e-01j,\n",
      "        -2.29474574e-01+4.49274331e-02j, -2.87705183e-01-1.03206253e-02j,\n",
      "         1.73533857e-01+5.55275679e-01j, -7.68620819e-02-1.07333794e-01j,\n",
      "         2.17798963e-01-2.64715731e-01j,  1.73822373e-01+1.34617284e-01j,\n",
      "        -1.17425717e-01+1.60592675e-01j,  1.03107719e-02-3.18308085e-01j,\n",
      "         2.97945172e-01+3.53375167e-01j,  6.63591251e-02+9.30496529e-02j,\n",
      "         4.46437311e+00+1.52958790e-02j]], dtype=complex64)>\n"
     ]
    }
   ],
   "source": [
    "for weight in model.trainable_weights:\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
