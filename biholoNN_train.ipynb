{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypersurface_tf import *\n",
    "from generate_h import *\n",
    "from biholoNN import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0, z1, z2, z3, z4 = sp.symbols('z0, z1, z2, z3, z4')\n",
    "Z = [z0,z1,z2,z3,z4]\n",
    "f = z0**5 + z1**5 + z2**5 + z3**5 + z4**5 + 0.5*z0*z1*z2*z3*z4\n",
    "np.random.seed(123)\n",
    "HS = Hypersurface(Z, f, 100000)\n",
    "np.random.seed(124)\n",
    "HS_test = Hypersurface(Z, f, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 25 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f086830dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 26 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f086830d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 27 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08686242f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 28 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f086877ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 29 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08686e7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 30 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08686e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 31 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08980b4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08982797b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f092c07db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f092c12aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f092e546400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f092c2fa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08a8726950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08a87269d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f089858fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08a815b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f08a82298c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "train_set = generate_dataset(HS)\n",
    "test_set = generate_dataset(HS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.shuffle(500000).batch(1000)\n",
    "test_set = test_set.shuffle(500000).batch(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KahlerPotential(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KahlerPotential, self).__init__()\n",
    "        self.biholomorphic = Biholomorphic()\n",
    "        #self.layer1 = WidthOneDense()\n",
    "        #self.layer1 = Dense(25, 1, activation=None)\n",
    "        self.layer1 = Dense(25,500, activation=tf.square)\n",
    "        self.layer2 = Dense(500,500, activation=tf.square)\n",
    "        self.layer3 = Dense(500,1000, activation=tf.square)\n",
    "        self.layer4 = Dense(1000,4000, activation=tf.square)\n",
    "        #self.layer5 = Dense(500,500, activation=tf.square)\n",
    "        #self.layer6 = Dense(500,500, activation=tf.square)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.biholomorphic(inputs)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        #x = self.layer5(x)\n",
    "        #x = self.layer6(x)\n",
    "        x = tf.reduce_sum(x, 1)\n",
    "        x = tf.math.log(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KahlerPotential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def volume_form(x, Omega_Omegabar, mass, restriction):\n",
    "\n",
    "    kahler_metric = complex_hessian(tf.math.real(model(x)), x)\n",
    "    volume_form = tf.math.real(tf.linalg.det(tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True))))\n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
    "    #factor = tf.constant(35.1774, dtype=tf.complex64)\n",
    "    return volume_form / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.3698\n",
      "test_loss: 0.013703559\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.01319101\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.01134931\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.010593451\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011462548\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.00845716\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.0063734464\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0066126166\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0064976257\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00584696\n",
      "step 0: loss = 0.0057\n",
      "test_loss: 0.004994429\n",
      "step 0: loss = 0.0052\n",
      "test_loss: 0.0054956754\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.0058985543\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0045970283\n",
      "step 0: loss = 0.0047\n",
      "test_loss: 0.0044949856\n",
      "step 0: loss = 0.0043\n",
      "test_loss: 0.004569483\n",
      "step 0: loss = 0.0045\n",
      "test_loss: 0.0046341163\n",
      "step 0: loss = 0.0047\n",
      "test_loss: 0.004763415\n",
      "step 0: loss = 0.0048\n",
      "test_loss: 0.004136487\n",
      "step 0: loss = 0.0042\n",
      "test_loss: 0.0039942786\n",
      "step 0: loss = 0.0040\n",
      "test_loss: 0.004185248\n",
      "step 0: loss = 0.0045\n",
      "test_loss: 0.0054799183\n",
      "step 0: loss = 0.0055\n",
      "test_loss: 0.0037975714\n",
      "step 0: loss = 0.0037\n",
      "test_loss: 0.004037912\n",
      "step 0: loss = 0.0044\n",
      "test_loss: 0.0036507256\n",
      "step 0: loss = 0.0038\n",
      "test_loss: 0.0044075656\n",
      "step 0: loss = 0.0045\n",
      "test_loss: 0.0042070276\n",
      "step 0: loss = 0.0043\n",
      "test_loss: 0.0035349787\n",
      "step 0: loss = 0.0036\n",
      "test_loss: 0.0038306287\n",
      "step 0: loss = 0.0039\n",
      "test_loss: 0.003680081\n",
      "step 0: loss = 0.0037\n",
      "test_loss: 0.0034370916\n",
      "step 0: loss = 0.0035\n",
      "test_loss: 0.0034505131\n",
      "step 0: loss = 0.0036\n",
      "test_loss: 0.0030743503\n",
      "step 0: loss = 0.0030\n",
      "test_loss: 0.0031636457\n",
      "step 0: loss = 0.0033\n",
      "test_loss: 0.0030887157\n",
      "step 0: loss = 0.0032\n",
      "test_loss: 0.0029328896\n",
      "step 0: loss = 0.0030\n",
      "test_loss: 0.0033994513\n",
      "step 0: loss = 0.0032\n",
      "test_loss: 0.0033828835\n",
      "step 0: loss = 0.0034\n",
      "test_loss: 0.0029869182\n",
      "step 0: loss = 0.0031\n",
      "test_loss: 0.0032069883\n",
      "step 0: loss = 0.0032\n",
      "test_loss: 0.0030673915\n",
      "step 0: loss = 0.0030\n",
      "test_loss: 0.0032004993\n",
      "step 0: loss = 0.0033\n",
      "test_loss: 0.0027632762\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.0030452127\n",
      "step 0: loss = 0.0030\n",
      "test_loss: 0.0032293445\n",
      "step 0: loss = 0.0032\n",
      "test_loss: 0.0029913876\n",
      "step 0: loss = 0.0030\n",
      "test_loss: 0.0025287187\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0031591181\n",
      "step 0: loss = 0.0033\n",
      "test_loss: 0.0028620115\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.0026770716\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.0024312998\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0031692896\n",
      "step 0: loss = 0.0031\n",
      "test_loss: 0.002859381\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0028457115\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0024710265\n",
      "step 0: loss = 0.0025\n",
      "test_loss: 0.0026718902\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0027111664\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.00275006\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0027533625\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.0029755346\n",
      "step 0: loss = 0.0029\n",
      "test_loss: 0.0024098798\n",
      "step 0: loss = 0.0025\n",
      "test_loss: 0.0025786299\n",
      "step 0: loss = 0.0025\n",
      "test_loss: 0.0024702237\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0027253216\n",
      "step 0: loss = 0.0027\n",
      "test_loss: 0.0029180325\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0027142973\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0024672013\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0025106077\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0024990784\n",
      "step 0: loss = 0.0025\n",
      "test_loss: 0.0023768567\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0027835954\n",
      "step 0: loss = 0.0028\n",
      "test_loss: 0.0023443138\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0026729004\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0026525564\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0021680207\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.002597132\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0022613516\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0025869762\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0022950564\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0022756807\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0022248398\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0023974846\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0025535233\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0019673337\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0025000044\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0023471392\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.002127582\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.0020774214\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0022130762\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.0021612903\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0025171358\n",
      "step 0: loss = 0.0024\n",
      "test_loss: 0.0020014914\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.002090228\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0020846268\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0021260784\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0021469763\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0021261566\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.002571084\n",
      "step 0: loss = 0.0026\n",
      "test_loss: 0.0019351804\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0022067989\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.0021403027\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.002050455\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.002062643\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0023671445\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0019690513\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0020143418\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0022906815\n",
      "step 0: loss = 0.0023\n",
      "test_loss: 0.0022654857\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.0018986571\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0020445331\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.001989665\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0022010165\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.0021575356\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019337268\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0020504424\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019726467\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0022589874\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.002124498\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019476925\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0021035774\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.002120553\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019430474\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0020289088\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0018976094\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0020138817\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0020768237\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0022186623\n",
      "step 0: loss = 0.0022\n",
      "test_loss: 0.002086575\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019172069\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0018424309\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.0019867155\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0017201054\n",
      "step 0: loss = 0.0017\n",
      "test_loss: 0.0019065095\n",
      "step 0: loss = 0.0019\n",
      "test_loss: 0.001990677\n",
      "step 0: loss = 0.0020\n",
      "test_loss: 0.0021208934\n",
      "step 0: loss = 0.0021\n",
      "test_loss: 0.0019028143\n",
      "step 0: loss = 0.0019\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "epochs = 6000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(train_set):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "            loss = weighted_MAPE(Omega_Omegabar, omega, mass)\n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "            #print(grads)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            print(\"step %d: loss = %.4f\" % (step, loss))\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_loss_old = 100\n",
    "    total_mass = 0\n",
    "    \n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(test_set):\n",
    "        omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "        mass_sum = tf.reduce_sum(mass)\n",
    "        test_loss += weighted_MAPE(Omega_Omegabar, omega, mass) * mass_sum\n",
    "        total_mass += mass_sum\n",
    "   \n",
    "    test_loss = test_loss / total_mass\n",
    "    print(\"test_loss:\", test_loss.numpy())\n",
    "    \n",
    "    # This part doesn't work right now\n",
    "    #if test_loss > test_loss_old:\n",
    "    #    break\n",
    "    #test_loss_old = test_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
