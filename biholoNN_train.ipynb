{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypersurface_tf import *\n",
    "from generate_h import *\n",
    "from biholoNN import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0, z1, z2, z3, z4 = sp.symbols('z0, z1, z2, z3, z4')\n",
    "Z = [z0,z1,z2,z3,z4]\n",
    "f = z0**5 + z1**5 + z2**5 + z3**5 + z4**5 + 0.5*z0*z1*z2*z3*z4\n",
    "np.random.seed(123)\n",
    "HS = Hypersurface(Z, f, 10000)\n",
    "np.random.seed(124)\n",
    "HS_test = Hypersurface(Z, f, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c2fe620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c2fe488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa40e4ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c222378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c21e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c21ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c21eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c1377b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c1347b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c134d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c165bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c099400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c102c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c0831e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c0991e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9a81d5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa40e527b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa40d50620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c50dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c4d7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffab472d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c50d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c106ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c4b9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c54cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c253b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c3849d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c375d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c45e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c45e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa3c2bd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa58d2a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa58d2a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa58d2e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa58e16950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa566a4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa566ab2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa562f00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa56312b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa56312a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "train_set = generate_dataset(HS)\n",
    "test_set = generate_dataset(HS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.shuffle(500000).batch(1000)\n",
    "test_set = test_set.shuffle(50000).batch(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KahlerPotential(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KahlerPotential, self).__init__()\n",
    "        self.biholomorphic = Biholomorphic()\n",
    "        self.layer1 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        self.layer2 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        #self.layer3 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "        #self.layer_4 = ComplexDense(50, 10, activation=tf.square)\n",
    "        #self.layer_3 = ComplexDense(10, 15, activation=tf.square)\n",
    "        #self.g = ComplexG(70)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.biholomorphic(inputs)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        #x = self.layer3(x)\n",
    "        #x = self.layer_4(x)\n",
    "        #x = self.g(x)\n",
    "        #x = tf.linalg.diag_part(tf.matmul(x, x, adjoint_b=True))\n",
    "        #x = tf.math.log(x)\n",
    "        x = tf.reduce_sum(x, 1)\n",
    "        x = tf.math.log(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KahlerPotential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def volume_form(x, Omega_Omegabar, mass, restriction):\n",
    "\n",
    "    kahler_metric = complex_hessian(tf.math.real(model(x)), x)\n",
    "    volume_form = tf.math.real(tf.linalg.det(tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True))))\n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
    "    #factor = tf.constant(35.1774, dtype=tf.complex64)\n",
    "    return volume_form / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.6070\n",
      "test_loss: 0.09932825088500977\n",
      "step 0: loss = 0.0978\n",
      "test_loss: 0.06426638126373291\n",
      "step 0: loss = 0.0657\n",
      "test_loss: 0.05879887104034424\n",
      "step 0: loss = 0.0564\n",
      "test_loss: 0.05617036342620849\n",
      "step 0: loss = 0.0546\n",
      "test_loss: 0.05415566444396973\n",
      "step 0: loss = 0.0538\n",
      "test_loss: 0.05303669452667236\n",
      "step 0: loss = 0.0513\n",
      "test_loss: 0.05133878231048584\n",
      "step 0: loss = 0.0507\n",
      "test_loss: 0.04886788845062256\n",
      "step 0: loss = 0.0483\n",
      "test_loss: 0.04734538555145264\n",
      "step 0: loss = 0.0462\n",
      "test_loss: 0.04464642524719238\n",
      "step 0: loss = 0.0418\n",
      "test_loss: 0.042682137489318844\n",
      "step 0: loss = 0.0413\n",
      "test_loss: 0.04032407760620117\n",
      "step 0: loss = 0.0377\n",
      "test_loss: 0.037876405715942384\n",
      "step 0: loss = 0.0357\n",
      "test_loss: 0.03602229118347168\n",
      "step 0: loss = 0.0340\n",
      "test_loss: 0.034733164310455325\n",
      "step 0: loss = 0.0316\n",
      "test_loss: 0.033231563568115234\n",
      "step 0: loss = 0.0326\n",
      "test_loss: 0.03134039878845215\n",
      "step 0: loss = 0.0303\n",
      "test_loss: 0.030648682117462158\n",
      "step 0: loss = 0.0297\n",
      "test_loss: 0.029255449771881104\n",
      "step 0: loss = 0.0271\n",
      "test_loss: 0.028610339164733888\n",
      "step 0: loss = 0.0281\n",
      "test_loss: 0.02733771562576294\n",
      "step 0: loss = 0.0260\n",
      "test_loss: 0.02643167495727539\n",
      "step 0: loss = 0.0242\n",
      "test_loss: 0.02558220863342285\n",
      "step 0: loss = 0.0253\n",
      "test_loss: 0.02470522165298462\n",
      "step 0: loss = 0.0221\n",
      "test_loss: 0.02426316261291504\n",
      "step 0: loss = 0.0230\n",
      "test_loss: 0.024169564247131348\n",
      "step 0: loss = 0.0227\n",
      "test_loss: 0.02295683145523071\n",
      "step 0: loss = 0.0209\n",
      "test_loss: 0.023018972873687746\n",
      "step 0: loss = 0.0224\n",
      "test_loss: 0.022048041820526124\n",
      "step 0: loss = 0.0214\n",
      "test_loss: 0.022543411254882812\n",
      "step 0: loss = 0.0222\n",
      "test_loss: 0.021010894775390625\n",
      "step 0: loss = 0.0200\n",
      "test_loss: 0.021232705116271972\n",
      "step 0: loss = 0.0196\n",
      "test_loss: 0.020852634906768797\n",
      "step 0: loss = 0.0196\n",
      "test_loss: 0.020139992237091064\n",
      "step 0: loss = 0.0187\n",
      "test_loss: 0.021084365844726564\n",
      "step 0: loss = 0.0196\n",
      "test_loss: 0.020534470081329345\n",
      "step 0: loss = 0.0189\n",
      "test_loss: 0.02014392852783203\n",
      "step 0: loss = 0.0192\n",
      "test_loss: 0.019670251607894897\n",
      "step 0: loss = 0.0184\n",
      "test_loss: 0.02002483367919922\n",
      "step 0: loss = 0.0199\n",
      "test_loss: 0.019569525718688963\n",
      "step 0: loss = 0.0186\n",
      "test_loss: 0.020132122039794923\n",
      "step 0: loss = 0.0203\n",
      "test_loss: 0.01969202160835266\n",
      "step 0: loss = 0.0180\n",
      "test_loss: 0.01939224362373352\n",
      "step 0: loss = 0.0193\n",
      "test_loss: 0.019019153118133545\n",
      "step 0: loss = 0.0183\n",
      "test_loss: 0.01902389883995056\n",
      "step 0: loss = 0.0176\n",
      "test_loss: 0.018845919370651245\n",
      "step 0: loss = 0.0185\n",
      "test_loss: 0.01863040804862976\n",
      "step 0: loss = 0.0169\n",
      "test_loss: 0.018898868560791017\n",
      "step 0: loss = 0.0179\n",
      "test_loss: 0.018290717601776123\n",
      "step 0: loss = 0.0169\n",
      "test_loss: 0.018468981981277464\n",
      "step 0: loss = 0.0175\n",
      "test_loss: 0.019273146390914916\n",
      "step 0: loss = 0.0185\n",
      "test_loss: 0.0186928391456604\n",
      "step 0: loss = 0.0169\n",
      "test_loss: 0.018848341703414918\n",
      "step 0: loss = 0.0169\n",
      "test_loss: 0.01839916706085205\n",
      "step 0: loss = 0.0163\n",
      "test_loss: 0.017663986682891847\n",
      "step 0: loss = 0.0168\n",
      "test_loss: 0.018635745048522948\n",
      "step 0: loss = 0.0171\n",
      "test_loss: 0.01801198482513428\n",
      "step 0: loss = 0.0177\n",
      "test_loss: 0.017843387126922607\n",
      "step 0: loss = 0.0168\n",
      "test_loss: 0.017821170091629028\n",
      "step 0: loss = 0.0165\n",
      "test_loss: 0.017560998201370238\n",
      "step 0: loss = 0.0174\n",
      "test_loss: 0.01822869896888733\n",
      "step 0: loss = 0.0171\n",
      "test_loss: 0.01764698266983032\n",
      "step 0: loss = 0.0164\n",
      "test_loss: 0.017620433568954468\n",
      "step 0: loss = 0.0167\n",
      "test_loss: 0.01754120588302612\n",
      "step 0: loss = 0.0180\n",
      "test_loss: 0.017333499193191527\n",
      "step 0: loss = 0.0163\n",
      "test_loss: 0.01769649386405945\n",
      "step 0: loss = 0.0172\n",
      "test_loss: 0.01739309549331665\n",
      "step 0: loss = 0.0168\n",
      "test_loss: 0.0179385507106781\n",
      "step 0: loss = 0.0172\n",
      "test_loss: 0.017315070629119873\n",
      "step 0: loss = 0.0155\n",
      "test_loss: 0.01731356143951416\n",
      "step 0: loss = 0.0156\n",
      "test_loss: 0.0171091091632843\n",
      "step 0: loss = 0.0166\n",
      "test_loss: 0.01714465022087097\n",
      "step 0: loss = 0.0165\n",
      "test_loss: 0.01730816125869751\n",
      "step 0: loss = 0.0160\n",
      "test_loss: 0.01725833773612976\n",
      "step 0: loss = 0.0159\n",
      "test_loss: 0.016935038566589355\n",
      "step 0: loss = 0.0158\n",
      "test_loss: 0.016936743259429933\n",
      "step 0: loss = 0.0158\n",
      "test_loss: 0.017227202653884888\n",
      "step 0: loss = 0.0151\n",
      "test_loss: 0.01668181538581848\n",
      "step 0: loss = 0.0158\n",
      "test_loss: 0.016937611103057863\n",
      "step 0: loss = 0.0162\n",
      "test_loss: 0.01720130205154419\n",
      "step 0: loss = 0.0159\n",
      "test_loss: 0.01656289219856262\n",
      "step 0: loss = 0.0163\n",
      "test_loss: 0.017054684162139892\n",
      "step 0: loss = 0.0166\n",
      "test_loss: 0.016745852231979372\n",
      "step 0: loss = 0.0157\n",
      "test_loss: 0.016608314514160158\n",
      "step 0: loss = 0.0162\n",
      "test_loss: 0.016813050508499145\n",
      "step 0: loss = 0.0166\n",
      "test_loss: 0.016859408617019653\n",
      "step 0: loss = 0.0153\n",
      "test_loss: 0.016617536544799805\n",
      "step 0: loss = 0.0155\n",
      "test_loss: 0.016519676446914672\n",
      "step 0: loss = 0.0144\n",
      "test_loss: 0.01690784454345703\n",
      "step 0: loss = 0.0161\n",
      "test_loss: 0.016644232273101807\n",
      "step 0: loss = 0.0161\n",
      "test_loss: 0.016631776094436647\n",
      "step 0: loss = 0.0169\n",
      "test_loss: 0.016478147506713867\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.016308162212371826\n",
      "step 0: loss = 0.0146\n",
      "test_loss: 0.016221680641174317\n",
      "step 0: loss = 0.0155\n",
      "test_loss: 0.016427950859069826\n",
      "step 0: loss = 0.0155\n",
      "test_loss: 0.01628211498260498\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.017079589366912843\n",
      "step 0: loss = 0.0177\n",
      "test_loss: 0.016613227128982545\n",
      "step 0: loss = 0.0148\n",
      "test_loss: 0.015972964763641358\n",
      "step 0: loss = 0.0146\n",
      "test_loss: 0.016223474740982055\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.01590012788772583\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.01596320629119873\n",
      "step 0: loss = 0.0157\n",
      "test_loss: 0.015696738958358766\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.015873208045959472\n",
      "step 0: loss = 0.0148\n",
      "test_loss: 0.015967971086502074\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.016476231813430785\n",
      "step 0: loss = 0.0154\n",
      "test_loss: 0.015695314407348632\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.015713300704956055\n",
      "step 0: loss = 0.0148\n",
      "test_loss: 0.016015576124191286\n",
      "step 0: loss = 0.0151\n",
      "test_loss: 0.015670188665390015\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.01568110704421997\n",
      "step 0: loss = 0.0141\n",
      "test_loss: 0.01604914426803589\n",
      "step 0: loss = 0.0158\n",
      "test_loss: 0.016025792360305786\n",
      "step 0: loss = 0.0155\n",
      "test_loss: 0.015402244329452515\n",
      "step 0: loss = 0.0139\n",
      "test_loss: 0.015630429983139037\n",
      "step 0: loss = 0.0147\n",
      "test_loss: 0.01546159029006958\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.015365142822265625\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.015370050668716431\n",
      "step 0: loss = 0.0140\n",
      "test_loss: 0.01590258479118347\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.015695713758468628\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.01519200325012207\n",
      "step 0: loss = 0.0143\n",
      "test_loss: 0.015098162889480592\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.015178714990615844\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.015026051998138428\n",
      "step 0: loss = 0.0139\n",
      "test_loss: 0.015284382104873658\n",
      "step 0: loss = 0.0150\n",
      "test_loss: 0.015292301177978515\n",
      "step 0: loss = 0.0147\n",
      "test_loss: 0.015117290019989014\n",
      "step 0: loss = 0.0146\n",
      "test_loss: 0.01505003809928894\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.015297240018844605\n",
      "step 0: loss = 0.0147\n",
      "test_loss: 0.014787228107452392\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.014969881772994995\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.01481652021408081\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.01499306321144104\n",
      "step 0: loss = 0.0140\n",
      "test_loss: 0.014784860610961913\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.014802581071853638\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.015189099311828613\n",
      "step 0: loss = 0.0149\n",
      "test_loss: 0.01469014048576355\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.015269792079925537\n",
      "step 0: loss = 0.0144\n",
      "test_loss: 0.014939656257629394\n",
      "step 0: loss = 0.0140\n",
      "test_loss: 0.014571152925491333\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.015036624670028687\n",
      "step 0: loss = 0.0143\n",
      "test_loss: 0.014537038803100586\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.014775959253311157\n",
      "step 0: loss = 0.0137\n",
      "test_loss: 0.014706922769546509\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.014957842826843261\n",
      "step 0: loss = 0.0141\n",
      "test_loss: 0.014824342727661134\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.014766179323196411\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.014504280090332031\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.014464550018310547\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.014820549488067627\n",
      "step 0: loss = 0.0145\n",
      "test_loss: 0.014497275352478028\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.014706672430038452\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.015007898807525635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0143\n",
      "test_loss: 0.014604041576385498\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.01464722990989685\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.014336119890213012\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.01455539584159851\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.014279202222824097\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.014589097499847412\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.014656957387924194\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.014251896142959596\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.01470661759376526\n",
      "step 0: loss = 0.0146\n",
      "test_loss: 0.014461288452148438\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.014452280998229981\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.01420001745223999\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.01477858543395996\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.014307210445404053\n",
      "step 0: loss = 0.0141\n",
      "test_loss: 0.014119254350662231\n",
      "step 0: loss = 0.0137\n",
      "test_loss: 0.01390238881111145\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.014655587673187255\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.014095629453659058\n",
      "step 0: loss = 0.0139\n",
      "test_loss: 0.013977322578430176\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.014435858726501464\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.013821682929992675\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.014356223344802856\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.013978947401046753\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.014070446491241456\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.014271687269210815\n",
      "step 0: loss = 0.0138\n",
      "test_loss: 0.013658199310302734\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.014040416479110718\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.014348403215408326\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.014392038583755493\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.013964341878890991\n",
      "step 0: loss = 0.0144\n",
      "test_loss: 0.013781965970993041\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.014192148447036743\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.013983283042907715\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013840605020523072\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.014211758375167846\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.01400770664215088\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.013968899250030517\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.014536265134811401\n",
      "step 0: loss = 0.0142\n",
      "test_loss: 0.013504718542098998\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.013871396780014039\n",
      "step 0: loss = 0.0136\n",
      "test_loss: 0.014097148180007934\n",
      "step 0: loss = 0.0135\n",
      "test_loss: 0.013532603979110719\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.014114099740982055\n",
      "step 0: loss = 0.0137\n",
      "test_loss: 0.013753305673599243\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.013628947734832763\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.013715482950210571\n",
      "step 0: loss = 0.0126\n",
      "test_loss: 0.013761749267578125\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.014081592559814454\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.013810142278671264\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.01369669198989868\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.013836930990219116\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.013626842498779297\n",
      "step 0: loss = 0.0126\n",
      "test_loss: 0.013658782243728637\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013827829360961915\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.014202326536178589\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.01366924524307251\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.013559080362319946\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.013379870653152466\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.01345874547958374\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.013545811176300049\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013719456195831299\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013516063690185548\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013730652332305908\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.013316603899002076\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.013368782997131347\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013736780881881714\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013804377317428588\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.013593424558639527\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013520864248275756\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.014052026271820069\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.012996225357055665\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.013757165670394898\n",
      "step 0: loss = 0.0126\n",
      "test_loss: 0.013790351152420045\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.013203541040420532\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013386083841323853\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.01347636580467224\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.0146085524559021\n",
      "step 0: loss = 0.0133\n",
      "test_loss: 0.013075168132781983\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.0131900155544281\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.013297704458236694\n",
      "step 0: loss = 0.0126\n",
      "test_loss: 0.013035860061645508\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.013368266820907592\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013413640260696412\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013382251262664796\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013095378875732422\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013243656158447265\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.01309669017791748\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.013326075077056885\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.0133713960647583\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013424108028411865\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013308135271072387\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.014014954566955567\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.013421626091003417\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.013078927993774414\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013159412145614623\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013354147672653199\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013064780235290528\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.013239114284515381\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013230265378952026\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.013008021116256714\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.01304205060005188\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.01334938883781433\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.013078259229660034\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.012978264093399049\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.013135014772415162\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.013405468463897705\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.012812421321868897\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013019750118255615\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013553496599197388\n",
      "step 0: loss = 0.0134\n",
      "test_loss: 0.013206291198730468\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.01326706051826477\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012948687076568604\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013450150489807128\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.013212207555770874\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.01305798888206482\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.01314692258834839\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.013451788425445557\n",
      "step 0: loss = 0.0131\n",
      "test_loss: 0.013233448266983033\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012908202409744263\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.013060858249664306\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013035203218460084\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012885009050369262\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012824277877807617\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.012783510684967041\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012923882007598878\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.013125\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012786346673965453\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013025823831558227\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.01296452283859253\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013154363632202149\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013328258991241454\n",
      "step 0: loss = 0.0130\n",
      "test_loss: 0.012687702178955079\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.013028875589370728\n",
      "step 0: loss = 0.0126\n",
      "test_loss: 0.012543566226959228\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01260704517364502\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012742208242416382\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012826764583587646\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.013141906261444092\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.01284703254699707\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.01281304121017456\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.013069717884063721\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.012776439189910888\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012753057479858398\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.013032834529876709\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.013117783069610596\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.01265484929084778\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012736157178878785\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012961872816085816\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.0125663959980011\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.012996081113815307\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01310362458229065\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.01305317759513855\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012758593559265136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012855548858642579\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012555787563323975\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012621641159057617\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.013076064586639404\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.013016525506973266\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.013001410961151124\n",
      "step 0: loss = 0.0132\n",
      "test_loss: 0.012733206748962403\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012698205709457398\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012925715446472167\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012793762683868408\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012715648412704467\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.0126580810546875\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012709435224533081\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012709603309631348\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01283471941947937\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.013153269290924072\n",
      "step 0: loss = 0.0129\n",
      "test_loss: 0.012661217451095582\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012532508373260498\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012722054719924927\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012601926326751708\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012654691934585571\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012786580324172974\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012459524869918824\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.012528948783874512\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012536849975585938\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012732467651367187\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.012669720649719239\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.01258753776550293\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012990106344223023\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.01231101632118225\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012769687175750732\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012579249143600464\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012876559495925904\n",
      "step 0: loss = 0.0123\n",
      "test_loss: 0.01261763572692871\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012868969440460206\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.012676411867141723\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.0126993727684021\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012518393993377685\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012783389091491699\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012666260004043578\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.01247577428817749\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012457208633422851\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012591450214385987\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012712671756744384\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01276469111442566\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012540028095245362\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012660428285598754\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012324974536895753\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012564162015914917\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012839350700378418\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.013032780885696411\n",
      "step 0: loss = 0.0128\n",
      "test_loss: 0.012731435298919678\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.012636345624923707\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012471883296966553\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012432656288146972\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012224689722061158\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012501583099365235\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.01263205885887146\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01266355037689209\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012522789239883423\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012409948110580445\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012290771007537843\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012568063735961914\n",
      "step 0: loss = 0.0127\n",
      "test_loss: 0.01283890962600708\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01226564884185791\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01243059992790222\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012476567029953003\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012546666860580445\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012437890768051147\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012548341751098632\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012530978918075562\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012240467071533203\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012291585206985473\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012448915243148805\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012389417886734009\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012430500984191895\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012366598844528199\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012311880588531493\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012681307792663575\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012370412349700927\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01251198649406433\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012372913360595704\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012620900869369506\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.012314269542694092\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.01250664234161377\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.0126381516456604\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012251235246658325\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012411104440689087\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.01277679681777954\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012360602617263794\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012692663669586182\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.012193242311477661\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012208635807037354\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012496570348739624\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012488739490509033\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012336901426315307\n",
      "step 0: loss = 0.0119\n",
      "test_loss: 0.012229914665222169\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012226470708847047\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01224070429801941\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012416417598724366\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01276668906211853\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.012456822395324706\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.01226478099822998\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012588478326797485\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012287538051605224\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012305434942245484\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012777023315429688\n",
      "step 0: loss = 0.0124\n",
      "test_loss: 0.012426215410232543\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.012540097236633302\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012305278778076172\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012291755676269531\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012588064670562744\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.011989846229553222\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012759501934051514\n",
      "step 0: loss = 0.0121\n",
      "test_loss: 0.012173737287521363\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012734761238098144\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012260231971740723\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01206478476524353\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012076584100723266\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012504295110702515\n",
      "step 0: loss = 0.0125\n",
      "test_loss: 0.012607837915420533\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012114394903182984\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012309359312057495\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012310912609100342\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012293002605438232\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.01215838074684143\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012073733806610108\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01208860158920288\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012379103899002075\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01250799536705017\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012037415504455567\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01226410984992981\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01217388391494751\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.01214848279953003\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012473487854003906\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012295852899551391\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012134981155395509\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012096034288406372\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012239177227020264\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012089980840682983\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012221179008483886\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012430452108383179\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.012191053628921509\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012207187414169311\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012349894046783447\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.01224927306175232\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012056822776794434\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.012328091859817505\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01229565978050232\n",
      "step 0: loss = 0.0120\n",
      "test_loss: 0.012569279670715331\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.011951621770858765\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.012175889015197753\n",
      "step 0: loss = 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.01232213020324707\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012053852081298827\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01229580283164978\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01229584813117981\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012347056865692138\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012108452320098877\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012210074663162231\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011870735883712768\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012217087745666504\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.01262924551963806\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012287839651107788\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.01221219778060913\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012246286869049073\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012103725671768189\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012257717847824097\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.01205466628074646\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011964136362075805\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01202862024307251\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.011995714902877808\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012123430967330933\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01195999264717102\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.012182769775390625\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01240370273590088\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012827211618423462\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012005165815353394\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01201193332672119\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.012052175998687744\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012365965843200684\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01207289457321167\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01197206139564514\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011998292207717896\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01212089776992798\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012161412239074708\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012073467969894409\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012351428270339965\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011876717805862427\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.0120537269115448\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.012043588161468506\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011882668733596802\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012128916978836059\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012221745252609252\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01195839762687683\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01214141607284546\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011742193698883057\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.012164465188980102\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012157644033432008\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01178335189819336\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01247846007347107\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01190434694290161\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012181886434555055\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011842588186264038\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012102893590927123\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.012099430561065674\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.01174407720565796\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011945830583572388\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011870273351669312\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011881473064422608\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.0119066059589386\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.012238404750823974\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01213948130607605\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.012269681692123413\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012243515253067017\n",
      "step 0: loss = 0.0117\n",
      "test_loss: 0.012041457891464234\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01186515212059021\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011827059984207154\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01191041350364685\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011840864419937133\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.012053561210632325\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012138463258743286\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.012390817403793336\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.012177318334579468\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012171962261199952\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012268658876419068\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011925626993179322\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01194959282875061\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01199947953224182\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012324111461639404\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011969050168991089\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012335184812545776\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.011857877969741821\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01205649733543396\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01199200987815857\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011742599010467529\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.01179373860359192\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.012093054056167602\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.011797139644622803\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.012077913284301758\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011828135251998901\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011934205293655395\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.012262811660766601\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011859878301620483\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012188783884048461\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012084720134735107\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.012329601049423218\n",
      "step 0: loss = 0.0122\n",
      "test_loss: 0.011999948024749756\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01182600975036621\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011832776069641114\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011947734355926514\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011896617412567138\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01212480902671814\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011895816326141357\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.01195580244064331\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.012041692733764648\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.011999715566635132\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011878902912139893\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012007863521575927\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011620414257049561\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.012072269916534423\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012136653661727906\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011890579462051392\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01207642912864685\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011885132789611817\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011556211709976196\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01172092318534851\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011855375766754151\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011733437776565553\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01180739164352417\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011878429651260377\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011708041429519653\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.012019994258880616\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.011945887804031372\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011836674213409424\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01178228497505188\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011888506412506104\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011816734075546264\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011749271154403686\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01201138973236084\n",
      "step 0: loss = 0.0116\n",
      "test_loss: 0.011799299716949463\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011915677785873413\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011685651540756226\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.012058403491973877\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01173577070236206\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.011921285390853882\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011909122467041016\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011961321830749511\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011833163499832154\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011845518350601197\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011889047622680664\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011903153657913208\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.012032665014266967\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011896589994430542\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011903566122055054\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012060390710830688\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011589148044586182\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011640889644622803\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011787624359130859\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011855204105377198\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011894179582595825\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011935880184173584\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.01180217146873474\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01200814962387085\n",
      "step 0: loss = 0.0118\n",
      "test_loss: 0.01160177707672119\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011713418960571289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012300717830657958\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011715128421783447\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011873233318328857\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011850458383560181\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011875067949295043\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011894387006759644\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011773816347122192\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01178048610687256\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011778953075408936\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011644768714904784\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.01179140329360962\n",
      "step 0: loss = 0.0114\n",
      "test_loss: 0.0116320538520813\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011862061023712157\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01182376742362976\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01168299674987793\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011917111873626708\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011730700731277466\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011661229133605957\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011681168079376221\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011681306362152099\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011862730979919434\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.012138484716415406\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01165203332901001\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01207200288772583\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011604812145233154\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011535394191741943\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.01175554633140564\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011358368396759033\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011726083755493165\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011645773649215698\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.012048401832580567\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011720151901245117\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011758389472961426\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01178092360496521\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011669310331344605\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011560683250427245\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011800118684768678\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011907333135604858\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.012059638500213623\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011849435567855835\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011641532182693481\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011778830289840699\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01161779761314392\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01181239366531372\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.01176397681236267\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01195563554763794\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011500346660614013\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011594198942184449\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011593343019485473\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011712386608123779\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011713331937789917\n",
      "step 0: loss = 0.0115\n",
      "test_loss: 0.011653934717178344\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01162022352218628\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011612117290496826\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011864254474639893\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011896449327468871\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011491838693618774\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011585601568222047\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.01156994104385376\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011422653198242188\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.01175665259361267\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011473845243453979\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011514246463775635\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011780269145965576\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011788359880447387\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011562706232070922\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011635208129882812\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011774497032165527\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011687644720077515\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011406803131103515\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011467578411102295\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011767252683639526\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011394519805908204\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011662328243255615\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01182935357093811\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011822636127471925\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011431498527526856\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01200447916984558\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011460323333740235\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011470576524734497\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011587525606155396\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011281994581222534\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011422257423400878\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011474545001983643\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011499712467193604\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011698136329650879\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011574398279190063\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011385277509689332\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011720106601715088\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011544941663742066\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011483080387115478\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01139431357383728\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011686941385269165\n",
      "step 0: loss = 0.0113\n",
      "test_loss: 0.011696118116378783\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011664589643478393\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011757352352142335\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011470669507980346\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01150542140007019\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011552729606628419\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011480876207351685\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011355986595153808\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011529649496078492\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011479223966598512\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011336461305618287\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011627899408340454\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011555187702178955\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011501349210739135\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011558386087417603\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011439664363861084\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011698079109191895\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011331839561462402\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.011595022678375245\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.01152420997619629\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011392905712127685\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011539068222045899\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011567883491516114\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011373081207275391\n",
      "step 0: loss = 0.0111\n",
      "test_loss: 0.01164075255393982\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.0115545654296875\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.011547746658325196\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011265411376953124\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011423521041870117\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011155786514282227\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011370182037353516\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011274491548538207\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011759991645812989\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01120651364326477\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011393272876739502\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011200188398361207\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.0112381112575531\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011735858917236329\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.0114651620388031\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011675393581390381\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.01139701247215271\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011378172636032104\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011508831977844238\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011613963842391968\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011288702487945557\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011680964231491089\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011490139961242676\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011472930908203125\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011445900201797485\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011526285409927369\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011717653274536133\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011273013353347778\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011232017278671265\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01134846568107605\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011518750190734863\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011318488121032715\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011232357025146484\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011261675357818603\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011257350444793701\n",
      "step 0: loss = 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.011271333694458008\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.0115838623046875\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011475112438201904\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011384128332138062\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.01123572826385498\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011474486589431763\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011337437629699708\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011461586952209472\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011700071096420288\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011448899507522583\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011663172245025635\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011235851049423217\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011395037174224854\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.01101369857788086\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011409794092178344\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.0112982177734375\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011384934186935425\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.01137187957763672\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011234095096588135\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011515986919403077\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011284022331237794\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011479090452194213\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.01110614776611328\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011324700117111206\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011253061294555665\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011195137500762939\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011215384006500245\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011175031661987305\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.011481430530548096\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.0113743257522583\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.01129346489906311\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.01152024269104004\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011222773790359497\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011143242120742797\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.01115775465965271\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.011347899436950684\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011147011518478394\n",
      "step 0: loss = 0.0106\n",
      "test_loss: 0.011216847896575928\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.010992685556411743\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011257306337356568\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011349184513092041\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011158159971237182\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011457810401916504\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.01143643856048584\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011053595542907715\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011040525436401367\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011510347127914428\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011198095083236694\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011276116371154785\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.011423038244247436\n",
      "step 0: loss = 0.0110\n",
      "test_loss: 0.01135149359703064\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011417407989501954\n",
      "step 0: loss = 0.0112\n",
      "test_loss: 0.01130165696144104\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011236333847045898\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011185394525527954\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01124434232711792\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01142257809638977\n",
      "step 0: loss = 0.0109\n",
      "test_loss: 0.010930949449539184\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011429215669631959\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.011180424690246582\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011306600570678711\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011120349168777466\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011190237998962403\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011386338472366333\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011050820350646973\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011096042394638062\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011130808591842652\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011268259286880493\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011298071146011352\n",
      "step 0: loss = 0.0107\n",
      "test_loss: 0.011285767555236817\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011111989021301269\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011276857852935791\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.01104433536529541\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.011099761724472046\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011188092231750489\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011245883703231811\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011146212816238404\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011022303104400635\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011116126775741577\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.0111771559715271\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011193578243255614\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.011147525310516358\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010896211862564087\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.011229722499847413\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.01115556001663208\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.011077289581298827\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010921221971511842\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.011213864088058472\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.011218184232711792\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011049473285675048\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010981534719467162\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010986981391906738\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011082239151000976\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010797019004821778\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.011052347421646118\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011419281959533692\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011037256717681885\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011199535131454467\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011405887603759766\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.01126927137374878\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011145560741424561\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01079662799835205\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011202834844589234\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010910327434539796\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.011097760200500488\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.010972472429275513\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.010943288803100587\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.01115839958190918\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011039483547210693\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011015969514846801\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010936390161514282\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.01075236439704895\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01084757924079895\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010854393243789673\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010907810926437379\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.011097456216812135\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.0112470281124115\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.010955367088317871\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010927654504776\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.01089489459991455\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.01088167428970337\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010962541103363038\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.011030664443969726\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010917853116989135\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010875766277313232\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010998449325561523\n",
      "step 0: loss = 0.0105\n",
      "test_loss: 0.011023985147476196\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010971062183380127\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011243537664413453\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.010866429805755615\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010783989429473877\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01076904296875\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010998042821884156\n",
      "step 0: loss = 0.0108\n",
      "test_loss: 0.010865952968597412\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010727858543395996\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010908807516098023\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.01085608959197998\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010665503740310668\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010818657875061035\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010805951356887817\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011101772785186767\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.011037259101867676\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.01096813678741455\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.011094616651535034\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01087298035621643\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.010773595571517944\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.01077444314956665\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010839407444000243\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010876927375793457\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010813329219818115\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.011112428903579712\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.011042323112487793\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.01092452645301819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010840804576873779\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010872359275817872\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010754210948944092\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010916249752044678\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010837202072143554\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010936692953109742\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010625579357147218\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010554314851760864\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010861893892288208\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010809582471847535\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010739225149154662\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010794166326522827\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010977808237075806\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010709964036941529\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010960996150970459\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010933706760406494\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010748269557952881\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010872316360473634\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010790839195251464\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010810810327529907\n",
      "step 0: loss = 0.0104\n",
      "test_loss: 0.01069129467010498\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010573983192443848\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010807653665542602\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010513240098953247\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.01060250163078308\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010691992044448852\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010592652559280396\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010579959154129029\n",
      "step 0: loss = 0.0102\n",
      "test_loss: 0.01061716914176941\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.01070517897605896\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010764691829681396\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010657539367675781\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.0106005859375\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010858873128890991\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010460039377212524\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010745155811309814\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010621088743209838\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010668696165084838\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010838662385940551\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010710607767105102\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010674453973770141\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.011009654998779296\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010544571876525879\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010942885875701905\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010836608409881592\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010532898902893066\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010641641616821289\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.01083450198173523\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.0105448317527771\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.01081497073173523\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010696457624435425\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010495275259017944\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.01069390058517456\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010623284578323365\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010731509923934936\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010564448833465577\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010575717687606812\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010696839094161987\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01066400170326233\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010539093017578126\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01054498553276062\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010510122776031494\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01072619080543518\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010479260683059693\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010664815902709962\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010341982841491699\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.0105005145072937\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01077341914176941\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.010445181131362915\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010416842699050903\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010353399515151978\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.010616179704666138\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010386096239089966\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01049768328666687\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010422136783599854\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010411947965621948\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010628819465637207\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010307323932647706\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.01043898582458496\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010414856672286987\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010527465343475342\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010479685068130493\n",
      "step 0: loss = 0.0103\n",
      "test_loss: 0.010676200389862061\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010268657207489014\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010535850524902343\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010481456518173218\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010514991283416748\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010530152320861817\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010336676836013794\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010532865524291992\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010246156454086304\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010681263208389281\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010561871528625488\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010458230972290039\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010439035892486572\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010620614290237427\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010301170349121093\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010445401668548585\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010574884414672851\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010298200845718385\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010206631422042846\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010510754585266114\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010528159141540528\n",
      "step 0: loss = 0.0101\n",
      "test_loss: 0.01057506799697876\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01031359076499939\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.01039225935935974\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010247405767440796\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010270802974700928\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010438333749771118\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.010262200832366944\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.01054324746131897\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.01034954309463501\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.01040222406387329\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010320338010787964\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010218774080276488\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010429506301879882\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010290530920028686\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010363039970397949\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010526890754699708\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01013669729232788\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010309094190597534\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010409733057022095\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010164169073104858\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.01016571044921875\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010308899879455567\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010168354511260986\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.0102681303024292\n",
      "step 0: loss = 0.0099\n",
      "test_loss: 0.010122746229171753\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010326253175735474\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010228528976440429\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010601015090942382\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010277745723724365\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01009537935256958\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010212913751602173\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010100467205047607\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.009975726008415222\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.010070608854293823\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010224072933197022\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.010295236110687256\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010397276878356933\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010051168203353882\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010206111669540406\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010371626615524291\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010111352205276489\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010053989887237548\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.010332733392715454\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009987223744392395\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010344672203063964\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010081380605697632\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.010501549243927003\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010197497606277466\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010257656574249268\n",
      "step 0: loss = 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.010398112535476685\n",
      "step 0: loss = 0.0097\n",
      "test_loss: 0.010486541986465455\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010274497270584106\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.010048015117645264\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010105626583099365\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.01005695343017578\n",
      "step 0: loss = 0.0100\n",
      "test_loss: 0.010067170858383179\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010076462030410767\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.010148364305496215\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010049372911453247\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.00997318685054779\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01014478325843811\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010368337631225586\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009982883930206299\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010176297426223755\n",
      "step 0: loss = 0.0098\n",
      "test_loss: 0.01016790270805359\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.010052508115768433\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010000114440917968\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010083096027374268\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.010026239156723023\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009890317320823669\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.010147780179977417\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.010113848447799683\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009920806288719178\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010204150676727294\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010133501291275025\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.009899200797080994\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.00998157799243927\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009970784783363343\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010000325441360473\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009873977303504944\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009981141090393067\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.009978558421134948\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009675307869911194\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009850839376449585\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010098874568939209\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009953328967094421\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.010080198049545288\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009992392063140869\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.00994027853012085\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009763588905334472\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00988671839237213\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009888126254081727\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009971898198127747\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010002156496047973\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.01000199794769287\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009604248404502868\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009722544550895692\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00984851598739624\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009779078364372253\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009839842319488526\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.0100022292137146\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.0099498450756073\n",
      "step 0: loss = 0.0094\n",
      "test_loss: 0.00999021291732788\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009876325130462646\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009888771772384643\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009819939136505126\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.010114151239395141\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009724343419075012\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.010027931928634643\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.010022444725036621\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009867401123046874\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009788389801979065\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009688755869865418\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.010005229711532592\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.00992950975894928\n",
      "step 0: loss = 0.0096\n",
      "test_loss: 0.009660009145736694\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009761075377464295\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009706414341926574\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00966583490371704\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009717715978622437\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.00976704716682434\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009927338361740113\n",
      "step 0: loss = 0.0095\n",
      "test_loss: 0.009700518250465393\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009694679975509643\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.00980796754360199\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009750676155090333\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009726480841636657\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009750486612319946\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.00969061315059662\n",
      "step 0: loss = 0.0093\n",
      "test_loss: 0.009715183973312377\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009605140089988709\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009962124824523926\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009531266093254089\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009660930633544921\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009920328259468078\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009616692662239074\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009867703318595886\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009688940048217774\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009601070284843445\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009569423198699951\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00980284333229065\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.010002450942993164\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.009673101305961608\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009823358058929444\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00973582923412323\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009681064486503601\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009674171805381776\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009603412747383118\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009648165702819823\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009613325595855713\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009842553734779358\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.00974884808063507\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009728769659996033\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009566777348518372\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009564707279205322\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009513244032859802\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009568433165550233\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009527824521064758\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009557449221611024\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009490503668785096\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00979648232460022\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009689417481422425\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009506320953369141\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.00960716485977173\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009471482634544372\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009529286623001098\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009482341408729554\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009616528153419495\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009523460865020752\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009464319348335266\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00958805799484253\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009471659064292908\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00971291720867157\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009481938481330872\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009499704241752624\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00943850040435791\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.00923940122127533\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009408991932868958\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009475105404853822\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009540861248970032\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009477844834327698\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009570205807685852\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009553819298744201\n",
      "step 0: loss = 0.0090\n",
      "test_loss: 0.009435898661613464\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009489603042602539\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00947922945022583\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.00937240719795227\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009398803114891052\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009523754715919494\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009262821078300476\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009509608745574952\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009274831414222718\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009392749667167664\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009282909631729126\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009419494867324829\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009455798864364625\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009427003860473633\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009360577464103698\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009454052448272705\n",
      "step 0: loss = 0.0092\n",
      "test_loss: 0.009468700885772705\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00930755317211151\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.009373194575309753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009372406601905824\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009231780767440795\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.009273610115051269\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009386776089668274\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009411943554878234\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009438936114311219\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009419693946838378\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009491570591926575\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009373973608016967\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009362724423408509\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009395543336868286\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009217519760131836\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.009242109060287475\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009395062327384948\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00944710373878479\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009281663298606873\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009522305727005005\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009217580556869507\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009169557094573975\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009268065690994262\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009404849410057068\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009459030628204346\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009271316528320313\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009225741028785706\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009315291047096252\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009500398635864257\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009180499315261841\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.00915012240409851\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009155162572860719\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00922110140323639\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.0092083740234375\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009073706269264221\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009163106083869934\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009170077443122863\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009287209510803222\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009329926371574402\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.00917797863483429\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009162012934684754\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009048122763633728\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.009152085781097411\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.00930739462375641\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009327394962310791\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009065307974815369\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009176806211471558\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009311391115188599\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009053472876548768\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.008885049223899842\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009230656027793884\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.00921510398387909\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009155946373939515\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009005088806152344\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009214746356010437\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009070177674293517\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009088465571403503\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.00924180269241333\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.009003320336341858\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008971425890922546\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009010748863220215\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009094894528388978\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009026506543159485\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.009043877720832824\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.00963534414768219\n",
      "step 0: loss = 0.0091\n",
      "test_loss: 0.008913043737411499\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009207035899162292\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009174140691757203\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008776116371154784\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.009220972061157226\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.009044026732444763\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009055752754211426\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009327502250671386\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009126957654953003\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009030646681785583\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00901625394821167\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008916245102882385\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009116047024726869\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00898428201675415\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009332431554794312\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009123626351356506\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.009288383722305298\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.009113582372665406\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.008678811192512513\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00922420859336853\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.008905930519104004\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.00896660566329956\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009198710322380066\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00913098394870758\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.00876469850540161\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00913457214832306\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008933617472648621\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.00904060184955597\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.00894257128238678\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.009172211289405824\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.009030140042304992\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.009053666591644288\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.009106817841529845\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008800438046455384\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008832265734672546\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008786789774894714\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.009095826745033264\n",
      "step 0: loss = 0.0087\n",
      "test_loss: 0.008832953572273254\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.009100943207740783\n",
      "step 0: loss = 0.0088\n",
      "test_loss: 0.009088391065597534\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008976198434829712\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.009161715507507323\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008889722824096679\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008742239475250244\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.009113659262657165\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008811362981796265\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.0089349627494812\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008913206458091736\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008796340227127076\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008864946365356445\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008977078199386597\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008879219889640808\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008874648213386536\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008900139927864075\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008909002542495728\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008960656523704529\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008850988149642944\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008720240592956542\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00895093023777008\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.009051135778427123\n",
      "step 0: loss = 0.0086\n",
      "test_loss: 0.008795024156570434\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.008732855319976807\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008712133765220642\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008799459338188171\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.00884571373462677\n",
      "step 0: loss = 0.0084\n",
      "test_loss: 0.00886915385723114\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008859815001487732\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008952561616897583\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008768311142921448\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.00890215575695038\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008825044631958007\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008813127875328064\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00874258816242218\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.00871153175830841\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.00867518424987793\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008872883915901185\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008647012114524842\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008723807334899903\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008815925121307373\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008835453987121582\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008634905219078065\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008801469206809997\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008837498426437378\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008626400232315064\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008773455619812012\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008542233109474183\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008583017587661744\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008793073296546937\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008775805234909057\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008784355521202087\n",
      "step 0: loss = 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.00855210304260254\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00887513518333435\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008714357018470764\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008925659656524658\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008693567514419555\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008551061153411865\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008715958595275878\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008821208477020264\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008538338541984557\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008773186206817628\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008911653757095336\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008738818764686584\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008651597499847412\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008779150247573853\n",
      "step 0: loss = 0.0085\n",
      "test_loss: 0.008676458597183228\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008601388335227967\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008539427518844605\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008708089590072632\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008726602792739869\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008571249842643737\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008627681732177735\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008908228874206543\n",
      "step 0: loss = 0.0089\n",
      "test_loss: 0.00871524453163147\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008528143763542176\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008805873990058898\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008503336906433106\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008651757836341858\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008651659488677979\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008719277381896973\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008518890142440796\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008984109163284302\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008432328104972839\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008427985310554505\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008538440465927125\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008376139402389526\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008519071340560912\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008393329977989196\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00845767319202423\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00861486315727234\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.00870507538318634\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008442030549049377\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008595804572105408\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008577301502227783\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008738965392112732\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.00856807291507721\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008479918241500855\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008518493175506592\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008647006750106812\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008367971777915954\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008396586179733276\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00863057553768158\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008474719524383546\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.0084314626455307\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008376628160476685\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008317115306854249\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008439037799835205\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008599403500556945\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008557988405227661\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008369349837303162\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008383796215057374\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00861225962638855\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008392189145088196\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008671904802322388\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.008436472415924072\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00864807963371277\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008583993911743163\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008569437861442566\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008598887920379638\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008350573182106018\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008385658264160156\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008707252144813538\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008305891156196595\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008505826592445373\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008390743136405945\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008644022941589356\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008520746231079101\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00834734320640564\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008406347632408141\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008447006344795227\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00847987174987793\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008375086784362794\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008573237061500549\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00834148108959198\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008364635705947875\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008291584849357604\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008508511185646057\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.00843567430973053\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008444189429283142\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008551967144012452\n",
      "step 0: loss = 0.0083\n",
      "test_loss: 0.00833450436592102\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008518280386924744\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008524430990219116\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.00830788791179657\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008562203049659729\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008382205367088318\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00850318968296051\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00846942126750946\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008359984159469605\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008415188789367676\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00828993022441864\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008557957410812379\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008566026091575623\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008363803625106811\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008489681482315064\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008149592876434327\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008278327584266663\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008480733036994934\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008413975238800048\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008464553952217102\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008163612484931946\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008591957688331604\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008272776007652282\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008411539196968078\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008612394332885742\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008337788581848145\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008465335965156555\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008374031782150269\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008362402319908141\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008307728171348571\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008229635953903199\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008330055475234986\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.00825929582118988\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008298212885856629\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008281819224357605\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008506532907485962\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008383074402809143\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008337759971618652\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008350703716278076\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008392829895019532\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008225873708724976\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008446372747421264\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008371572494506836\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008388127088546754\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008413701057434083\n",
      "step 0: loss = 0.0082\n",
      "test_loss: 0.008207825422286987\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008159921169281006\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008251233100891113\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008349131345748901\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008262996077537537\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008366074562072754\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008326220512390136\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008374435901641846\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008248122930526734\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007996063828468323\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008159267902374267\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008141422867774964\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008199328780174256\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00821917712688446\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008408477902412415\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008362189531326295\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.008177879452705383\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00811165153980255\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008259978890419007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008154905438423156\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008083112835884095\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008215517401695252\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008389523029327392\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008347931504249572\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008160091042518615\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008238874077796936\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008208262920379638\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008251801729202271\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008171581029891968\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008287410140037537\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008173862099647522\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008124948143959046\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008393983840942382\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008278454542160035\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008220037817955017\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008222497701644897\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008234515190124511\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008310356736183166\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008355924487113952\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00815286099910736\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008202841281890869\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008183571696281432\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008170411586761475\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00816821813583374\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008012502193450928\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008053647875785828\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008219638466835022\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00824553906917572\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008129966855049133\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008323714137077332\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008268242478370666\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008258308172225953\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008230472207069397\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008127347230911255\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008139386773109436\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00839151918888092\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008166447281837463\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008210044503211975\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008261337280273437\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00827390730381012\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007992678284645081\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008094964623451233\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00822884202003479\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008242757320404052\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008151897192001344\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008163667917251587\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00819553792476654\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008005293607711792\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008198952078819275\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00819383144378662\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008037083745002747\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008388481736183166\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00815543532371521\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008171403408050537\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008194451332092284\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008157222867012023\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008081403970718383\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008250479102134705\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008017473816871644\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00825503170490265\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007947409152984619\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00826133906841278\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008025662899017334\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008016557693481445\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008127356171607971\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008057090640068054\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00787301242351532\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008416942358016967\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008263020515441895\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007963296175003052\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00827254056930542\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.00807466745376587\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008287342786788941\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008046567440032959\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008085066676139832\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008229944705963135\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008097002506256104\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008151798844337463\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008113054037094116\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008242350816726685\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008290563225746155\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008036771416664123\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008086629509925843\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008254965543746948\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008007189631462098\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008070715069770813\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007989544868469239\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008069100975990295\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008148583173751832\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008096720576286316\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007928653955459594\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007972774505615234\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00808502197265625\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007897886633872985\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007968866229057313\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008143486380577087\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.008067682385444641\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008062137961387635\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007941315174102783\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008407408595085144\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0081571364402771\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007971821427345276\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00815663456916809\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007961798310279846\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00814390242099762\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00812907874584198\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008036244511604309\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007993049621582031\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00819047451019287\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008301421999931335\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007991853952407837\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008044296503067016\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008201431632041931\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.00822379469871521\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008033711910247803\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00811492919921875\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008020755052566528\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008045496344566345\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.00788781702518463\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008302600979804993\n",
      "step 0: loss = 0.0080\n",
      "test_loss: 0.007964600920677184\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00796222984790802\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008102244734764098\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007884206175804138\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00822554886341095\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007940476536750793\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.008116771578788757\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008204721212387085\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008046059608459473\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008128924369812012\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008117846250534057\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008017525672912598\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008204618692398071\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008048545718193054\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008199836611747741\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008062573671340943\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00786716639995575\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008140912652015686\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008127433061599732\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007849958539009095\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007954311966896057\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007864169478416443\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007971261739730834\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007974944710731506\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008186442852020264\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008048654794692993\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008116755485534668\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007834225296974182\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007936604022979736\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007942576408386231\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008182191848754882\n",
      "step 0: loss = 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.008087474107742309\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007819663286209106\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007862188816070557\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008120529055595398\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008019642233848571\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007862632274627685\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007867833375930786\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00785421371459961\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007788245677947998\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007971317172050477\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00786730945110321\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008063468933105469\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008124005794525147\n",
      "step 0: loss = 0.0081\n",
      "test_loss: 0.008204606771469116\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007961530089378357\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00812263548374176\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008022791743278503\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007841119766235352\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00806826114654541\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0082522052526474\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008019691705703736\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007998038530349732\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007857770323753357\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007857885956764222\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008020954728126526\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.007880764603614808\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007809876799583435\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008019516468048096\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007917896509170533\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007858879566192627\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008145994544029235\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00791406750679016\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00805148422718048\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007959694266319275\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00795880615711212\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007755404114723205\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007855809926986694\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.008017596602439881\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008085296750068664\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00814337432384491\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007913532853126525\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007958089709281921\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007981301546096801\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008082762956619263\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007868804335594178\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007879222631454469\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00798926293849945\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.00784226655960083\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.008006433844566346\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007799189686775208\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00802232801914215\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008129380345344543\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007894699573516845\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007850359082221986\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00804581880569458\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007766086459159851\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008085412383079528\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007976276278495788\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.008048282265663146\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007913261651992798\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007915793657302857\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008004255890846253\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008006806969642639\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.0077893674373626706\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007988213300704957\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008071104288101196\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007994011640548707\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.008098811507225037\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007972789406776428\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007918246984481812\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007952231764793396\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00785428524017334\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007928624153137206\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008028064966201781\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008008601069450378\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.008035115003585815\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008016152977943421\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007904363870620728\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007989206910133361\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00778670847415924\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007995368838310242\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00801970660686493\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007739075422286987\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0078043794631958005\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007976223826408385\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007995721697807313\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008122003078460694\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00800579845905304\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007960717082023621\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008146483302116394\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.00796723246574402\n",
      "step 0: loss = 0.0079\n",
      "test_loss: 0.007868109345436096\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007993977665901184\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007818700075149536\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00790695309638977\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008106977343559266\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007882070541381837\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007876160740852355\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00798426866531372\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007972230315208434\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007772605419158935\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007993950247764588\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007914230227470398\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077939885854721065\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007873326539993286\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007871156930923462\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077992135286331175\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007896247506141662\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007824456691741944\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008034865260124207\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007831903100013733\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077845466136932375\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008027979731559753\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007766426801681519\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007912265062332153\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007992895245552063\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007788131833076477\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007952499389648437\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00794639229774475\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.00778334379196167\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007896094918251037\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077554923295974736\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007862467169761658\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00805479884147644\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007921801805496216\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007833123803138733\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007917619943618774\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008073503971099854\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.008002142310142518\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00792899250984192\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007987183332443238\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0078082108497619625\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007752745151519775\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00817630410194397\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007991433739662171\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00794099509716034\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00790833830833435\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007780789732933045\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007950597405433656\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007776368856430054\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007882567048072815\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007975262999534606\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007952248454093933\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.008139063715934753\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.008005929589271545\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007925740480422973\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008007960915565491\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007696588039398194\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007805614471435547\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.008083581924438477\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00798977792263031\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007770593762397766\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007908051013946532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008007927536964417\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007801474928855896\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007953295707702637\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007806025147438049\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007752736806869507\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007765102982521057\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007957691550254822\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00793093740940094\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00795095145702362\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00785582721233368\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007832999229431153\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077026402950286866\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007769097685813904\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007862519025802612\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007937241196632385\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007725223302841187\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008031325340270996\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007801476716995239\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007701200842857361\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00812158465385437\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.0078412926197052\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007862620949745179\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007806935906410217\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007899155616760254\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.00776669442653656\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0076693731546401975\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00784491240978241\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007853452563285828\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007914117574691772\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007762975096702576\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007863049507141113\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007771056890487671\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007943596839904785\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007715035676956177\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007848986387252808\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007829867005348205\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007907929420471192\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007917939424514771\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007854621410369873\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00794613778591156\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007998828887939452\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007866023182868958\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007723153829574585\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007903881669044495\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007788833975791931\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0079716694355011\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007817232608795166\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007799082994461059\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007866336703300477\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007840571999549866\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007963513135910033\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007840797901153565\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0077882915735244754\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007954583764076232\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007909969091415406\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007760617733001709\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007695105075836182\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007841041684150696\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00800952672958374\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007668443918228149\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007662807703018189\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0077836036682128905\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077138543128967285\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.008013678193092346\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076942133903503416\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007904866337776184\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007743422985076904\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007873340249061585\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007652947902679444\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007879979610443115\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007824435234069824\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007878432273864746\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007989578247070313\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008049201369285584\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007748733758926391\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.008007739782333373\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00788151204586029\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007809728980064392\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0077445518970489504\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007782387733459473\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007773856520652771\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007862730622291566\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007781369686126709\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007846404314041138\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007865101099014282\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007643591165542602\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007708711624145508\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007839639186859131\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00772449254989624\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00798654079437256\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007854964137077331\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0077700638771057125\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007687117457389831\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0077824461460113525\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007714683413505554\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007691343426704407\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007890037894248962\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007788516283035278\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007929747104644775\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076856911182403564\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007834863066673279\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.007765879034996033\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.008008804321289063\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007902860045433044\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007712147235870361\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007488046288490296\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007584226727485657\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007815612554550171\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007918695807456971\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007667537927627564\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007793910503387451\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007769724726676941\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007726775407791138\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007817519903182983\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007688714265823364\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007932780981063843\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007842814922332764\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077819180488586425\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007909252047538758\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007597664594650269\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007709867358207703\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007613070607185364\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007598093748092651\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007734494209289551\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007854150533676147\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007932992577552795\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007794110178947449\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007703713178634644\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007783000469207764\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007904002666473389\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007888634800910949\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007905071377754211\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00784725248813629\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00778765857219696\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007873735427856444\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007978019118309022\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007984357476234437\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007731860280036926\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007731204032897949\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007803068161010742\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00787185251712799\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007657727003097534\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007857165932655334\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007725793123245239\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007766067981719971\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007631893754005432\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007564882040023804\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007822245359420776\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007634317874908448\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007601286768913269\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007719098329544067\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007898470759391785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007806910872459411\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0076975500583648685\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0077471107244491575\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007868832349777222\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007770164608955383\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007743797898292541\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007756677865982056\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007802667617797851\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007753002643585205\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007950816750526429\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007808334231376648\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007898271679878235\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077426421642303464\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007540010809898376\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00792822778224945\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.00800668478012085\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007734202742576599\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007737597227096557\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007941346764564514\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007720431089401245\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007957459092140198\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007694265842437744\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0076532715559005735\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007909849286079407\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.0078128981590271\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007781873941421508\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007655181884765625\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007760811448097229\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007808936834335327\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0078008508682250975\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007635020017623902\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0077571475505828855\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007794457077980041\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007665579915046692\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007887258529663085\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007755182385444641\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007649837136268616\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007805781960487365\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007704218626022339\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007564589977264404\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007789332866668702\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007709471583366394\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007757934927940369\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00785722017288208\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007775775790214538\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0076246815919876094\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007747575640678406\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.0077705389261245724\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077875196933746334\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0076682579517364504\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007886418104171754\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007590852975845337\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007782277464866638\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007830749750137329\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007642764449119568\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007715942859649658\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007760487794876099\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007734876275062561\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007806705832481384\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007701119184494018\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007714802622795105\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007692654132843018\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00764259397983551\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0076708924770355225\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007801294922828674\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007707753777503967\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007776637673377991\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007601072192192078\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007783955931663513\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007628586292266846\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007654683589935303\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007598075270652771\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007694189548492432\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007881144285202027\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007734608054161072\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007728608250617981\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007723961472511292\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007672219872474671\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00761400043964386\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007822732329368592\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007781047821044922\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007616838812828064\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007564969658851624\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007594712972640991\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0075945591926574706\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007850874662399292\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007752819061279297\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077078777551651\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007831686735153198\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007803189158439636\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0075704073905944825\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007702481746673584\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007601519823074341\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007675561308860779\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007691256403923034\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00769647479057312\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007605423927307129\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007707616686820984\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00767707884311676\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077602148056030275\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00781295120716095\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0076374787092208865\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007861533164978028\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007763757705688477\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00759367823600769\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007722814679145813\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0075271201133728025\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007837688326835632\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007597842216491699\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0076947444677352905\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007617695331573486\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007840927243232727\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007801505327224731\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007718693017959594\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007561948299407959\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0075663989782333374\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00759596586227417\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007757015228271484\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007564085721969605\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00767335057258606\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.008094331622123719\n",
      "step 0: loss = 0.0078\n",
      "test_loss: 0.0077745521068573\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007717077732086182\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007738655805587769\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007811850905418396\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007655244469642639\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007742712497711182\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007646233439445495\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007836490273475646\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007522832751274109\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007648387551307678\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007673595547676087\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007991811037063598\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007553291916847229\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007581037878990174\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007701845169067383\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00756810188293457\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007637854814529419\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007621946930885315\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007591286897659302\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007602941393852234\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007643498778343201\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007672294974327087\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00782991647720337\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007674533724784851\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007590173482894897\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0077476131916046145\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007582735419273377\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007640056014060974\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007800090909004211\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007621498703956604\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007519450783729553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007766430377960205\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007768632769584656\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007552317976951599\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007530996799468994\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007628249526023864\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007838433980941773\n",
      "step 0: loss = 0.0077\n",
      "test_loss: 0.007735054492950439\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007927101850509644\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007580289840698242\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007505001425743103\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007402669191360473\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007600072622299194\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007565281987190246\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007725988626480103\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007725962400436401\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007710299491882324\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007649818062782287\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007623597979545593\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007665268182754517\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075460284948349\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007630140781402588\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007695519924163818\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007747772336006165\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075850987434387205\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007761704325675964\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007670722007751465\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077694827318191525\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007691622376441955\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007651540040969848\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007614661455154419\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0077665412425994874\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007663952708244323\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007636034488677978\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007903771996498108\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007571139335632324\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007651719450950623\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007800498604774475\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0075965821743011475\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00770216166973114\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007668043971061706\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0074899160861968996\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007541335821151733\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0077124106884002685\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007629169225692749\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007784172892570496\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007774783968925476\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0076110965013504025\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0075893145799636845\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007702909111976623\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00768083930015564\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007660236358642578\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007558790445327759\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007907124161720276\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007618511915206909\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007547466158866882\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007660430669784546\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007678471207618713\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007671688795089722\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007810938358306885\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007626743912696838\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007679257392883301\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0076143240928649904\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076072591543197635\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007685484290122986\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007801785469055176\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007799593806266785\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007729853391647339\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007695883512496948\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007581876516342163\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007609692811965943\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00763965368270874\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007637550830841064\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00784406304359436\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007471648454666138\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00749376118183136\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007653712034225464\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007573873996734619\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007638232707977295\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007632988691329956\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007640658020973206\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007684198021888733\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007453166246414185\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007559835314750672\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007762933373451233\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007498176693916321\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007685512900352478\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007565252780914307\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007564175724983215\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007583651542663574\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00774541437625885\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007604303359985351\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007745606303215027\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007713448405265808\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00754159927368164\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007608811855316162\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007793672084808349\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007578039169311523\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007534634470939636\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007603240013122558\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007575203180313111\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00756089448928833\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007711081504821777\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007600805163383484\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007829356789588928\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007715029120445252\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007742783427238465\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007627753019332886\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007787089943885803\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007646444439888001\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007775763869285583\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007645018696784973\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0077627265453338624\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007630646824836731\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007552008628845214\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007508169412612915\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007648271322250366\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0077088940143585204\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007643611431121826\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007676601409912109\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076630526781082155\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007535653114318848\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007605249285697937\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007670605182647705\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007598088383674622\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007632375955581665\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007584795355796814\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00766656756401062\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0075317776203155514\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007561647891998291\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007551005482673645\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0076478695869445805\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007549066543579102\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007757554054260254\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00767622172832489\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007624817490577698\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00762717068195343\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0075071221590042115\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007611139416694641\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007554636597633362\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007530691623687744\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007558141946792603\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007630300521850586\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075784969329833985\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007515069246292114\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007636989951133728\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007587202787399292\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00764050841331482\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007667012214660644\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007638863325119019\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007600634098052978\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007620524168014526\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007535144686698914\n",
      "step 0: loss = 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.007718824744224548\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007653070092201233\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0075219708681106565\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007568563222885132\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007545222043991089\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007550870776176452\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007504303455352784\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007594735026359558\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007570546865463257\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00760083794593811\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0075711715221405025\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00758699893951416\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007631179690361023\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00750180721282959\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007480441927909851\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00756780743598938\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007712128162384033\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007478553056716919\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075921154022216795\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007659251689910889\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007514207363128662\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007614695429801941\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007598801255226135\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0077062475681304934\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007514814734458923\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007616334557533264\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007473467588424682\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007588236927986145\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007612420320510864\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007584485411643982\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007560154795646668\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00768364429473877\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0075945258140563965\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0074586570262908936\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007663103938102722\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007482460737228394\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007548602223396301\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007632558345794678\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007557034492492676\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007547172904014588\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007524135708808899\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007559107542037964\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007609744668006897\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007624670267105103\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007641603350639343\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0075506925582885746\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007632147669792175\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007492915391921997\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007761567831039429\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007598392367362976\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007690447568893433\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007621581554412842\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007726895213127136\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007794599533081054\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007614716291427613\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.0075498813390731815\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007615512609481812\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007581374645233154\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007629194855690002\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007562884092330933\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007534739375114441\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007621777057647705\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0076137840747833255\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007670905590057373\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007452349066734314\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007709624767303466\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007550902962684632\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007553178071975708\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075628674030303955\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0075757187604904175\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007598488330841064\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007553505897521973\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007782670855522156\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0075525730848312374\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007630181312561035\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007610884308815002\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0076379221677780156\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007571347951889038\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007695832848548889\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007455063462257386\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007500370740890503\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007570708990097046\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075034904479980465\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007451503872871399\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007444155216217041\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075165069103240965\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007607123851776123\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007510534524917603\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007850863337516785\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0077024495601654055\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007759221792221069\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007608087062835694\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007547857761383056\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076389598846435544\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007568557262420655\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00760509729385376\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007562052607536316\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007606114149093628\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007698269486427307\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007592817544937134\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007607493996620179\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007511528730392456\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007751691937446594\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007587695121765136\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007541803121566773\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007654346227645874\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007688394188880921\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007575387954711914\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00751738429069519\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007519739866256714\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007631219029426575\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007511759400367737\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007691724896430969\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007535752654075622\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007511223554611206\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007675040364265442\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007402880787849426\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007581035494804382\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007678050994873047\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007623193860054016\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007520921230316162\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007634391188621521\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007509651184082031\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007519419193267822\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007623636722564697\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007493277192115784\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007417059540748596\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007651503682136535\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007498119473457337\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007641245126724244\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007471094727516174\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00755877435207367\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0075380182266235355\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007551678419113159\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007417680621147156\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007556627988815307\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007559912800788879\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007461851835250855\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007610195279121399\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007482524514198303\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007478707432746887\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007414944767951966\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007679077386856079\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007584149837493896\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007523309588432312\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007635141015052796\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00757926881313324\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007448434829711914\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0076032763719558714\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007807705998420716\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007505871057510376\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007524258494377136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007456585764884949\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007446190118789673\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007812107801437378\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007437871694564819\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00763231635093689\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007490851283073426\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007499351501464844\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007584636807441711\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007509540319442749\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007569836378097534\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007652132511138916\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007594484090805054\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075802308320999144\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007369371056556702\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00750413715839386\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0076344400644302365\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007574498057365418\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007555763125419617\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075489461421966554\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007571152448654175\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007515894174575806\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007727163434028625\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007467400431632996\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007715581655502319\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00765945553779602\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007615063786506653\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007505937814712525\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007587468624114991\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007445291876792908\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007652193903923034\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007555717825889588\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007411618828773499\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007485311627388001\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007493904829025269\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007520773410797119\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00743618905544281\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007472648024559021\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0075931096076965335\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0077710384130477905\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007622981071472168\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007528603672981262\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007664851546287536\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007538873553276062\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007460734248161316\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074159657955169675\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007681567668914795\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007596666812896728\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007709755897521973\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007560024857521057\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007518669366836548\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.0075330215692520144\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007507230639457702\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007688887119293213\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007485431432723999\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007523371577262878\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007566040754318238\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007584207653999329\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007563593387603759\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007551031708717346\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007583433985710144\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007551998496055603\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007674646377563476\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00751904308795929\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0075252348184585574\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007405130863189697\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00753158450126648\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007597330808639526\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007569849491119385\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007525442838668823\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007538673877716065\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007450559735298156\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007503260374069214\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007526143193244934\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007459269165992737\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007385522723197937\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007557702660560608\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007644492983818054\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007448688745498657\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007507302761077881\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007478311061859131\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007513515949249268\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007520517110824585\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007514254450798035\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007516108155250549\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007461947202682495\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007507431507110596\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007422787547111512\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007511996030807495\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007558931708335877\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007723437547683716\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007521868348121643\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007581082582473755\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007384648323059082\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075826627016067506\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075318610668182375\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007510864734649658\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007471302747726441\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007501165866851806\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00749756634235382\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007653204202651978\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007538478374481201\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007508429884910584\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00757278561592102\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007375417947769165\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007562474608421326\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007459872364997864\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007659311890602111\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007365934252738952\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007623679041862488\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007540857195854187\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007482172846794128\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075733006000518795\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007537180781364441\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007581676244735718\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007441511750221253\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007457646727561951\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007576181292533874\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007438728213310241\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00765960693359375\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007567070722579956\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007510364651679992\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0075058406591415406\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007353355884552002\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007424849271774292\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075844496488571165\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007507527470588684\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007479000687599182\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007430740594863892\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007562495470046997\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00741933524608612\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0073801809549331665\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007390477657318115\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007511253356933594\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007512171268463135\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00736386775970459\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007558202743530274\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007441831231117249\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007425842881202698\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007429451942443848\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007509776949882507\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007387053966522217\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00759727656841278\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007549963593482971\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007494855523109436\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007465799450874329\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007534340620040893\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075107705593109135\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007446382641792298\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007456971406936646\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007517759203910828\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0076219761371612545\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007637731432914734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007561483979225158\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007507469058036804\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007628784775733948\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007499600648880005\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007657656073570251\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007545730471611023\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007458775639533997\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007617742419242859\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007491406202316284\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007425532937049866\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00749030590057373\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007629766464233399\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007405996918678283\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007513694763183594\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007456520795822144\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00745265007019043\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007489431500434875\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007431566119194031\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007601548433303833\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007454485297203064\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074267244338989255\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007503668069839478\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007465923428535462\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007526606321334839\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00746600866317749\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007501757144927979\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007457505464553833\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007362605333328247\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007614713311195374\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007517069578170776\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007506824731826782\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007373704314231872\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074518537521362305\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007506566047668457\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007377066612243652\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007418952584266662\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007301720380783081\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0075536763668060305\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007422686219215393\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007665014863014221\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007466835975646973\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007431655526161194\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00750594973564148\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007388452887535095\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007586432695388794\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074517691135406496\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007461068630218506\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074388539791107175\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007406275272369384\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007324196696281433\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0075811010599136355\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00741971492767334\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007388991117477417\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007466187477111816\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00743023157119751\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007404281497001648\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007522557377815247\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00743047297000885\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007679857611656189\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0076031327247619625\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007510838508605957\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007440190315246582\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007432411909103393\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0074405944347381596\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007549003958702088\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00740220844745636\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007444589138031006\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007507379055023193\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007422546148300171\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007453144788742066\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007375470399856567\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007533605694770813\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0075557780265808104\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074842232465744014\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007405681610107422\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073762345314025875\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007522293925285339\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007409173846244812\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007372868061065674\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007635443806648255\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00735295832157135\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007429013848304748\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007451096177101135\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007607903480529785\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007406377792358398\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007543236017227173\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007557761073112488\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007422823309898376\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007391624450683594\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007394236326217651\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007339965105056762\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0075484240055084225\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007514367699623108\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00749179482460022\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007449637651443481\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007503095865249634\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007425644397735596\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073391801118850705\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007442300319671631\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007386712431907654\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007619704008102417\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007345738410949707\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007628465294837952\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007479232549667358\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007477530837059021\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007504270076751709\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007511722445487976\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007525356411933899\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007446033358573914\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0073928296566009525\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00749156653881073\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007490934729576111\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007302531003952026\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007400385737419128\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007355906963348389\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007373233437538147\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007517750263214111\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007456256151199341\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007527086138725281\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007391840815544128\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007515332102775574\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007464281916618347\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0075058466196060184\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007441886067390442\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007511307001113892\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007462375164031983\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0075046861171722415\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0074084681272506715\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007303876876831055\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074149203300476075\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007411442399024963\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074309599399566655\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007506943941116333\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007367703318595886\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007533006072044372\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007447745203971862\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007461235523223877\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007401648759841919\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007395585775375366\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007389681339263916\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007461603879928589\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007456631660461426\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075115376710891725\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072296828031539915\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073728072643280025\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00764569103717804\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074572920799255375\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007466253638267517\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007462430000305176\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073927569389343264\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007482699155807495\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007630740404129028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007412884831428528\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007396809458732605\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00741973340511322\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007657722234725952\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007593307495117187\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00739227831363678\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074299460649490355\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00747467815876007\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007377723455429077\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007351070046424866\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007520743608474731\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007329471111297607\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007448987364768982\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074336987733840945\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007382505536079407\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073910045623779294\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00732887864112854\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0074414688348770144\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007371029853820801\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007587330341339111\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007460625767707825\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007440828680992126\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007384966611862182\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007405626773834229\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007484540343284607\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00742574155330658\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007488872408866882\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007496492862701416\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007441000938415527\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007485833764076233\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00746454119682312\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0075593537092208864\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007346546053886413\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007515822052955628\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007358272671699524\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074127066135406495\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007436970472335816\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007444930076599121\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00742275595664978\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007416736483573914\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007379021048545837\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007544324398040771\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007494277358055115\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007374868392944336\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007509562373161316\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007509949803352356\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007475353479385376\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007365679740905762\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007605737447738648\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073640507459640505\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007482337355613708\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074095380306243895\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007519803047180176\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074763882160186765\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0074351227283477785\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007420256137847901\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007553303837776184\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007320892810821533\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007576447129249573\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00740216851234436\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0075483697652816775\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007425697445869446\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007435241341590881\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007310119271278381\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007418742179870605\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007325391769409179\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007365353107452392\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007537634372711182\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074004954099655155\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007392123341560364\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007482497692108154\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074420785903930664\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007446988821029663\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007479216456413269\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007583379149436951\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00748348593711853\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00732261061668396\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007438571453094483\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074461597204208375\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.00751987338066101\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007397449016571045\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007356435656547546\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00743390679359436\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007533443570137024\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007394217848777771\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0074380838871002195\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007401546239852905\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007446791529655456\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007347699999809265\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007378553748130798\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007372275590896606\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075674295425415036\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007419842481613159\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007391979694366455\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007445792555809021\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007523742318153381\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00747948944568634\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007361153364181519\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007426345348358154\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007612249851226807\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00740054190158844\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007451056838035584\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007482788562774658\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00737238347530365\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007360365390777588\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00743541419506073\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0073211598396301265\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075754857063293456\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00749737024307251\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007398730516433716\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0072814422845840455\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007532046437263489\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007405852675437927\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00728937029838562\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007557812333106995\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007406746745109558\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007552539110183716\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007419413328170777\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007404952049255371\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007330500483512878\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007407022714614868\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007381981015205383\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007415571212768555\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007424941062927246\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074007248878479\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0074930846691131595\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074597328901290895\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007514902353286743\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007440077066421509\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007385857701301575\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074202907085418705\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007345389723777771\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007393299341201782\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00747154176235199\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007427610754966736\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007498431801795959\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007487693428993225\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007371922731399536\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007314400672912598\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0074843794107437136\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007328661680221557\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00752448320388794\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007419145703315735\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00751939058303833\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007310088276863098\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007487847208976745\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007377672791481018\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007346394658088684\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007429500818252563\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.00738020122051239\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007561683654785156\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007388569712638855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007295066118240356\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007381826043128968\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007337989807128906\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007338492274284363\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007499850988388061\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007526130080223083\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007295888662338257\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007514209151268005\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074039483070373535\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007308778762817383\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007506663799285889\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007566205263137817\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007369909882545472\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00733225166797638\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007357751727104187\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007417133450508118\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007387086153030396\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00735380470752716\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007409321665763855\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007370853424072265\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007297064661979675\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007551848888397217\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007382653355598449\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007365760803222657\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007519447207450867\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0075204259157180785\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007395805716514587\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0073401820659637455\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007274171113967895\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0074055719375610354\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00750436782836914\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007378545999526978\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007326622605323792\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007503997683525086\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007335804700851441\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007426728010177613\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00728753387928009\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007490435242652893\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007392529249191284\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007527276277542115\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007464805841445923\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007614216208457947\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007183494567871093\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073491430282592776\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007435857653617859\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007353676557540894\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007318921089172363\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007484526634216309\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007432539463043213\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074679434299469\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007387705445289612\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007413785457611084\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071833980083465575\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007416360378265381\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007353575825691223\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007504801750183105\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007379356026649475\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074621295928955075\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007359474301338196\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007420859932899475\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007337074279785156\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007474848628044128\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007504264712333679\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007496370673179626\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007415393590927124\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007393041849136353\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073625147342681885\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00737773597240448\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007433310747146606\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007386586666107178\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007487059831619263\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007375745177268982\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007479119300842285\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00747764527797699\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007320314645767212\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007477875947952271\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007403163909912109\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007349305748939514\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007268664240837097\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007323082685470581\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007465834617614746\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007327964901924134\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007431433200836181\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00752265214920044\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007400193810462951\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007404194474220276\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007344854474067688\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007220700979232788\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074306589365005496\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007541144490242005\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007262055277824402\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007470670938491821\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007356995344161987\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0074855035543441775\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007473246455192566\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007383787035942078\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007490578889846802\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074714720249176025\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074192404747009276\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007341300845146179\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007402523159980774\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007440221309661865\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007458574771881103\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007362874150276184\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007358055114746093\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007473481297492981\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007286645174026489\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007378491163253784\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00745930552482605\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007444625496864319\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007434115409851074\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007282705307006836\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007327306866645813\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00736946702003479\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007500777840614319\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007440192699432373\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007402679920196533\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007386172413825989\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007283574938774109\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007352714538574219\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073060417175292965\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007483493089675903\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007415197491645813\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007379201054573059\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0074617981910705565\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00744771420955658\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00738282561302185\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0074402976036071775\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007339759469032287\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00733521044254303\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074522531032562254\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007318499088287353\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007345935702323914\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007598919272422791\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007352360486984253\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00754127323627472\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007459126710891724\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007389063835144043\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007378129959106445\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007511088848114014\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007321431636810303\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072899794578552245\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007364383935928345\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007239332795143128\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007411534190177918\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007443794012069702\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007437624931335449\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073381346464157105\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007394637465476989\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007287137508392334\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007291486859321595\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007401486039161682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007372123003005981\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007497678399085998\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007398601174354553\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007379490733146667\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007398941516876221\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007457020282745361\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0074291789531707765\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007375529408454895\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007378502488136291\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007461173534393311\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007337658405303955\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00729154646396637\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007310603260993958\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007356213331222534\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007459335327148438\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007353471517562866\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007327964901924134\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007285002470016479\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007353379726409912\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007379632592201233\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007342351078987122\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007514567375183106\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073777824640274044\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007234712243080139\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007379997372627258\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007374444007873535\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007309747934341431\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007400516271591186\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007369365096092224\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007373949289321899\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007526248097419739\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007288393378257751\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007473291158676148\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00739392101764679\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007420294284820557\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073088592290878295\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007530419826507568\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073807984590530396\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007241113781929016\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007289276123046875\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007272504568099976\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007317447662353515\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007313349843025207\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007325446009635925\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007324208021163941\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007515915632247925\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.00732607364654541\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007304522395133972\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072653436660766605\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007385630011558533\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007316157817840576\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007314562797546387\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007329967617988586\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007424608469009399\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007489485144615174\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007320085167884826\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007360804677009582\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007413581013679504\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007736155986785889\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007204135060310364\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072918391227722165\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007333408594131469\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007372364997863769\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007278840541839599\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007355452179908752\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007515968680381775\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007238326668739319\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007347273230552673\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007421009540557862\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007341916561126709\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007243181467056274\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073352384567260745\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007259412407875061\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007357335090637207\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007315338253974914\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007406356930732727\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007378960847854614\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007273104190826416\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0072865265607833865\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007370545268058777\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007347086071968078\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007309094071388245\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007248122096061706\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007473306655883789\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0074681746959686275\n",
      "step 0: loss = 0.0075\n",
      "test_loss: 0.007345783114433288\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00738297700881958\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007424906492233276\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007525293231010437\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007387017011642456\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073050856590271\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007405853271484375\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007326372265815735\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007269213199615479\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007499107718467712\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007509608864784241\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007347756028175354\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074544578790664675\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073375338315963745\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007366645932197571\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007457709908485413\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00734074354171753\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007375171780586243\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007375185489654541\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007396291494369506\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007384362816810608\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00729654312133789\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007251513600349427\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007350810766220093\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007233808040618897\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007311038374900818\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007393273711204529\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007459251880645752\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0074911415576934814\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007274575233459472\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073637843132019045\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007267128229141235\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007374531626701355\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007352873086929322\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007306556701660156\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007358758449554443\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007401134371757507\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073241180181503295\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007315850853919983\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007406742572784424\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007277713418006897\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007233566641807556\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007413172721862793\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00733652114868164\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007413184642791748\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073925316333770755\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007456684112548828\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0074329376220703125\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007343345284461975\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007339274883270264\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007279501557350159\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007484793066978455\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007331095933914185\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007290182709693909\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007275591492652893\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007423979043960571\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007373061180114746\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007341313362121582\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007329307198524475\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072975409030914306\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007605979442596436\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.0072878867387771605\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007337512969970703\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007399027943611145\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007253749966621399\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007325261831283569\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007309025526046753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007519039511680603\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007401856184005737\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007292234301567078\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007226125001907348\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007324571013450623\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007316399216651916\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007335711121559143\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007244875431060791\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007374393939971924\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007357509136199951\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007259456515312195\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007337398529052734\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007373843789100647\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074986833333969116\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007316855788230896\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007343579530715943\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007284387350082398\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007213298678398133\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007326105237007141\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007367726564407349\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007336955070495605\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007349076867103577\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007311940789222717\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007338840961456299\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007241923213005066\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00736397922039032\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007252058386802674\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007296346426010132\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007410687804222107\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007405990362167358\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007351861596107483\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007275549173355103\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007416743040084839\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007177329659461975\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007266613841056824\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007356796860694886\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007260080575942993\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073085886240005496\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073108959197998044\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007228825092315674\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073566162586212154\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007339369058609008\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007318747639656067\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007351568341255188\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007370842695236206\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007435953021049499\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073837172985076905\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00754263699054718\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007308670282363892\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0075260329246521\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007324807643890381\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007290597558021545\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007331975102424622\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007240732908248901\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007358583211898803\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00737657368183136\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072568488121032716\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007305063605308533\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007367537617683411\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0074645310640335085\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007225751876831055\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007356745600700379\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007297657132148742\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00730328381061554\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007349077463150024\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00732632040977478\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007366513609886169\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00732420027256012\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007357284426689148\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007337266802787781\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007380890846252442\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007406479716300964\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007377943396568299\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007284550666809082\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007420326471328735\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007233107686042786\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007431451678276062\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073794019222259526\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007296338081359864\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007257452011108398\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0073747336864471436\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007389544248580932\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007240234613418579\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0072163337469100955\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007328661680221557\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007367839813232422\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007333734631538391\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007370513677597046\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007382738590240479\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007369758486747742\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073184376955032346\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073798072338104245\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007243286967277527\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007363691329956055\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007117494344711304\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007320355176925659\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007213412523269653\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007227866053581238\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007373694181442261\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007392206788063049\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007339849472045899\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007281447052955628\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00742471992969513\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007287082076072693\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007245107889175415\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007339779734611512\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007204139828681946\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073820513486862185\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007192188501358032\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00720503568649292\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007229044437408448\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007302727699279785\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007330185770988464\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0074512970447540286\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007319815158843994\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072621917724609375\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007326753735542297\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007452086210250854\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072042888402938845\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007398558259010315\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007198334932327271\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007416104078292847\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007281689047813416\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007294443845748902\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073683100938796995\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007334350943565369\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007355420589447021\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007275393605232239\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007204905748367309\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007414134740829467\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0072709423303604125\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00742456316947937\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007401424050331115\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007357804179191589\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007362978458404541\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007409871816635132\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072396093606948856\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072676950693130495\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072948110103607175\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072420710325241085\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072319889068603515\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007336740493774414\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007372971773147583\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007412168383598328\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007347539663314819\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007302130460739136\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007364825606346131\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007382591962814331\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00726842999458313\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007301029562950134\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007471293807029724\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073033785820007325\n",
      "step 0: loss = 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.007580656409263611\n",
      "step 0: loss = 0.0076\n",
      "test_loss: 0.007261404395103454\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071904569864273075\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007337878942489624\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00734557569026947\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007252202033996582\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007280610203742981\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007274398803710938\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007446699738502502\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007381008267402649\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007516281008720398\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007177793979644775\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072316288948059086\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007288329005241394\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00726102888584137\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071990108489990235\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007385075688362121\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007393034100532532\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007191451787948608\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072799140214920045\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007233803868293762\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007382302880287171\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007484038472175598\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007197939157485962\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00730471670627594\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007282593846321106\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007283418178558349\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007370011806488037\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007449766397476196\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0074126142263412475\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007322673797607422\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007333047389984131\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0072935354709625245\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00737605094909668\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007389059662818909\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007328163385391235\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007213695049285889\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072775065898895265\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007353182435035705\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007301682829856873\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007264120578765869\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007248141169548035\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007296276688575745\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007509236931800842\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007195738554000855\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007374578714370727\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007241036891937256\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007227049469947815\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073010832071304325\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072128760814666746\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007281560897827149\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007318795919418335\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007403277158737183\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072830718755722045\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007329946160316467\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007415733933448791\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007249699831008911\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007204480171203613\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007351178526878357\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007372125387191773\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007455376982688904\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007299056053161621\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007407037019729615\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007249817252159119\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007272517085075378\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00742175817489624\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007348276972770691\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007272369861602783\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007259985804557801\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007178500294685364\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00735542893409729\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007293723821640015\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007304259538650513\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072700434923171995\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007349414825439453\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0072719955444335935\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007202942967414856\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007266910076141358\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007413551211357117\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007421795129776001\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073420989513397214\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00718643307685852\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007365822792053223\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007260229587554932\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007319228649139404\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0074508821964263915\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007321015000343323\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00719777524471283\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007362395524978638\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007331961393356323\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00733940601348877\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007276993989944458\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007201268076896667\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007298514246940613\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007228370308876037\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007393946647644043\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007308321595191955\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007330992817878723\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073183029890060425\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007311892509460449\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073139572143554685\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007333523035049439\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007315195798873901\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007288001775741577\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007403029203414917\n",
      "step 0: loss = 0.0074\n",
      "test_loss: 0.007196270227432251\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007226642966270447\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007277266383171082\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007327088713645935\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007214813828468323\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007144696712493896\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007270067930221558\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007377539873123169\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007319926023483276\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007287235856056213\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007190421819686889\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007220494151115417\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007244352102279663\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007456417083740234\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007491672039031982\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072922462224960325\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007231783270835877\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007195817828178405\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007361823320388794\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007247008085250854\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007251719236373902\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007435654997825622\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007388668656349182\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007291017770767212\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007292933464050293\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007332046627998352\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007268468737602234\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007252406477928162\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0071811282634735105\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00725554883480072\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007279226183891296\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007271062135696411\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007310453057289124\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00730231523513794\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007260777950286865\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007324346303939819\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007187992334365845\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007303518056869507\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007444250583648682\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007268216013908386\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073434126377105715\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007354917526245117\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007328495979309082\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072521352767944336\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00721901535987854\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007483735680580139\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007357129454612732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007224013805389404\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007328650951385498\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007179969549179077\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0073207104206085205\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0073129040002822875\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007274292111396789\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007412489056587219\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007177384495735168\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00728963553905487\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007232493162155152\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007237452268600464\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007309420108795166\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007355222105979919\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007366428375244141\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0074811190366745\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007397143244743347\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00730400562286377\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007225134372711182\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007341731786727906\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007178184390068054\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007339897751808167\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072969883680343624\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007280430793762207\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00717254638671875\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007341468930244446\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007106688618659973\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007283461093902588\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007220060825347901\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007290305495262146\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007235321402549744\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00723325252532959\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007221454381942749\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00727851152420044\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007388834357261658\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007345110177993774\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007286289930343628\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0072376179695129396\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073554527759552004\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007392758131027221\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007238238453865052\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007143434286117554\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007242317199707031\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00728989064693451\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071592777967453\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007208694815635681\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007263101935386658\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007330732941627502\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00735749900341034\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007370947003364563\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007294127345085144\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007319602370262146\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071694451570510865\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007274176478385925\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007210164666175843\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007110422253608703\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007356730699539185\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073485666513443\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073448377847671505\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007307335734367371\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007506424188613891\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.00737384021282196\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007281955480575562\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007230742573738098\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007335065007209778\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072778302431106565\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007401421070098877\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007446857690811157\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073843830823898315\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072012859582901\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007312268614768982\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072739112377166746\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007190663814544678\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007234569787979126\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007278189063072205\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007282928228378296\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007323280572891235\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007328928709030152\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072476065158844\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007368184924125672\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072624868154525755\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007224082946777344\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007187037467956543\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007172512412071228\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007278892993927002\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007249607443809509\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007288385629653931\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007295912504196167\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007241212725639343\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007254493236541748\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007321174144744873\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00722123384475708\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00730126678943634\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007254562973976135\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007228708267211914\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007283530831336975\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007234091758728027\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007296174168586731\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007190171480178833\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007298461198806763\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007171907424926758\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007262498140335083\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007180356979370117\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007301567792892456\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007268025279045105\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007339637279510498\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007245504856109619\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007304078936576843\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007386763095855713\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007251739501953125\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007222703695297241\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007332294583320618\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007338745594024658\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007267072200775147\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007280417680740356\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072461187839508055\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00728775143623352\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00712070882320404\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007400662899017334\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007282959222793579\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007271724939346314\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.007210180163383484\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007196758389472962\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007277904748916626\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007164102792739868\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007242834568023682\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007237762808799743\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007263232469558716\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007420185804367065\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007277419567108154\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072383624315261845\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007341129779815674\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007304235696792603\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007234779000282287\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007400705814361573\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007274631261825561\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007249332070350647\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007316415905952453\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007226425409317017\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007208906412124634\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007129079699516296\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007429733872413635\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007334969639778137\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007338736653327942\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007310910224914551\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007110170125961304\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007180930972099304\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007167718410491943\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00723377525806427\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007209264636039734\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007180749177932739\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007223075032234192\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072300142049789426\n",
      "step 0: loss = 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.007260974049568176\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007196415066719055\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007259511351585388\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007204980850219727\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007175691127777099\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007355198860168457\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007260179519653321\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007289548516273499\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007284354567527771\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007151367664337158\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007101219892501831\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007191224694252014\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007347407341003418\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0071829754114151\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007315191626548767\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00720499038696289\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007183167338371277\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007284337282180786\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007221901416778564\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00726468563079834\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007129209041595459\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007161416411399842\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00723982572555542\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007255035638809204\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007394453883171082\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0073624557256698605\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0071368181705474855\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007242852449417114\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007218936681747437\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007200338840484619\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007431725263595581\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007292411923408508\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073581719398498535\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007193770408630371\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007197759747505188\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007190279364585876\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007229623198509216\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007244783639907837\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072666299343109135\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007235725522041321\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00716128945350647\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007265790104866028\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007327657341957092\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007260134220123291\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007244503498077393\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00720110297203064\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007222540974617005\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007198541164398193\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007178679704666137\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007191152572631836\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007220422625541687\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007244248986244202\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007124829888343811\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007256036996841431\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007284966707229615\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0073004794120788575\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007377609014511109\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007236313819885254\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007398825287818909\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007332656383514404\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007277780771255493\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007235889434814453\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007322424054145813\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007277777194976806\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007153581380844116\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007395657896995545\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007260737419128418\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007192705273628235\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007271875739097595\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007202872037887573\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007127479910850525\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007219282984733582\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007199362516403198\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00723578155040741\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007201935052871704\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007117578983306885\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007172671556472779\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007174871563911438\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007226212620735168\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007212378382682801\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007175317406654358\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007240655422210693\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007252257466316223\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072096014022827145\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007242506742477417\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007262443900108337\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007221964597702027\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007234991192817688\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007251266837120057\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007274569869041443\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007219684720039368\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007264725565910339\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007141712307929993\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007168959379196167\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007194243669509888\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007250417470932007\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007332873940467835\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007257475256919861\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007325487732887268\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007312778234481811\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071510404348373415\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007217616438865661\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007234075665473938\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007332297563552856\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00718121588230133\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007310112714767456\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007283096313476563\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007359589338302612\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007310953140258789\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073125135898590085\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072547620534896854\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007172958850860596\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007246249318122864\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0073308199644088745\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007175254225730896\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007271808981895447\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007192201018333435\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007304300665855408\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007255422472953796\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007261041998863221\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007180907726287842\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007227034568786621\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072883695363998415\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071443510055542\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007252936363220215\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007254382967948914\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007212727069854736\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007145769000053406\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007200858592987061\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072527027130126955\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007193437218666077\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007361852526664734\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007254827618598938\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007175590395927429\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007255858778953552\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007219061255455017\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007242769002914429\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007397842407226562\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007208079695701599\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007164991497993469\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007176395654678345\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072355085611343385\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007234799265861511\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007173300981521607\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007326506972312927\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007317734360694886\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007256816029548645\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007217885255813599\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007373933792114258\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007141285538673401\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007237583994865417\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007225280404090881\n",
      "step 0: loss = 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.007284278869628906\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00715767502784729\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007222236394882202\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007181307673454285\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007277373671531678\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007318930625915527\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007228391170501709\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007105883359909058\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007334537506103515\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007153111696243286\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071962857246398925\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007235568165779114\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007215235233306885\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007317765355110168\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007200872302055359\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007204765677452088\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007292532920837402\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007286049723625183\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007265218496322632\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007233999371528625\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007184135317802429\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007220521569252014\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007241888642311096\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007296521067619324\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007192267179489136\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00721677303314209\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007103344798088074\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007211189270019531\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007279075980186463\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007275232672691345\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007202188372611999\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007196147441864014\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007180954813957214\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007206429839134216\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0072400087118148805\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007202491760253906\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007214800119400024\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007198066115379333\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007208175659179687\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007179666757583619\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007186077237129211\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007193096876144409\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071942412853240965\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071358799934387205\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007292629480361939\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007235449552536011\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072481918334960935\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007270797491073609\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007176002860069275\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007212105989456177\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007276744842529297\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00720712959766388\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007338492274284363\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007082062363624572\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007168757915496826\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00720034122467041\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007248561382293701\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007138314247131347\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072668945789337155\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007166412472724914\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007199554443359375\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007093191742897033\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007124826908111572\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007155224680900574\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007298735976219177\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007201855778694153\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007101250290870667\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00714832067489624\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007329518795013428\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007233206629753113\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007108751535415649\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0073084598779678345\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007267347574234009\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071869069337844845\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007076453566551209\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007169507741928101\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007208539843559265\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007365317344665528\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072414886951446536\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007355800271034241\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007265669107437134\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0073082011938095095\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007322432994842529\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007233206033706665\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007228073477745056\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007240886688232422\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007163751721382141\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007186635732650757\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007186396718025207\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007233902215957642\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007162636518478394\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007207237482070923\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007316370010375977\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007182749509811401\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007148706912994384\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007199533581733704\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007063494324684143\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007218874096870422\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007275127172470093\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007271000742912292\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00724042534828186\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071878451108932494\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071701562404632565\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007230536937713623\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007141552567481994\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007232429385185242\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007164283394813537\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007233534455299378\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00727430522441864\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007177632451057434\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007152153849601745\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007165901064872741\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00721807599067688\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007131073474884033\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007143440842628479\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007205674648284912\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007236824631690979\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007273569107055664\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007329289317131043\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007165274024009705\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007229402661323547\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070715129375457765\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007251299619674682\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071435487270355225\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007129045724868774\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007318070530891419\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007224448323249817\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007258780002593994\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007175376415252685\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007200258374214172\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007250445485115051\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071428996324539185\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007178893089294433\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007204979062080384\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007189775705337524\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007100121378898621\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007245900630950927\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007150543928146362\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007243729829788208\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007143867611885071\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007126768231391907\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071324026584625244\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007281299829483032\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007238192558288574\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00722572386264801\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0072875916957855225\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007341262698173523\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007271171808242798\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007297031879425049\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007186742424964905\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007150676250457764\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007170566916465759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007084613442420959\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072765350341796875\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00717840850353241\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072084182500839235\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007270919680595398\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007113423347473145\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007109050750732422\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00721243441104889\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071212238073349\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071258538961410526\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007152566909790039\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007189176082611084\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007176584601402283\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007162790298461914\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007124680280685425\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007230540513992309\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007177801728248596\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007339293360710144\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007236513495445252\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0072807794809341434\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007145277261734009\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00715991735458374\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0072183054685592656\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007240944504737854\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007150459885597229\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007119341492652893\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071350401639938355\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007258461117744446\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007239931225776672\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072154909372329715\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007079383730888367\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007276219725608826\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007172826528549194\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071468549966812135\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007223962545394897\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007131581902503967\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007194263935089111\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007150212526321411\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007061596512794494\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007213067412376404\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0071822887659072875\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007167674303054809\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007186232805252075\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007115940451622009\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007177223563194275\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007132349610328674\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007247165441513061\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007098695039749145\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071937209367752076\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007128990888595581\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072882574796676635\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007214804291725159\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007310671210289002\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007184517979621888\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007144762873649597\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007204204797744751\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007166006565093994\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007481572628021241\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007218875885009766\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007078182101249695\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007248995900154114\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007254346609115601\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007155646681785584\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071748077869415285\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007339344620704651\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071397626399993894\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007158947587013245\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070982426404953\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00732904851436615\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007160519957542419\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007094477415084839\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0073615115880966185\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00718008816242218\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007145237326622009\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007193798422813416\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0072675347328186035\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007185840010643005\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007150018215179443\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007244457006454468\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00703121542930603\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007312430143356323\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007136685252189637\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007312589883804321\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007152403593063354\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007202393412590027\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00713245689868927\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007162266373634338\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007218636274337768\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007288166880607605\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007310820817947388\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007365160584449768\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007204927802085877\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007294802665710449\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007125825881958008\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071497315168380735\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007223193049430848\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007205606698989868\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007273716926574707\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007300133109092713\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0073655229806900025\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007157278656959534\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072022521495819095\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072006148099899294\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007209715843200684\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007213413119316101\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007239087224006653\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007208447456359863\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007208449840545654\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007111356854438782\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007199246287345886\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007213950753211975\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007276409268379211\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00712954044342041\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007185385227203369\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007259088754653931\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007106462717056275\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007073423862457275\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007183461189270019\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007097049951553345\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007202128171920777\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007162556052207947\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007087929844856262\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007162118554115296\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007262929081916809\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007201443314552307\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071969741582870485\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007200849652290345\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007179505228996277\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007263737320899963\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070768028497695925\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00717025637626648\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007277971506118775\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007307068109512329\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00716225266456604\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007236562371253967\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007204504013061524\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007248865962028503\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072309130430221556\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007101196050643921\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007228028178215027\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007298293113708496\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007180615663528443\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00723085880279541\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007116057872772217\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007183231115341186\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007196933031082153\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007183113694190979\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007228132486343384\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007114394307136535\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007288920879364014\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007118932008743286\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007095915675163269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007088668346405029\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007117195129394531\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007181736230850219\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007123434543609619\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007120313644409179\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007272140979766846\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007251309752464294\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007267163395881653\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007274624109268189\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0073009192943573\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007128223180770874\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007181137204170227\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007286390662193299\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007243632078170776\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0073079907894134525\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007245160937309265\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007255789041519165\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007043866515159607\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071373856067657475\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007067996859550476\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007151862382888794\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007205523252487182\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007162134051322937\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007118692994117737\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007205922603607178\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007107944488525391\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007172672152519226\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00715910017490387\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007099775671958923\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007103949785232544\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007188875675201416\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007265104651451111\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00732351303100586\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007188549637794495\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007250124216079712\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0072114825248718265\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007107592225074768\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00723556935787201\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007171400785446167\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007210030555725098\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007275140881538391\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007182271480560303\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007184016108512878\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072473323345184325\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007222306728363037\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007240818738937378\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007228031158447266\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007185467481613159\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007155827283859253\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007281457781791687\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071662431955337525\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0071773135662078855\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072012126445770265\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071599280834198\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007291564345359802\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007157771587371826\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007277271747589111\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071575212478637695\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007153881788253784\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007161707282066345\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007170397639274597\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007302369475364685\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007291352152824402\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00721143126487732\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007158790230751038\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007190250754356384\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007216249108314515\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007360453009605408\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071835356950759885\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007149062156677246\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007179325819015503\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00722145676612854\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007100616097450257\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0072248905897140505\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007204298973083496\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007188283205032349\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.0071330821514129636\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007172613143920898\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007224858403205871\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007083964943885804\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071232026815414426\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007263100743293762\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00719079852104187\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007282965779304504\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007167039513587952\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007192256450653076\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007079119682312012\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007187278866767883\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0072407954931259155\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007148596048355102\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007204618453979492\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007211835384368897\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007147207260131836\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007250185012817383\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00711452841758728\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007142859697341919\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007330061197280884\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007265403866767883\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007166558504104614\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007198975086212158\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0071290600299835204\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007065573930740357\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007206172347068786\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071705770492553715\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007021883726119995\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007173665165901184\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070643675327301024\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007157196998596191\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007154887318611145\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007062373161315918\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007141141891479492\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007192720770835877\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007116758823394775\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007250220775604248\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007210033535957336\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007122232317924499\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007139842510223388\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007200467586517334\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007259420156478882\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007197549939155579\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00714356005191803\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007127434611320495\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007144293785095215\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007128427028656006\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007309534549713135\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007260538935661316\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007184713482856751\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007174343466758728\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00726431131362915\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007233396768569946\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007178598046302795\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007114920020103455\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007229730486869812\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070707380771636965\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007127788662910461\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007295334339141845\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00715307354927063\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007139507532119751\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071078366041183475\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007141627073287964\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007163749933242798\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007266647219657898\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007249993681907654\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007106623649597168\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007206255197525024\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071401834487915036\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007181238532066345\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007210683226585388\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007264301776885986\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007032608985900879\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007218105792999268\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007139866948127746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007117990851402283\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007118674516677856\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007232027649879455\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007204571962356568\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071440738439559935\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007100012302398682\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007136197090148926\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007200296521186828\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007073160409927368\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007135769724845887\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007217938899993896\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007226162552833557\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007068595886230469\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00703535258769989\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007222074270248413\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007149312496185303\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007119871973991394\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0071729934215545655\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007088124752044678\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007140351533889771\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00720939040184021\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007204748392105102\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007172987461090088\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007040833830833435\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007161173224449158\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007189259529113769\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007218560576438904\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007302300930023193\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007204693555831909\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007186240553855896\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007119426727294922\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007075691819190979\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071618276834487914\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007118090391159058\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007100707292556763\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070689040422439575\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007077180743217468\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007213804125785828\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007305960655212402\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007140371799468994\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071407341957092285\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007192886471748352\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007129748463630676\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007100975513458252\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007246266603469848\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00714814305305481\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007122900485992432\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007178159952163696\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007032662630081177\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007105154395103455\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007347168326377869\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007197536826133728\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007257874011993408\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.0072575992345809935\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007295393943786621\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007195307016372681\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007245367169380188\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007304320335388184\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007167612910270691\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007158749103546143\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007270362973213196\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072236210107803345\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007127302289009094\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007063669562339783\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007103546261787414\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071449875831604\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007287489175796509\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007166407108306885\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007062729597091675\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072015637159347536\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007312309145927429\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007154172658920288\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007098789811134338\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007156969904899597\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007105907797813416\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007237863540649414\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007163493037223816\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007123872041702271\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070623081922531125\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007118027806282044\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007133212089538574\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072118031978607175\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007128308415412903\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007066108584403992\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007112534642219543\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007160073518753052\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007178480625152588\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007094148993492127\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007178163528442383\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070890140533447265\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007208004593849182\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007106136679649353\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007158558964729309\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071495682001113895\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007145483493804932\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072403961420059205\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071494287252426144\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007126526832580566\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007089700102806091\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007131044268608094\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007101486921310424\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007164261937141418\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007147415280342102\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007008966207504273\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00714926540851593\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007102340459823608\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007138131260871887\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00714800238609314\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007174407243728638\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007214097380638123\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007112752199172973\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007274816632270813\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007264856696128846\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007106960415840149\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007100484371185303\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007147538065910339\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007172029018402099\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007045493125915527\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007204015254974366\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007075918912887573\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00721129834651947\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007154446840286255\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007113646864891052\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007089954018592835\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007076342701911926\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071706193685531616\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007178381085395813\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071115845441818235\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00712597668170929\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0071212702989578245\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0072133708000183105\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007171152830123901\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007103113532066345\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071611529588699345\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007181155085563659\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007137184143066406\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007124519944190979\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007135617733001709\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071824765205383305\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007188913822174073\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0069797754287719725\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007044100761413574\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007026727199554443\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00727662980556488\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007070582509040833\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007183312773704529\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007136427164077759\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007075874209403992\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007211823463439942\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0071884095668792725\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071355682611465455\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007197808027267456\n",
      "step 0: loss = 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.00706695020198822\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007126185297966004\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007191649675369263\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007214884161949158\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007128168344497681\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007218003869056701\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007209978103637695\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007259039282798767\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007164142727851867\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007094274759292602\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007230829000473022\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007186207175254822\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00709056556224823\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007023504376411438\n",
      "step 0: loss = 0.0058\n",
      "test_loss: 0.007137428522109985\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007098371386528015\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007189568281173706\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007085736393928527\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007097010612487793\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007150013446807862\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007063370943069458\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007020670771598816\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007287939190864563\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007109224796295166\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00713931679725647\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0073512673377990724\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007136524915695191\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007222731709480286\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00711704671382904\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070421302318573\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007136255502700806\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007134716510772705\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007227206230163574\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007222182750701904\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007170014381408692\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007285946011543274\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007086549997329712\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007076711058616638\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007017482519149781\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007210121154785156\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007109562754631042\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070263296365737915\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007094542384147644\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007066852450370789\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007135232090950012\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007201152443885803\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007173391580581665\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007035554647445679\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007160441279411316\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071017897129058835\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00709244430065155\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007267371416091919\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007132556438446045\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007052048444747925\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007180085182189941\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007121079564094543\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007103860378265381\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007101441621780395\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007079981565475464\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007101049423217773\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071129328012466434\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00707335352897644\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071910214424133305\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007168204784393311\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007282360196113586\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007049465179443359\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006993080973625183\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007119269371032715\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007000998258590698\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007146156430244446\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007009565830230713\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007104596495628357\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007077531814575195\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007164515256881714\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0072196096181869505\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007196413874626159\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007119807600975037\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007079705595970154\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007233254313468933\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007091557383537292\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007108148336410523\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007136422395706177\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007170165777206421\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007071219086647033\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007146661877632141\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007148971557617187\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007109835147857666\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007170708775520325\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007047159671783447\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007107565402984619\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071537792682647705\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007075161933898926\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007168908715248108\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007263496518135071\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007304375171661377\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0071141237020492555\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071402621269226075\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007119619250297546\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007098596096038818\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0070244473218917846\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007158966660499573\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.00709561288356781\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007158098816871643\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007199702858924866\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070953649282455445\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007177360653877259\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007086911201477051\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00726041316986084\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00709561288356781\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007264281511306763\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.0071519452333450315\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007026738524436951\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071484845876693725\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007201826572418213\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007067978978157043\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007122336626052856\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007128937840461731\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007170215845108032\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070858198404312135\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071992605924606325\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007157414555549622\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007136973142623901\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007152215242385864\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007154316902160645\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007075769901275635\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007200117111206055\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007094280123710633\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007120364308357239\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007219242453575134\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007251598834991455\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007122639417648315\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007083197236061096\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007120652198791504\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00719999372959137\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0069933199882507326\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071075439453125\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007091415524482727\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007144463062286377\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0071053171157836915\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007090487480163574\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067370414733887\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007099339365959167\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007168317437171936\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007019969224929809\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007035179734230041\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007101895809173584\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072890353202819825\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070757436752319335\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007072818279266357\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007063287496566773\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071184831857681275\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070034158229827885\n",
      "step 0: loss = 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.007148106694221497\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071296805143356325\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006973568201065063\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007130130529403687\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007172419428825378\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007152055501937866\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007161804437637329\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007267546653747558\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007155967950820923\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007232142686843872\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007115540504455567\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007099190354347229\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007094418406486511\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007087306380271912\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071023541688919065\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007169934511184692\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007039833664894104\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007007317543029785\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00713244378566742\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071819543838500975\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00719164252281189\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007218233942985534\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00714697003364563\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071770745515823365\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0072225022315979\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007057691812515259\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00704094409942627\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007048513293266296\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007128649353981018\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071502143144607545\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071568465232849125\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007195103168487549\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007199451923370361\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007133853435516357\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007033133506774902\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007098936438560486\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006983805894851685\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007087386250495911\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00717333972454071\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007189322710037232\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071314918994903565\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00711969256401062\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007041311264038086\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007151811718940735\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007293658256530762\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007089787125587463\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007099352478981018\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007170562744140625\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070803451538085935\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070970308780670165\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00704861044883728\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007079459428787231\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007033311128616333\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007019311785697937\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007098284363746643\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007069171667098999\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007086970210075379\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007155598402023316\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007159413099288941\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007154795527458191\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007135046720504761\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071695268154144285\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007073450684547424\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007126176953315735\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007142651081085205\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007359967231750488\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007199928164482117\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007135841846466064\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007076653838157654\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006994811296463013\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007196863293647766\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00706334114074707\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007097447514533997\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007063764333724976\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007144830226898193\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007074655890464783\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070521897077560425\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007045962810516357\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007128455042839051\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0071546387672424315\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007159833312034607\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00699714720249176\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007122600674629212\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007198716402053833\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007083823084831238\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007230910062789917\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007051331996917725\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070875191688537596\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007048015594482422\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007099742293357849\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007291783690452576\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007192287445068359\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007154667973518372\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006989594697952271\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007188073992729187\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.0071717602014541625\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007020413875579834\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007096002697944641\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007129637002944947\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007206448912620544\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007188162803649902\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007085673809051514\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071541392803192135\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007027817964553833\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007078792452812194\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007121085524559021\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00704633116722107\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071303462982177735\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007026069760322571\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071372342109680175\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007118103504180909\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070997333526611325\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062315344810486\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007038219571113586\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007150182127952575\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007095623016357422\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0072136855125427245\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007142636775970459\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007117842435836792\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0071451389789581295\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007112045288085938\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007155151963233948\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0072356462478637695\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007288178205490112\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007187958955764771\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007151486873626709\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007134294509887696\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007142755389213562\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007175682783126831\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007017025351524353\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007102630138397217\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00714350163936615\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007162129282951355\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007039172649383545\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007231645584106446\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007155494689941406\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007181371450424194\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007158027291297913\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007184731364250183\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00706231415271759\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007187249660491943\n",
      "step 0: loss = 0.0073\n",
      "test_loss: 0.007151238918304444\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007050889134407043\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007147877216339111\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007187466621398925\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007102178931236267\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071670860052108765\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007101062536239624\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007035176753997802\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070211273431777955\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007090306878089905\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007107452154159546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007118214964866638\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007167964577674866\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0071815353631973266\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006991901397705078\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007189565300941467\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007079840898513794\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007191955447196961\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007123261094093323\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007105764746665954\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007084302306175232\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007075803875923156\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007054941058158875\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070797944068908695\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007207038402557373\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007148467898368835\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007044929265975952\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007238890528678894\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007068529129028321\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007119384407997131\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007048675417900085\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007128153443336487\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007119448184967041\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007018373608589173\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007239009141921997\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007112010717391968\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007172034978866577\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007085435390472412\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007082001566886902\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00708841323852539\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007201281189918518\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007139737606048584\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007047984004020691\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007029536962509155\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007013540863990784\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0072447478771209715\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006994967460632324\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00716941237449646\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007076120972633362\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007181640267372131\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007057973742485046\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070693731307983395\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007131165862083435\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007150032520294189\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00693203330039978\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070741397142410276\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007151126861572266\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00712521493434906\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007174025774002075\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007022705674171448\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007229559421539307\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070950031280517575\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00707294225692749\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0072476094961166386\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00706480324268341\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007087380290031433\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071272927522659305\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007154557704925537\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007059268355369568\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007082104682922363\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007083156108856201\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070675045251846315\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007127813100814819\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007102739810943603\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007077218294143677\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007293103337287903\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00723336398601532\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007113283276557922\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007130789160728454\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007092379927635193\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007126604914665222\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007048227787017822\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00717939019203186\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007039080262184143\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007047963738441468\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007097742557525635\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070369565486907955\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007143754959106446\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007129456996917725\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007057228088378906\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007080993056297303\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007032011151313782\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007185842990875244\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070760524272918705\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007175725698471069\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007046450972557068\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007096509933471679\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007119658589363098\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007149670720100403\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007066482305526733\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.00717160701751709\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007187343835830688\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007000503540039063\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00708527684211731\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007168809175491333\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071032303571701046\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007053276896476746\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007171661257743835\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007205536961555481\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007148253321647644\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007112144827842713\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007170924544334411\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007181823253631592\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072126567363739015\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007106397151947021\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007108538746833802\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007013329267501831\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007036597728729248\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007184039950370789\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007073072791099548\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071034830808639525\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007156980633735657\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007074189186096191\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070839041471481325\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00716446578502655\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007033731937408447\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007074389457702637\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007094569206237793\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071553832292556765\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007195112705230713\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007052739858627319\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006997332572937011\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007104625105857849\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00708884060382843\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007182801961898804\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007047445774078369\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007146784663200378\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00705671489238739\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007055804133415222\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00700233519077301\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007052564024925232\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070054358243942265\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007104119658470154\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007068620920181274\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007102584838867188\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007122958898544311\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007058703303337097\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007104663848876953\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007081776261329651\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007148367166519165\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00699837327003479\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007170991897583008\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00722866415977478\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007018826603889465\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007023520469665527\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007241402864456177\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007001096606254578\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007034207582473755\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007131264209747314\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0071664929389953615\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007100722789764404\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007026011943817139\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007068650126457215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007135406732559204\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007026495337486267\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007119653224945069\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007051026821136475\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007069064974784851\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007107229828834534\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067221403121948\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007129796147346497\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006998395323753357\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007142983078956604\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007081297636032105\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.00708304762840271\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007171440124511719\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071115452051162716\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007251394391059876\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007111252546310425\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007006093859672546\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007180189490318298\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00706852376461029\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007114649415016174\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070768141746521\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007097774147987366\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007097641229629517\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007104713916778565\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007061992287635804\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007031255960464477\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007127345204353332\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007095907926559448\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007204870581626892\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006965541243553162\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071052086353302\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007061882019042969\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006966000199317932\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006983436942100525\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007163145542144775\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007150804996490479\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007044544219970703\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007103893756866455\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070771616697311406\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007050013542175293\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007112786769866943\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007101686596870422\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007178866267204285\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007115855813026428\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007074156999588013\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00701526939868927\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007061347961425781\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007131984233856201\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007098443508148193\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007056906819343567\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007095758318901062\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007057511806488037\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007058982849121094\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007238627672195435\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007089812755584717\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007065584659576416\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007096018791198731\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00703807532787323\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007159923911094665\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007088366746902466\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007170302867889404\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007078686952590943\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006978892087936402\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00706580638885498\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007066463828086853\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007137396335601807\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070956707000732425\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007045780420303345\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070508611202239994\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007274273633956909\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007043654322624207\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007123258113861084\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067019939422607\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007097975611686707\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007100542187690735\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070566624402999874\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069909518957138065\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006983808279037476\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007074761986732483\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00715093195438385\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007109771370887756\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007044513821601868\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007085270285606384\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007057716250419617\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007117863297462463\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007070539593696594\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007109777331352234\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007082481980323792\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007128834128379822\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007194805145263672\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007146974205970764\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007161630392074585\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007175523042678833\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00704318642616272\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007050054669380188\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007020075917243958\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007131096720695495\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007140128016471863\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071397054195404056\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007034550309181213\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00705312192440033\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007012166976928711\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007134816646575928\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071223235130310055\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007176737785339355\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007181287407875061\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007146164178848267\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007026360630989075\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00708521842956543\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007113581299781799\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007031157016754151\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007229486703872681\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007197067737579345\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007037553787231445\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006921146512031556\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007143744826316833\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007187492251396179\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007161685824394226\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070749825239181515\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00709258496761322\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007094951868057251\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007049546837806702\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007046196460723877\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007014760375022888\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007050921320915222\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007026890516281128\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007001721262931824\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007125523090362549\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007122788429260254\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007104389667510987\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00713032603263855\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007154261469841003\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070517373085021975\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007034634947776794\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007150042653083801\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007133209705352783\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007032859325408936\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007065222263336181\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007095133066177368\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007071854472160339\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007150018215179443\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00716412365436554\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007122555375099182\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007101229429244995\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007021682262420654\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007192479372024536\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007017045617103577\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007093487977981567\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007069692611694336\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006959110498428345\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007057200074195862\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007069478631019592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007034664750099182\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007189445495605469\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.0070099538564682\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007156102657318115\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007137086391448975\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007045384049415588\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007019435167312622\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007122959494590759\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00704383134841919\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006982791423797608\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070962607860565186\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00710097849369049\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007111571431159973\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007111772894859314\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007121503949165344\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007083995938301086\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007133997082710266\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007151498198509216\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007116633653640747\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00700225293636322\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007057071328163147\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007058408260345459\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007131693363189698\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007004826664924622\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071295368671417236\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007021356225013733\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007040601968765259\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007065568566322327\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070691508054733275\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007075456380844117\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007165388464927674\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007056974172592163\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007052971720695495\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007257753610610962\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070365267992019654\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0071040141582489015\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007081841230392456\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007098042964935302\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007020211219787598\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007097592353820801\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007194520235061646\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006999967694282532\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007097367644309998\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007092850804328918\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007060278058052063\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007161229252815247\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006998942494392395\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007038605213165283\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007064176797866821\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007119952440261841\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007100293040275573\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007043139934539795\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071046602725982665\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006985607743263245\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007015276551246643\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007050897479057312\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007054968476295471\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007107568383216858\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007159668803215027\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007241714596748352\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007059577107429505\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070528948307037355\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007114120125770569\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007094097137451172\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007114190459251404\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007057955861091614\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007031313180923462\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.00706455409526825\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00713212251663208\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007072386741638184\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070546561479568485\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0069596368074417115\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007019925713539123\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007094143033027649\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007100191116333008\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007044275403022766\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007166366577148437\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070981991291046145\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007112323641777039\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007116525769233704\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007037953734397888\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007129499316215515\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00697393536567688\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007100355625152588\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007054944038391114\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007162423133850098\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00700644314289093\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007176370620727539\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007030259370803833\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0069421398639678954\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007105706334114075\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007018498182296753\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007059023380279541\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007060489654541016\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007106983661651611\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071493834257125854\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007024569511413574\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0071329808235168456\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007129850387573242\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007137511968612671\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007099387645721436\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007134398818016053\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007187082767486573\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006980354189872742\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006969082951545715\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007131488919258118\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007161686420440674\n",
      "step 0: loss = 0.0072\n",
      "test_loss: 0.007088297605514526\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007107516527175903\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006983792185783386\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006985816359519959\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007133408188819885\n",
      "step 0: loss = 0.0071\n",
      "test_loss: 0.007133457660675049\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006998488306999206\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007152060866355896\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007130255699157715\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070139050483703615\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006945009231567383\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006951228380203247\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007067837715148926\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007079590559005738\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007129007577896118\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007026301622390747\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007211335301399231\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007110351920127869\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007053155899047852\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070565807819366454\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007093885540962219\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070347261428833005\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070259982347488405\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007072824835777283\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007008799910545349\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007168989777565003\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070882105827331544\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00713361918926239\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071290540695190426\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00701907753944397\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00707001805305481\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007089287638664245\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007106902003288269\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007154951095581055\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00711394190788269\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007046857476234436\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070773279666900635\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007076919674873352\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007094191908836364\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070700782537460325\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006981464624404907\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0069883960485458375\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070593696832656865\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007038688063621521\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070969581604003905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006987430453300476\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007105467319488526\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007133679389953613\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071617597341537475\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007031846046447754\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007006741762161255\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007147594690322876\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071385037899017335\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070074242353439335\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007119261026382447\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007031545639038086\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007166115045547486\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007028471827507019\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062638401985169\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007099561095237732\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007068392038345337\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007225245237350464\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007063790559768677\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007206600308418274\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00704982578754425\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007112007737159729\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007016080617904663\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007130995988845825\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007124860286712647\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00710324227809906\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007078295946121216\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007104569673538208\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006935980916023254\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007087687849998474\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070017480850219724\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007047847509384155\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007064049243927002\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071005111932754515\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00705074667930603\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007125172615051269\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070768558979034425\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069727015495300295\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007134301662445068\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007143563628196716\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007038342356681823\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069802385568618775\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007089287042617798\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007038978934288025\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00703562319278717\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071489554643630986\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007066282033920288\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062502503395081\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007133898735046387\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007052795290946961\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007067899703979492\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070206946134567265\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006955927014350891\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070760250091552734\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007022382616996765\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070692265033721925\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007044904232025147\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007099881172180176\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00709520161151886\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007056567668914795\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007129439115524292\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007139714956283569\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007114334106445313\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00706984281539917\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007136409878730774\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007012985348701477\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007049047350883484\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007178096771240234\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007155642509460449\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006997914910316467\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007020280957221985\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007105947732925415\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007144960165023803\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007055490016937256\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007052237391471863\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007058819532394409\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007005407810211182\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00712601900100708\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007043479681015014\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070528477430343624\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00701292872428894\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00715544044971466\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070125538110733035\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006999422907829285\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00705613911151886\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007084393501281738\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007189854383468628\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070193582773208614\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007053806781768799\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0071284502744674684\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007020955681800842\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007045789361000061\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007090970277786255\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007215877175331116\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007009491324424744\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006917865872383118\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00710468590259552\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0071288210153579714\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070742970705032346\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007151151895523071\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007127416729927063\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007119625210762024\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007015822529792786\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007073259949684143\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007087347507476807\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070197761058807375\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007041351199150086\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007051536440849304\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006982510089874268\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007123834490776062\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0069563728570938115\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007022692561149597\n",
      "step 0: loss = 0.0058\n",
      "test_loss: 0.007099487185478211\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006965131759643555\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007035048604011536\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067583799362183\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007162386775016785\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006975530385971069\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007062371969223023\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007012342810630798\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.006907395720481872\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007051471471786499\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007050004005432129\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070089328289031985\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007054520845413208\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007033081650733948\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007010720372200012\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007161591053009033\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007076292634010315\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007022783160209656\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007011170983314514\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007071877717971802\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007097953557968139\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007139614224433899\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007084116339683533\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007026230692863464\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007100471258163452\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007082450985908508\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007109934091567993\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007031238675117493\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007143325209617615\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006956155300140381\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007006913423538208\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006950050592422485\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007057833075523376\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006992795467376709\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067282795906067\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070217764377593994\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00704497754573822\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007057783007621765\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007067456245422364\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0071101409196853635\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006997500658035278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006985004544258117\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069847780466079715\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007022766470909119\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007020527720451355\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007048904895782471\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062922716140747\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007141086459159851\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007056018114089966\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007056000828742981\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007026289701461792\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006980472207069397\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007074512243270874\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007065949440002442\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007070410847663879\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070761370658874514\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007127672433853149\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007128627300262451\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007027390003204345\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007112141847610474\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007077251672744751\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007018983364105225\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007042596340179444\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006970312595367432\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006989290118217468\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007029427289962769\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007011706829071045\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006967554688453674\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00709696352481842\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00710711121559143\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007039493322372437\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007201250791549683\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00691330373287201\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006998611092567444\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007128172516822815\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007111693024635315\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007039667963981628\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007006999850273132\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007023405432701111\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007029985189437866\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007111546993255616\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007063852548599243\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007082246541976929\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007137482166290283\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062165737152099\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006996942758560181\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007027623653411866\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007079265713691711\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007032898068428039\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070396530628204345\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00707574725151062\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007084791660308838\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006932266354560852\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006948974132537842\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007051576375961304\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007080340385437011\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00700336754322052\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007039310336112976\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006994986534118652\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007040216326713562\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007080129384994507\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006996276378631591\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007103526592254638\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007036811113357544\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006977323293685913\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007076784372329712\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007145095467567444\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.0070501226186752315\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007013203501701355\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00704257071018219\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007050557136535645\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006955838799476624\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006946138739585876\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007112101316452026\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006960307955741882\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007088240385055542\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007022704482078552\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007027488946914673\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007008793950080872\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00703696608543396\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006976886391639709\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007019623517990113\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007007297277450562\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007014895081520081\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007083941102027893\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007079417705535889\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006987048387527466\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007122350335121155\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006982454657554626\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006970658898353577\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006981115937232971\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007044222950935364\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007108032703399658\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00705810546875\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007108436822891235\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007013557553291321\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007094960808753967\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00707309901714325\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007030174136161804\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007093276977539063\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007065491676330566\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007061669826507569\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007061983346939087\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007048223614692688\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007056335210800171\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0072017496824264525\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007021159529685974\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007014701366424561\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006970472335815429\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007039628624916076\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007050312757492065\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00694281816482544\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006972509026527404\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007054197192192077\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007073670029640198\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007042454481124878\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007042348384857178\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006921036243438721\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006993461847305298\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006999209523200989\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007014769911766052\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007067739963531494\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007059823274612426\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00711809515953064\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006988046169281006\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007054489254951477\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007044219374656677\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006902852654457092\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007024092674255371\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007007394433021546\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070123571157455445\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070261162519454955\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007010541558265686\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007004697918891907\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007021956443786621\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007024344205856323\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007012958526611328\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00702946126461029\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007126147747039795\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00710303544998169\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007016829252243042\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007071380615234375\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007074965238571167\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007107493877410889\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007111868858337402\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007035591006278992\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007063797116279602\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006989569067955017\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007095483541488648\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007069979906082153\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007079463601112366\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007103944420814514\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007160218954086303\n",
      "step 0: loss = 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.006966246962547302\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007041746377944946\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00695745050907135\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006996049284934997\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006998875141143799\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006998748183250427\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007036427259445191\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007074309587478638\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007033665776252747\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006999208331108093\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006966820955276489\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00700967013835907\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007016467452049255\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007168960571289062\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00699995756149292\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007131304740905762\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006984120011329651\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007054160237312317\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070281559228897094\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0069771182537078855\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006959552764892578\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007035857439041138\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006986644864082336\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006968801021575928\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007065702080726623\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006942736506462097\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007070351839065552\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006998934745788574\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070057171583175655\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007076753377914429\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007000248432159423\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006991648077964783\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070364314317703245\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006998247504234314\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070938456058502195\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007062556147575378\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007245163321495056\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006985411047935486\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007149321436882019\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006997067332267761\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007017863392829895\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007127457857131958\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006982009410858154\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007092737555503845\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007046860456466675\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007059769034385681\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006974394917488098\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007050164937973022\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007038241028785705\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006997454166412354\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007078050971031189\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070398634672164916\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006929935216903687\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006969972252845764\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070176184177398685\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007015762329101563\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007053725123405456\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007039982080459595\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007018688917160034\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070428413152694705\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007037058472633362\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00707032024860382\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007025764584541321\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007000491619110107\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007088704109191895\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070469027757644655\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007002702355384827\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007084043025970459\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006982139348983765\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007081711888313294\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007136006355285645\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006930816769599914\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006928997635841369\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007076267004013061\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0071069467067718505\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0069978266954422\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070482462644577025\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007099355459213257\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007086140513420105\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007075849771499634\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006980026960372925\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006975553035736084\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0069799405336380006\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070006722211837765\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007023196220397949\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007012915015220642\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007060538530349731\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00707977294921875\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007058528661727906\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006968660354614258\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006987559795379639\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007037353515625\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069668394327163695\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007031347751617432\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007025729417800903\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007009050250053406\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0071203458309173585\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007009709477424622\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.007071362733840942\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00708093523979187\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006987976431846618\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007007066607475281\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007009595036506653\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006967863440513611\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007003501653671264\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070407378673553464\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007002923488616943\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007056958079338074\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007090601921081543\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007073933482170105\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006875885725021362\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007032449245452881\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006968815326690674\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007034370303153991\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00701080322265625\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006987366676330566\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0069859051704406734\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006977711915969849\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007024136185646057\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006997979879379272\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006974133253097534\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070778453350067135\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069991803169250485\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006961076855659485\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007060754895210266\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006989192366600037\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007052742242813111\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007048169374465943\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007072877287864685\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007016246318817139\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006977049708366394\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007068014144897461\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070356899499893185\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006950529217720032\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007001863718032837\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007098728418350219\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007032038569450378\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.007021397948265075\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006958057880401611\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007064067721366882\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069888848066329955\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007038688659667969\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007020858526229859\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00717168390750885\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006911824345588684\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006964616775512696\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006983851790428161\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070088768005371095\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00704264223575592\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007122966051101684\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007068668603897095\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007086684703826904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070181721448898315\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007042770385742188\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069933515787124634\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00703650951385498\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007051728963851929\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00699335515499115\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007127501368522644\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006936307549476623\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007038989067077637\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007152613401412964\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00696435272693634\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006983663439750671\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007034767270088196\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.006943516731262207\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006917015910148621\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007020125985145569\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007040620446205139\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007029950022697449\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007048380374908447\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007030305862426758\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007037601470947266\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0069904494285583495\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007025997042655945\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069353306293487545\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006956669688224793\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007154436707496643\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007051243782043457\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007016899585723877\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007064778208732605\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007111026048660278\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006974229216575622\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007038056254386902\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00699393093585968\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006961717009544372\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007039127349853516\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007040880918502808\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007003189921379089\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006981706619262696\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007030596137046814\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069860172271728515\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006979796886444092\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007012623548507691\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007030893564224244\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.00712824285030365\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007081058621406555\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070244306325912475\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006954579353332519\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0069768762588500975\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006924847960472107\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007018594145774841\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006991211175918579\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070706260204315185\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007011308670043946\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007059755921363831\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007063238620758056\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007098990082740783\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0069707494974136355\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00703981876373291\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070592820644378666\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0069888514280319215\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006999367475509643\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007002142667770386\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007024787068367004\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00707065224647522\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.006902930736541748\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007033705115318299\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006974815726280213\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007000647783279419\n",
      "step 0: loss = 0.0058\n",
      "test_loss: 0.007089226245880127\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006998707056045533\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070955193042755126\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00701742947101593\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006974836587905884\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007010197639465332\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006988958120346069\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006999189257621765\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007004992961883545\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00702489972114563\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069944971799850465\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007005909681320191\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007088207006454468\n",
      "step 0: loss = 0.0069\n",
      "test_loss: 0.006993001699447632\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007074753046035767\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006888192892074585\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00700819194316864\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007062233090400696\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007016599774360656\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007033112049102783\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00696651816368103\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00692809522151947\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007099459767341614\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007066300511360169\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007025678157806397\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.00701913058757782\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006970146298408508\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007030207514762878\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006985187530517578\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006947020888328552\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070357429981231685\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006935394406318665\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.0070944100618362425\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007083582282066345\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006916194558143616\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006959867477416992\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007004321217536926\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007044744491577148\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007055124640464783\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007049989700317383\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007003215551376343\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007045400738716126\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007062040567398072\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007029409408569336\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006893358826637268\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00701139509677887\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069909882545471196\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007037211656570435\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006970186829566956\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070512348413467405\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007067689299583435\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007095610499382019\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0070278322696685795\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0069483727216720585\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070228767395019535\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007018636465072631\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007072910666465759\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007035748958587646\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007091495990753174\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007017374038696289\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070381444692611695\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0070522260665893555\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006993361711502075\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007006837725639343\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006969401240348816\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007029125690460205\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070504707098007205\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0071297425031661985\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007135462164878845\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006911834478378296\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007066713571548462\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070652908086776735\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007018768191337585\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00700471580028534\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007050474286079407\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007025191187858581\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007045338749885559\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007063261270523071\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006961645483970642\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007029210925102234\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007035413980484009\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007145032882690429\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00700217604637146\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007152072191238403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007069270014762878\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007030076384544373\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007072692513465881\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006982313990592956\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070342087745666505\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00696378767490387\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007054601311683655\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007034944891929626\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007093643546104431\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006941607594490052\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006901085972785949\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007105556726455689\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006955658197402954\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00704873263835907\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007033311128616333\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007001749277114868\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007088199257850647\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007029955387115479\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069784802198410035\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006986186504364013\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069205456972122196\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007025901079177856\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00702285349369049\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007072438597679138\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007035583257675171\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0070171809196472165\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.0070511060953140255\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007198845148086548\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00702728271484375\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070256352424621586\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007023417353630066\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006957323551177979\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006964042782783508\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006949953436851501\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007010610699653625\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007007129788398743\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00706479549407959\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006961632370948791\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007056156992912292\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006986136436462402\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006964042782783508\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069994497299194335\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006993122696876526\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007043406963348388\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007063018679618835\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00703310489654541\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007043500542640686\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007117704749107361\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00701241135597229\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006919923424720764\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069586396217346195\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007031303644180298\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007087790966033935\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006951737403869629\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00687255322933197\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00699758768081665\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007018304467201233\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007048841118812561\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006968359947204589\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.0071250319480895994\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007063618302345276\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007071684598922729\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007003354430198669\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007068901658058167\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007016516923904419\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007078054547309876\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.00699731707572937\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006928597092628479\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007009170055389404\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0069673091173172\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006935839653015137\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006998491287231445\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006940072178840637\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007051002979278564\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006954674124717713\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007039836049079895\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006977716684341431\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00698452889919281\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070153862237930294\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006931407451629639\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006998607516288757\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006996538043022155\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006997094750404358\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007011743187904358\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007043100595474243\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007122507095336914\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007089458703994751\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006928747892379761\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007084039449691773\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006896709203720093\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007011516690254211\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007169066071510315\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006952236890792846\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007082512378692627\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006988012790679931\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006996944546699524\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006944524049758911\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006916407346725464\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006976543664932251\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007019915580749512\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0069939917325973515\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006958708167076111\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007043336629867554\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070081609487533565\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006986692547798157\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007041496634483338\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006978508830070495\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069264787435531616\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006984474062919617\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.006958369016647339\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070464849472045895\n",
      "step 0: loss = 0.0070\n",
      "test_loss: 0.007077080011367798\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.006982730031013489\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007030865550041199\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007017800211906433\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006906813383102417\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007042935490608216\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007004298567771912\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007003901600837708\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.00697335422039032\n",
      "step 0: loss = 0.0058\n",
      "test_loss: 0.0069876909255981445\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007045481204986572\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0069650644063949585\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00699865460395813\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006993280053138733\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007010946273803711\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007006602883338928\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.007040139436721802\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00692872405052185\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007054373621940613\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006942007541656494\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007098670601844787\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006930241584777832\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007138620018959045\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007027121186256409\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007062956094741822\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0070133405923843385\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.00693311333656311\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070915788412094114\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006936533451080322\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006968188881874084\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069391226768493654\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006972170472145081\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006948968172073364\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007001866698265076\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007006864547729492\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007065168023109436\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007055593729019165\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006973106265068054\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006978085637092591\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006918652653694153\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007006739974021911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 0.0059\n",
      "test_loss: 0.007018402814865112\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006974183320999146\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007028198838233948\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007010753154754639\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006989938616752625\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006944034099578857\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069385749101638795\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006959058046340942\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007022362947463989\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006914392709732055\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.006998027563095093\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.007120726108551026\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006988462209701538\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.0069773197174072266\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006948070526123047\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070305800437927245\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007030363082885742\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007033449411392212\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006924166083335876\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006948032379150391\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0071073567867279055\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.0070283013582229615\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007005383372306824\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006868672370910644\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.006986875534057618\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006959733963012696\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00696906864643097\n",
      "step 0: loss = 0.0059\n",
      "test_loss: 0.007013468742370605\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.006949043273925782\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.0069788283109664916\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006940820217132568\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.00692651629447937\n",
      "step 0: loss = 0.0057\n",
      "test_loss: 0.007036085724830627\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006940346360206604\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006988899111747742\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00709139347076416\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006974467635154724\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.007041073441505432\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007013541460037231\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006970509886741638\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0069338053464889525\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007027808427810669\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.0069546282291412355\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.00696061909198761\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006992380619049072\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006984122395515442\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007041982412338257\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007016692757606507\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007004945874214173\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007010048627853394\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.007100304365158081\n",
      "step 0: loss = 0.0068\n",
      "test_loss: 0.007051337361335754\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.006927650570869446\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.007003059983253479\n",
      "step 0: loss = 0.0067\n",
      "test_loss: 0.00699398398399353\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.007016071081161499\n",
      "step 0: loss = 0.0064\n",
      "test_loss: 0.0070501530170440675\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.006983634829521179\n",
      "step 0: loss = 0.0062\n",
      "test_loss: 0.007031658887863159\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006982890963554382\n",
      "step 0: loss = 0.0066\n",
      "test_loss: 0.007037753462791443\n",
      "step 0: loss = 0.0065\n",
      "test_loss: 0.006956014037132263\n",
      "step 0: loss = 0.0061\n",
      "test_loss: 0.006907631754875183\n",
      "step 0: loss = 0.0060\n",
      "test_loss: 0.007051413655281067\n",
      "step 0: loss = 0.0063\n",
      "test_loss: 0.006973115205764771\n"
     ]
    }
   ],
   "source": [
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1)\n",
    "#learning_rate = 1\n",
    "n_layers = 3\n",
    "epochs = 6000\n",
    "\n",
    "alpha = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "eta = 1e-8\n",
    "\n",
    "m = [0]*n_layers\n",
    "v = [0]*n_layers\n",
    "t = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(train_set):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "            loss = weighted_MAPE(Omega_Omegabar, omega, mass)  \n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "            #print(grads)\n",
    "\n",
    "        t = t + 1\n",
    "        i = 0\n",
    "        for weight, grad in zip(model.trainable_weights, grads):\n",
    "            \n",
    "            m[i] = beta1 * m[i] + (1 - beta1) * grad\n",
    "            v[i] = beta2 * v[i] + (1 - beta2) * grad**2\n",
    "  \n",
    "            alpha_t = alpha * np.sqrt(1 - beta2**t) / (1 - beta1**t)\n",
    "            theta = alpha_t * m[i] / (tf.sqrt(v[i]) + eta)\n",
    "            #print(theta)\n",
    "            \n",
    "            i = i + 1\n",
    "            \n",
    "            weight.assign_sub(theta)\n",
    "    \n",
    "        if step % 500 == 0:\n",
    "            print(\"step %d: loss = %.4f\" % (step, loss))\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_loss_old = 100\n",
    "    \n",
    "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(test_set):\n",
    "        omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "        test_loss += weighted_MAPE(Omega_Omegabar, omega, mass)\n",
    "   \n",
    "    test_loss = tf.math.real(test_loss).numpy()/(step+1)\n",
    "    print(\"test_loss:\", test_loss)\n",
    "    \n",
    "    # This part doesn't work right now\n",
    "    if test_loss > test_loss_old:\n",
    "        break\n",
    "    test_loss_old = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some debugging tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def volume_form(x, Omega_Omegabar, mass, restriction):\n",
    "\n",
    "    kahler_metric = complex_hessian(tf.math.real(model(x)), x)\n",
    "    volume_form = tf.linalg.det(tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True)))\n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
    "    #factor = tf.constant(4.380538, dtype=tf.complex64)\n",
    "    return  volume_form/factor\n",
    "    #return factor\n",
    "for step, (points, Omega_Omegabar, mass, restriction) in enumerate(dataset):\n",
    "    omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
    "    \n",
    "    weights = mass / tf.reduce_sum(mass)\n",
    "    print('omega', omega)\n",
    "    print('OO',Omega_Omegabar)\n",
    "    print(tf.cast(tf.abs(Omega_Omegabar -  omega), dtype=tf.complex64) / Omega_Omegabar)\n",
    "   # print(mass/tf.reduce_sum(mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 15) dtype=complex64, numpy=\n",
      "array([[ 2.2768168e+00+1.6352530e+00j,  5.8658237e+00-4.2718673e-01j,\n",
      "         5.3873414e-01-1.7244281e-01j, -3.9534414e-01+7.2521999e-02j,\n",
      "        -1.8923687e-02+1.1802919e-02j, -3.8347977e-01-2.2627316e-01j,\n",
      "        -7.6662725e-01+8.0790210e-01j,  2.6793966e-01+6.7697294e-02j,\n",
      "        -4.4106621e-01-1.5242220e-01j, -1.6198709e+00-5.7326740e-01j,\n",
      "         2.8095651e+00+8.1460869e-01j, -1.1343197e+00-2.5883400e+00j,\n",
      "        -4.6649609e+00+1.1073344e+00j,  1.7060937e-01-2.2714563e-02j,\n",
      "         8.5827917e-01-7.9530555e-01j],\n",
      "       [ 1.9180773e+00+4.4432992e-01j, -1.7982172e+00+1.0105304e+00j,\n",
      "        -6.0589733e+00-8.5629034e-01j,  2.9838247e+00-3.7910095e-01j,\n",
      "         2.8432586e+00+9.5829725e-01j, -4.8352519e-01-4.6606249e-01j,\n",
      "        -1.7036586e+00-9.6777737e-01j, -3.2158126e-03+1.6477600e-03j,\n",
      "         1.7850419e+00+6.1775154e-01j,  4.3784446e-01-8.8729739e-02j,\n",
      "         2.8238079e-01+1.9228293e-01j, -2.9208440e-01+1.6115788e-01j,\n",
      "        -2.7304552e+00+1.0982864e+00j, -1.3929390e+00+3.4327587e-01j,\n",
      "        -3.5853200e+00-1.3666987e-01j],\n",
      "       [-1.4581397e+00+1.9110115e+00j, -1.7909920e-01+3.6252013e-01j,\n",
      "        -1.1931094e+00+3.0919951e-01j,  7.2101420e-01-1.2520562e+00j,\n",
      "        -5.5755311e-01-2.0128660e-02j,  3.1300583e+00-2.7365923e-01j,\n",
      "         4.9949604e-01-5.2422490e+00j, -1.7338538e-01+2.4592508e-02j,\n",
      "         1.9228923e+00-6.3471007e-01j,  3.0070311e-01+5.4850805e-01j,\n",
      "         1.8207195e+00-1.2229290e+00j, -4.6268797e+00-1.4987248e+00j,\n",
      "         1.1876729e+00+3.0295810e-01j, -7.5662631e-01+1.2398404e-01j,\n",
      "         3.7306695e+00+1.6974617e+00j],\n",
      "       [ 1.5903249e-01-2.4123290e-01j,  4.2902447e-02+8.1711315e-02j,\n",
      "        -3.3539832e-01+3.9116329e-01j, -2.4176884e+00+1.5029418e-02j,\n",
      "        -4.5817409e+00+8.9052248e-01j, -4.5735011e+00+3.7343332e-01j,\n",
      "         2.3762546e-02-4.5621830e-01j, -1.9385403e-01+8.9566067e-02j,\n",
      "         4.0899768e+00-1.5305756e-02j, -2.5236410e-01+9.8926350e-02j,\n",
      "        -2.1313027e-01-2.0266116e-02j,  2.7595261e-02+4.9135927e-03j,\n",
      "         4.4409629e-02+1.6594049e-01j, -5.0119634e+00+7.1290761e-02j,\n",
      "        -3.5859435e-03+2.7132857e-01j],\n",
      "       [ 2.8225083e+00-1.9472898e+00j, -1.9300312e-01+1.2453795e-01j,\n",
      "        -7.0934814e-01-1.3123615e-01j, -3.2763820e+00+1.2321837e+00j,\n",
      "         1.0924923e+00-7.1551239e-01j,  6.0893261e-01+3.7527627e-01j,\n",
      "         1.0850860e+00-8.6598074e-01j,  4.2221852e-02+8.6574353e-02j,\n",
      "        -2.4428689e+00-5.7877851e-01j,  5.8101020e+00-3.2419884e-01j,\n",
      "         4.1471138e+00+9.2794955e-02j,  1.2292573e+00+7.8488910e-01j,\n",
      "        -1.2955481e-01-9.0879291e-01j, -2.4329317e+00-7.5963151e-01j,\n",
      "         8.8978034e-01+5.8874261e-01j]], dtype=complex64)>\n",
      "<tf.Variable 'Variable:0' shape=(15, 15) dtype=complex64, numpy=\n",
      "array([[ 4.48537874e+00-5.30717336e-02j,  3.97880413e-02-8.86093974e-02j,\n",
      "        -5.31146526e-02+2.45492142e-02j,  8.67075175e-02-1.01624019e-01j,\n",
      "        -1.85670733e-01-6.91963136e-02j, -1.48487300e-01-6.05651662e-02j,\n",
      "         1.20190650e-01-1.69870649e-02j, -5.21362424e-02+1.12177646e-02j,\n",
      "        -9.27942619e-03-8.68658349e-02j,  1.54285967e-01-1.91998314e-02j,\n",
      "         5.47923846e-03+3.80867757e-02j,  3.08177918e-01+2.94221759e-01j,\n",
      "        -1.75426140e-01+1.19707145e-01j, -1.02277972e-01-1.52171299e-01j,\n",
      "        -1.69872731e-01-1.57393202e-01j],\n",
      "       [-5.20558469e-02+1.35510653e-01j,  4.76845026e+00-1.03557847e-01j,\n",
      "        -3.10402393e-01-2.63872325e-01j, -3.83945145e-02-8.85578468e-02j,\n",
      "        -6.10975474e-02-5.13151139e-02j,  3.30757163e-02-6.16653822e-02j,\n",
      "        -6.88735908e-03+3.06749791e-01j,  5.53110726e-02+3.24442722e-02j,\n",
      "         5.61661236e-02-9.50987190e-02j,  3.09128780e-02-1.52821139e-01j,\n",
      "        -5.20106591e-02-6.28411546e-02j,  7.88327605e-02+3.26288608e-03j,\n",
      "         2.27459460e-01+5.63018508e-02j,  8.88381824e-02-2.21358798e-02j,\n",
      "        -2.27249622e-01-5.98294660e-02j],\n",
      "       [-8.53944421e-02-1.59421653e-01j, -4.13616151e-01+3.89929742e-01j,\n",
      "         4.94551754e+00+4.43636924e-02j,  1.50215358e-01+4.44892310e-02j,\n",
      "        -1.41069680e-01+1.37919381e-01j,  4.76978607e-02+3.27756219e-02j,\n",
      "         3.87099892e-01-3.87359917e-01j,  2.56092846e-03+2.12033968e-02j,\n",
      "        -3.92926149e-02-7.29754344e-02j, -1.58888400e-01+7.86960423e-02j,\n",
      "        -1.02544896e-01+3.43110152e-02j, -1.23513997e-01+1.75399467e-01j,\n",
      "         8.80063027e-02+7.74727017e-02j, -4.35849488e-01-7.28005618e-02j,\n",
      "         2.04764962e-01+3.01671684e-01j],\n",
      "       [ 1.15745574e-01+1.57252774e-01j, -1.34361401e-01+5.97085431e-03j,\n",
      "        -1.57307282e-01-2.38582008e-02j,  4.51907349e+00+9.55896154e-02j,\n",
      "        -2.30961278e-01-1.77684844e-01j, -4.40963022e-02+1.08772136e-01j,\n",
      "         1.72351792e-01-3.85349840e-01j,  1.27901202e-02-2.35390174e-03j,\n",
      "         4.82990772e-01-4.60580401e-02j, -7.62113333e-02+4.24391218e-02j,\n",
      "         4.44995686e-02+1.28467217e-01j,  4.94761541e-02-1.91863418e-01j,\n",
      "        -6.11173883e-02+1.82351992e-01j, -1.56536192e-01-3.34206402e-01j,\n",
      "        -2.64782637e-01+9.08263773e-02j],\n",
      "       [-3.49517226e-01+4.60335091e-02j,  1.31304011e-01+1.01816170e-02j,\n",
      "        -3.40697199e-01-1.68635607e-01j, -5.71821369e-02+1.61503091e-01j,\n",
      "         4.63839626e+00+1.15938382e-02j,  6.46486878e-02-9.14678499e-02j,\n",
      "        -3.66927534e-02+1.30854309e-01j,  3.99125144e-02-9.48923826e-03j,\n",
      "         1.12672292e-01-1.14765264e-01j, -1.40039295e-01-4.60513979e-02j,\n",
      "         1.43637145e-02-1.35932982e-01j, -1.13129027e-01-5.67088183e-03j,\n",
      "        -5.44985309e-02-1.37464151e-01j,  2.69388884e-01-2.30145697e-02j,\n",
      "        -5.95672801e-02+1.25840053e-01j],\n",
      "       [-4.16479334e-02+4.21791933e-02j,  2.05890760e-02+2.97590904e-02j,\n",
      "         1.83426924e-02+1.32056922e-01j, -1.38517901e-01+1.10309437e-01j,\n",
      "         6.92991614e-02+5.72190918e-02j,  4.63341808e+00-9.73349288e-02j,\n",
      "         2.43234590e-01+1.41646847e-01j,  7.56485062e-03-4.06649448e-02j,\n",
      "         2.42830552e-02-5.73686250e-02j, -8.83598477e-02-5.31893317e-03j,\n",
      "        -1.07734889e-01+3.14638652e-02j, -1.21181324e-01-1.96566097e-02j,\n",
      "        -4.81016561e-02+2.78094318e-04j,  1.52766019e-01+1.74600426e-02j,\n",
      "        -3.01439971e-01-3.85408252e-02j],\n",
      "       [ 3.00037742e-01-6.98629916e-02j, -4.49373275e-02-1.61733106e-01j,\n",
      "         2.56243914e-01+6.09023511e-01j,  1.36562020e-01+2.60854691e-01j,\n",
      "        -2.74651754e-03-1.08257674e-01j,  1.03100389e-01-2.59782612e-01j,\n",
      "         4.71440935e+00+3.64487455e-03j,  3.80301401e-02-3.25144790e-02j,\n",
      "         9.35852975e-02+5.02375886e-02j,  2.00922623e-01-1.79778919e-01j,\n",
      "        -1.75713956e-01-1.36633992e-01j, -2.38222659e-01-1.92321986e-01j,\n",
      "        -1.23847418e-01-2.11267114e-01j,  3.34210247e-01-1.15863480e-01j,\n",
      "         2.37649888e-01-4.49349672e-01j],\n",
      "       [-1.66156478e-02-7.40435254e-03j,  4.84454557e-02-4.18997854e-02j,\n",
      "        -2.20417902e-02-1.80865303e-02j,  2.84999199e-02+1.54592039e-03j,\n",
      "         1.95790012e-03+9.60797537e-03j, -1.78892480e-03+2.34980136e-02j,\n",
      "         5.60312420e-02+6.79078884e-03j,  1.02035797e+00-1.41587004e-03j,\n",
      "         5.71653470e-02+1.35919440e-03j, -4.11586696e-03+1.70466807e-02j,\n",
      "        -1.22735696e-02+5.34778112e-04j,  2.58589257e-03-8.94873589e-03j,\n",
      "         3.30339633e-02-1.97864827e-02j, -9.78538394e-03+3.22149433e-02j,\n",
      "        -3.68325524e-02+5.54051772e-02j],\n",
      "       [-2.33105617e-04+1.45302713e-01j, -1.40367433e-01-7.84626901e-02j,\n",
      "        -2.98394740e-01+2.03740776e-01j,  4.79328364e-01+1.82237089e-01j,\n",
      "         8.17002635e-03+2.04623297e-01j,  3.38333040e-01+8.51498097e-02j,\n",
      "         1.94009811e-01-3.49350661e-01j,  1.14320517e-01-2.17770189e-02j,\n",
      "         4.51932383e+00+1.78256646e-01j,  1.14981748e-01+1.48429707e-01j,\n",
      "         5.64091764e-02-1.75696075e-01j, -3.98885965e-01-1.18323140e-01j,\n",
      "         3.33802626e-02-4.43213582e-02j,  6.17789589e-02+1.38245270e-01j,\n",
      "         2.13064000e-01+1.79522529e-01j],\n",
      "       [-7.09886604e-04-1.26861371e-02j, -2.62292355e-01+2.72542089e-01j,\n",
      "        -5.57135046e-02+1.39568806e-01j, -4.03439905e-03+4.15739752e-02j,\n",
      "        -2.80338436e-01+3.21313441e-02j, -1.63199157e-01-8.84823427e-02j,\n",
      "         2.22131297e-01+8.47790092e-02j, -4.71316651e-02-2.76802052e-02j,\n",
      "        -2.04155609e-01-9.45463106e-02j,  4.82785606e+00-9.14236009e-02j,\n",
      "        -6.13764375e-02-3.94683145e-02j,  3.66575152e-01-3.63307834e-01j,\n",
      "         1.35576446e-02+3.57938886e-01j, -2.09227741e-01-5.84533885e-02j,\n",
      "         9.33421105e-02-2.38120303e-01j],\n",
      "       [-4.62606281e-01-2.92114038e-02j, -1.05735824e-01-3.64217255e-03j,\n",
      "        -2.66819566e-01-5.29242568e-02j,  8.31092298e-02+5.24944253e-03j,\n",
      "        -1.63037237e-02+1.26137689e-01j,  5.59939817e-03-1.25258237e-01j,\n",
      "         1.06825724e-01+2.39404127e-01j, -1.50322216e-02-3.76014039e-03j,\n",
      "         7.54148513e-02+2.03093141e-02j,  2.86383659e-01-2.77430087e-01j,\n",
      "         4.48912239e+00-4.42797877e-03j,  4.68228877e-01+1.18662231e-02j,\n",
      "        -1.73990220e-01+1.60518482e-01j, -2.17481717e-01-1.80866912e-01j,\n",
      "        -9.43631157e-02-3.28368872e-01j],\n",
      "       [ 1.39473125e-01-3.72130185e-01j,  5.04988022e-02-1.66483656e-01j,\n",
      "        -4.57128733e-02-1.31300867e-01j,  2.80909566e-03+1.68979898e-01j,\n",
      "         8.12469050e-02+2.91961357e-02j, -4.57474701e-02-3.06981169e-02j,\n",
      "         3.91981453e-02-1.05741225e-01j,  2.10939124e-02-2.54678586e-03j,\n",
      "         6.12901598e-02+2.84539282e-01j,  1.91698879e-01+2.75423944e-01j,\n",
      "        -5.37234508e-02+4.94065508e-02j,  4.68861437e+00-6.97277561e-02j,\n",
      "         1.88950926e-01-3.14086676e-01j, -2.56929696e-02-9.12510138e-03j,\n",
      "        -7.24915490e-02+2.37303257e-01j],\n",
      "       [-5.19249380e-01-8.25218931e-02j,  4.53692585e-01-6.55159131e-02j,\n",
      "         1.70892984e-01-2.90004879e-01j,  1.45027399e-01-1.58730075e-01j,\n",
      "        -1.79294348e-01+1.14760011e-01j, -3.70380431e-02-7.66561106e-02j,\n",
      "        -1.95335552e-01+1.75296322e-01j,  9.01950300e-02+2.10906975e-02j,\n",
      "         9.28890929e-02+1.45167699e-02j,  3.77069503e-01-2.98564043e-02j,\n",
      "         7.31683522e-02+8.59315693e-02j,  1.53700531e-01+3.36694151e-01j,\n",
      "         4.57327032e+00+1.19299643e-01j, -1.22024298e-01+1.21267781e-01j,\n",
      "         8.43100473e-02-1.91762120e-01j],\n",
      "       [-5.13286963e-02+1.19752854e-01j, -4.29707654e-02-1.45511866e-01j,\n",
      "        -4.25873190e-01+3.33982483e-02j, -5.83635420e-02+2.12984264e-01j,\n",
      "         3.29427958e-01-1.09983608e-01j,  7.29476437e-02-1.16220005e-02j,\n",
      "         3.54535788e-01+2.12048709e-01j, -2.34260764e-02-6.92817569e-02j,\n",
      "         1.44652680e-01-1.01296343e-01j, -1.73711032e-01+5.02539426e-02j,\n",
      "        -2.53031403e-02-4.64386865e-02j,  6.10113889e-02+8.44140574e-02j,\n",
      "        -7.20824208e-03-5.15585840e-02j,  4.63824749e+00-2.41747703e-02j,\n",
      "         1.78209066e-01-2.16658525e-02j],\n",
      "       [-9.55702737e-02+2.83877194e-01j, -2.95165628e-01-2.67776310e-01j,\n",
      "         3.08804125e-01-5.71958303e-01j, -2.65512139e-01-2.44255111e-01j,\n",
      "        -2.29474574e-01+4.49274331e-02j, -2.87705183e-01-1.03206253e-02j,\n",
      "         1.73533857e-01+5.55275679e-01j, -7.68620819e-02-1.07333794e-01j,\n",
      "         2.17798963e-01-2.64715731e-01j,  1.73822373e-01+1.34617284e-01j,\n",
      "        -1.17425717e-01+1.60592675e-01j,  1.03107719e-02-3.18308085e-01j,\n",
      "         2.97945172e-01+3.53375167e-01j,  6.63591251e-02+9.30496529e-02j,\n",
      "         4.46437311e+00+1.52958790e-02j]], dtype=complex64)>\n"
     ]
    }
   ],
   "source": [
    "for weight in model.trainable_weights:\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KahlerPotential(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KahlerPotential, self).__init__()\n",
    "        self.biholomorphic = Biholomorphic()\n",
    "        self.layer1 = tf.keras.layers.Dense(100, activation=tf.square, use_bias=False)\n",
    "\n",
    "\n",
    "        #self.layer_4 = ComplexDense(50, 10, activation=tf.square)\n",
    "        #self.layer_3 = ComplexDense(10, 15, activation=tf.square)\n",
    "        #self.g = ComplexG(70)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.biholomorphic(inputs)\n",
    "        x = self.layer1(x)\n",
    "        #x = self.layer_2(x)\n",
    "\n",
    "        #x = self.layer_4(x)\n",
    "        #x = self.g(x)\n",
    "        #x = tf.linalg.diag_part(tf.matmul(x, x, adjoint_b=True))\n",
    "        #x = tf.math.log(x)\n",
    "        x = tf.reduce_sum(x, 1)\n",
    "        x = tf.math.log(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KahlerPotential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n",
      "tf.Tensor([1000], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for step, (points, Omega_Omegabar, mass, restriction) in enumerate(train_set):\n",
    "    print(tf.shape(model(points)))\n",
    "    if step == 0:\n",
    "        a = model(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.transpose(a)\n",
    "a = tf.reduce_sum(tf.abs(a), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 1), dtype=float32, numpy=\n",
       "array([[5.38316548e-01],\n",
       "       [8.83447230e-02],\n",
       "       [5.26222169e-01],\n",
       "       [7.88766980e-01],\n",
       "       [1.48804903e-01],\n",
       "       [7.92228580e-01],\n",
       "       [2.03350872e-01],\n",
       "       [6.20962977e-01],\n",
       "       [1.69604346e-01],\n",
       "       [8.83976184e-03],\n",
       "       [6.39118850e-02],\n",
       "       [1.27156880e-02],\n",
       "       [6.97958589e-01],\n",
       "       [3.64552498e-01],\n",
       "       [2.37538330e-02],\n",
       "       [1.51279286e-01],\n",
       "       [1.08250463e+00],\n",
       "       [3.38911235e-01],\n",
       "       [2.04938009e-01],\n",
       "       [4.25134525e-02],\n",
       "       [8.43953907e-01],\n",
       "       [1.02830306e-03],\n",
       "       [7.30025589e-01],\n",
       "       [4.43385094e-01],\n",
       "       [3.14193010e-01],\n",
       "       [1.46317527e-01],\n",
       "       [1.05443120e+00],\n",
       "       [9.39430669e-02],\n",
       "       [2.25267470e-01],\n",
       "       [1.41357586e-01],\n",
       "       [2.44012162e-01],\n",
       "       [3.09310365e-03],\n",
       "       [3.00194952e-03],\n",
       "       [1.89879518e-02],\n",
       "       [1.02200031e-01],\n",
       "       [3.23994249e-01],\n",
       "       [1.09909177e-01],\n",
       "       [2.04617605e-01],\n",
       "       [3.81948858e-01],\n",
       "       [3.12934995e-01],\n",
       "       [2.31474987e-03],\n",
       "       [5.75395346e-01],\n",
       "       [1.63811922e-01],\n",
       "       [5.14457047e-01],\n",
       "       [3.06347877e-01],\n",
       "       [2.60526359e-01],\n",
       "       [1.64557934e-01],\n",
       "       [7.60450363e-02],\n",
       "       [1.91943109e-01],\n",
       "       [1.36420667e-01],\n",
       "       [9.98000242e-03],\n",
       "       [1.63263816e-03],\n",
       "       [3.54856253e-01],\n",
       "       [8.50094855e-01],\n",
       "       [1.94461562e-03],\n",
       "       [6.37127519e-01],\n",
       "       [2.61987001e-01],\n",
       "       [1.48277972e-02],\n",
       "       [1.65264115e-01],\n",
       "       [7.46664226e-01],\n",
       "       [4.23906557e-02],\n",
       "       [1.42650783e-01],\n",
       "       [7.80697167e-02],\n",
       "       [1.17721260e-01],\n",
       "       [4.66266870e-01],\n",
       "       [6.77842617e-01],\n",
       "       [2.51748085e-01],\n",
       "       [1.69550151e-01],\n",
       "       [2.79203534e-01],\n",
       "       [9.16797260e-04],\n",
       "       [1.85993174e-03],\n",
       "       [1.92945879e-02],\n",
       "       [9.95079614e-03],\n",
       "       [1.39296672e-03],\n",
       "       [6.15130663e-01],\n",
       "       [9.90013927e-02],\n",
       "       [7.13307500e-01],\n",
       "       [1.88159430e-03],\n",
       "       [8.44977498e-01],\n",
       "       [2.20774710e-01],\n",
       "       [1.35443024e-02],\n",
       "       [2.95090795e-01],\n",
       "       [4.38467532e-01],\n",
       "       [3.31128538e-02],\n",
       "       [4.20521975e-01],\n",
       "       [3.03465962e-01],\n",
       "       [7.16736838e-02],\n",
       "       [1.29723933e-03],\n",
       "       [9.35717428e-04],\n",
       "       [1.13315932e-01],\n",
       "       [2.85578817e-01],\n",
       "       [4.45782930e-01],\n",
       "       [1.53944895e-01],\n",
       "       [4.71644461e-01],\n",
       "       [3.62036079e-01],\n",
       "       [5.69755912e-01],\n",
       "       [6.46473169e-02],\n",
       "       [8.05950761e-02],\n",
       "       [6.45202279e-01],\n",
       "       [4.70536709e-01],\n",
       "       [1.92221582e-01],\n",
       "       [8.36479887e-02],\n",
       "       [6.95436029e-03],\n",
       "       [3.28904353e-02],\n",
       "       [5.68692744e-01],\n",
       "       [1.48130342e-01],\n",
       "       [1.08953141e-01],\n",
       "       [1.44075500e-02],\n",
       "       [8.38327482e-02],\n",
       "       [8.88222516e-01],\n",
       "       [5.28036356e-01],\n",
       "       [4.34200227e-01],\n",
       "       [8.68946780e-03],\n",
       "       [1.27950907e-01],\n",
       "       [3.36464077e-01],\n",
       "       [1.73032358e-01],\n",
       "       [3.56737375e-01],\n",
       "       [1.72211736e-01],\n",
       "       [1.57704040e-01],\n",
       "       [1.26581490e+00],\n",
       "       [1.53976245e-04],\n",
       "       [5.39542317e-01],\n",
       "       [7.03575909e-02],\n",
       "       [5.55310340e-04],\n",
       "       [6.56210661e-01],\n",
       "       [3.05293966e-02],\n",
       "       [9.29241419e-01],\n",
       "       [1.92418545e-02],\n",
       "       [1.56349331e-01],\n",
       "       [1.03628233e-01],\n",
       "       [6.48442447e-01],\n",
       "       [1.70793869e-02],\n",
       "       [4.07280885e-02],\n",
       "       [2.24944148e-02],\n",
       "       [9.92213339e-02],\n",
       "       [3.56963962e-01],\n",
       "       [1.56911582e-01],\n",
       "       [2.30691418e-01],\n",
       "       [1.90554503e-02],\n",
       "       [1.00399246e-02],\n",
       "       [3.51919644e-02],\n",
       "       [7.89669275e-01],\n",
       "       [2.29221389e-01],\n",
       "       [5.15340194e-02],\n",
       "       [3.39347541e-01],\n",
       "       [2.60344923e-01],\n",
       "       [2.33422011e-01],\n",
       "       [3.99111509e-01],\n",
       "       [7.65324116e-01],\n",
       "       [4.51232463e-01],\n",
       "       [2.56473757e-03],\n",
       "       [3.32698040e-02],\n",
       "       [4.52563286e-01],\n",
       "       [4.55038026e-02],\n",
       "       [1.17141157e-01],\n",
       "       [3.94438237e-01],\n",
       "       [3.54521006e-01],\n",
       "       [5.63650839e-02],\n",
       "       [1.09202757e-01],\n",
       "       [5.82595408e-01],\n",
       "       [6.95868790e-01],\n",
       "       [8.82846210e-03],\n",
       "       [9.48682427e-03],\n",
       "       [2.22325698e-01],\n",
       "       [4.47169155e-01],\n",
       "       [1.67121775e-02],\n",
       "       [1.16719550e-03],\n",
       "       [2.04482004e-01],\n",
       "       [2.59002179e-01],\n",
       "       [1.27158195e-01],\n",
       "       [3.14534754e-02],\n",
       "       [6.23633564e-02],\n",
       "       [8.48551631e-01],\n",
       "       [9.52156067e-01],\n",
       "       [2.84346014e-01],\n",
       "       [2.79039741e-01],\n",
       "       [6.05081115e-03],\n",
       "       [9.60928351e-02],\n",
       "       [1.03521593e-01],\n",
       "       [1.42014204e-02],\n",
       "       [1.19064853e-01],\n",
       "       [1.43906641e+00],\n",
       "       [3.15529913e-01],\n",
       "       [5.53799095e-03],\n",
       "       [1.31218389e-01],\n",
       "       [4.28039044e-01],\n",
       "       [7.22895712e-02],\n",
       "       [9.48312819e-01],\n",
       "       [2.33588740e-01],\n",
       "       [5.46412468e-01],\n",
       "       [2.51006391e-02],\n",
       "       [3.75342555e-02],\n",
       "       [3.51657234e-02],\n",
       "       [1.17196977e-01],\n",
       "       [4.05958235e-05],\n",
       "       [2.54324913e-01],\n",
       "       [7.27449276e-07],\n",
       "       [2.64452487e-01],\n",
       "       [3.29142762e-03],\n",
       "       [1.52389817e-02],\n",
       "       [1.39548600e-01],\n",
       "       [2.00994030e-01],\n",
       "       [2.00035349e-01],\n",
       "       [2.18043779e-03],\n",
       "       [1.72011241e-01],\n",
       "       [4.28827524e-01],\n",
       "       [6.61934316e-01],\n",
       "       [6.03422076e-02],\n",
       "       [1.54333739e-02],\n",
       "       [4.46195714e-03],\n",
       "       [5.08151436e-03],\n",
       "       [7.00214226e-03],\n",
       "       [1.17333460e+00],\n",
       "       [4.11816202e-02],\n",
       "       [1.02341540e-01],\n",
       "       [6.02514267e-01],\n",
       "       [1.09615791e+00],\n",
       "       [2.68378761e-02],\n",
       "       [1.71220198e-01],\n",
       "       [6.06812828e-04],\n",
       "       [4.63831693e-01],\n",
       "       [2.93283105e-01],\n",
       "       [1.67444758e-02],\n",
       "       [2.45635342e-02],\n",
       "       [2.60648951e-02],\n",
       "       [1.19036496e-01],\n",
       "       [1.56392865e-02],\n",
       "       [9.88346279e-01],\n",
       "       [2.40522204e-04],\n",
       "       [4.81750518e-01],\n",
       "       [8.14683497e-01],\n",
       "       [1.64531693e-02],\n",
       "       [1.63343281e-03],\n",
       "       [1.82454009e-02],\n",
       "       [7.03876019e-02],\n",
       "       [6.27285063e-01],\n",
       "       [8.08972597e-01],\n",
       "       [2.73266971e-01],\n",
       "       [5.19832253e-01],\n",
       "       [3.29519123e-01],\n",
       "       [1.64886168e-03],\n",
       "       [4.03486155e-02],\n",
       "       [5.02435684e-01],\n",
       "       [9.34588723e-03],\n",
       "       [6.45909429e-01],\n",
       "       [4.02661115e-02],\n",
       "       [6.76799193e-02],\n",
       "       [2.85665765e-02],\n",
       "       [9.31720018e-01],\n",
       "       [3.91413659e-01],\n",
       "       [1.16916699e-02],\n",
       "       [2.07200098e+00],\n",
       "       [4.20721108e-03],\n",
       "       [2.52688259e-01],\n",
       "       [3.72704685e-01],\n",
       "       [3.30335706e-01],\n",
       "       [1.83822483e-01],\n",
       "       [1.90203205e-01],\n",
       "       [5.30166812e-02],\n",
       "       [1.57781139e-01],\n",
       "       [3.25568326e-05],\n",
       "       [2.50494685e-02],\n",
       "       [4.09729540e-01],\n",
       "       [4.65393692e-01],\n",
       "       [1.94930777e-04],\n",
       "       [2.34111741e-01],\n",
       "       [3.37261349e-01],\n",
       "       [2.29978040e-01],\n",
       "       [4.13689623e-03],\n",
       "       [2.46065035e-01],\n",
       "       [2.38536060e-01],\n",
       "       [7.34878033e-02],\n",
       "       [5.38288891e-01],\n",
       "       [2.26413101e-01],\n",
       "       [3.54636088e-02],\n",
       "       [1.09380059e-01],\n",
       "       [3.85458827e-01],\n",
       "       [1.77092769e-03],\n",
       "       [1.52380884e-01],\n",
       "       [9.97242797e-03],\n",
       "       [2.43078008e-01],\n",
       "       [9.07537937e-02],\n",
       "       [7.46111691e-01],\n",
       "       [5.22413105e-02],\n",
       "       [2.73389488e-01],\n",
       "       [5.67844987e-01],\n",
       "       [1.45755693e-01],\n",
       "       [1.85823767e-04],\n",
       "       [1.80102419e-02],\n",
       "       [1.78303018e-01],\n",
       "       [1.51840821e-01],\n",
       "       [3.15028965e-01],\n",
       "       [4.16790158e-01],\n",
       "       [5.19168191e-03],\n",
       "       [8.67344160e-03],\n",
       "       [6.19850278e-01],\n",
       "       [2.08430476e-02],\n",
       "       [2.78555185e-01],\n",
       "       [4.60650653e-01],\n",
       "       [4.91950884e-02],\n",
       "       [4.67636324e-02],\n",
       "       [1.79470354e-03],\n",
       "       [6.47949928e-04],\n",
       "       [1.04132265e-01],\n",
       "       [7.04782596e-03],\n",
       "       [2.53995862e-02],\n",
       "       [1.17021427e-03],\n",
       "       [2.33588908e-02],\n",
       "       [5.38303368e-02],\n",
       "       [3.30584258e-01],\n",
       "       [1.02365553e-01],\n",
       "       [5.46018481e-02],\n",
       "       [2.92853955e-02],\n",
       "       [5.30685065e-04],\n",
       "       [7.60933936e-01],\n",
       "       [1.32080251e-02],\n",
       "       [7.47783948e-03],\n",
       "       [8.23770389e-02],\n",
       "       [6.16513984e-03],\n",
       "       [1.01143859e-01],\n",
       "       [1.09760845e+00],\n",
       "       [2.33348370e-01],\n",
       "       [7.41681695e-01],\n",
       "       [1.83683791e-04],\n",
       "       [6.80987120e-01],\n",
       "       [4.84636039e-01],\n",
       "       [2.44807899e-01],\n",
       "       [3.15707445e-01],\n",
       "       [4.09092486e-01],\n",
       "       [4.55837883e-02],\n",
       "       [2.75340267e-02],\n",
       "       [3.60772341e-01],\n",
       "       [3.64718884e-02],\n",
       "       [3.89123380e-01],\n",
       "       [3.22986692e-02],\n",
       "       [1.78162098e-01],\n",
       "       [4.06207234e-01],\n",
       "       [6.65523171e-01],\n",
       "       [5.81689775e-01],\n",
       "       [9.70411956e-01],\n",
       "       [9.49949548e-02],\n",
       "       [8.02080095e-01],\n",
       "       [1.77842355e-03],\n",
       "       [3.66441123e-02],\n",
       "       [1.63064241e-01],\n",
       "       [5.28569855e-02],\n",
       "       [9.47349966e-01],\n",
       "       [1.92048633e-03],\n",
       "       [1.27801642e-01],\n",
       "       [6.03561401e-01],\n",
       "       [2.37146005e-01],\n",
       "       [3.46600592e-01],\n",
       "       [4.71113762e-03],\n",
       "       [3.14281911e-01],\n",
       "       [1.17530478e-02],\n",
       "       [1.97218478e-01],\n",
       "       [1.34370431e-01],\n",
       "       [4.47331667e-02],\n",
       "       [3.43940035e-02],\n",
       "       [9.51908007e-02],\n",
       "       [2.37034820e-02],\n",
       "       [3.22076902e-02],\n",
       "       [3.93378437e-02],\n",
       "       [4.65178609e-01],\n",
       "       [2.06030443e-01],\n",
       "       [4.64711078e-02],\n",
       "       [3.54571640e-02],\n",
       "       [5.28677441e-02],\n",
       "       [5.67432605e-02],\n",
       "       [3.66510712e-02],\n",
       "       [3.10160443e-02],\n",
       "       [1.38538867e-01],\n",
       "       [2.45145895e-02],\n",
       "       [1.10175967e-01],\n",
       "       [2.08496198e-01],\n",
       "       [2.42313370e-01],\n",
       "       [3.03758204e-01],\n",
       "       [7.24763013e-05],\n",
       "       [6.53872311e-01],\n",
       "       [5.88593706e-02],\n",
       "       [2.29357779e-01],\n",
       "       [2.08012685e-02],\n",
       "       [2.29629297e-02],\n",
       "       [4.75010335e-01],\n",
       "       [1.35667482e-03],\n",
       "       [3.70681256e-01],\n",
       "       [2.27034483e-02],\n",
       "       [1.35201827e-01],\n",
       "       [2.61974424e-01],\n",
       "       [9.90035310e-02],\n",
       "       [3.06151295e-03],\n",
       "       [4.76550460e-01],\n",
       "       [3.00448053e-02],\n",
       "       [2.41601512e-01],\n",
       "       [6.00506701e-02],\n",
       "       [1.24307454e-01],\n",
       "       [2.51870483e-01],\n",
       "       [4.08969820e-02],\n",
       "       [6.18336320e-01],\n",
       "       [3.00134066e-02],\n",
       "       [1.47188986e-02],\n",
       "       [7.07767606e-02],\n",
       "       [1.74302123e-02],\n",
       "       [1.31381959e-01],\n",
       "       [2.61602134e-01],\n",
       "       [2.66570568e-01],\n",
       "       [8.23391199e-01],\n",
       "       [5.79631049e-03],\n",
       "       [9.27901268e-02],\n",
       "       [1.00984024e-02],\n",
       "       [4.61707124e-03],\n",
       "       [1.34176183e-02],\n",
       "       [9.71531495e-02],\n",
       "       [3.02107602e-01],\n",
       "       [2.30426827e-04],\n",
       "       [5.59561513e-03],\n",
       "       [8.47150907e-02],\n",
       "       [2.55709495e-02],\n",
       "       [6.58134937e-01],\n",
       "       [1.38600944e-02],\n",
       "       [3.36853713e-01],\n",
       "       [4.69264358e-01],\n",
       "       [7.91200697e-02],\n",
       "       [6.41524419e-02],\n",
       "       [6.40734062e-02],\n",
       "       [6.97881579e-01],\n",
       "       [1.12247304e-04],\n",
       "       [3.09127301e-01],\n",
       "       [3.19223590e-02],\n",
       "       [5.25455117e-01],\n",
       "       [8.09400063e-03],\n",
       "       [2.04931796e-01],\n",
       "       [4.87177446e-02],\n",
       "       [1.37521073e-01],\n",
       "       [6.72088750e-03],\n",
       "       [2.15303415e-04],\n",
       "       [1.51482979e-02],\n",
       "       [1.33968502e-01],\n",
       "       [3.70825268e-02],\n",
       "       [1.26055807e-01],\n",
       "       [2.10477552e-07],\n",
       "       [3.40045750e-01],\n",
       "       [6.88233852e-01],\n",
       "       [1.40312221e-02],\n",
       "       [2.63290554e-01],\n",
       "       [4.86847132e-01],\n",
       "       [8.79936144e-02],\n",
       "       [1.16689317e-01],\n",
       "       [5.64788410e-04],\n",
       "       [2.61806846e-01],\n",
       "       [3.04510027e-01],\n",
       "       [1.73627399e-02],\n",
       "       [2.20953673e-02],\n",
       "       [2.73417984e-03],\n",
       "       [1.93860941e-03],\n",
       "       [2.02105090e-01],\n",
       "       [1.92534044e-01],\n",
       "       [9.80519056e-02],\n",
       "       [1.89610408e-03],\n",
       "       [1.00027747e-01],\n",
       "       [3.11206002e-02],\n",
       "       [8.87992322e-01],\n",
       "       [8.08310211e-01],\n",
       "       [1.26846075e-01],\n",
       "       [4.22526240e-01],\n",
       "       [1.26063660e-01],\n",
       "       [7.47678101e-01],\n",
       "       [2.39222527e-01],\n",
       "       [4.47865903e-01],\n",
       "       [2.79717833e-01],\n",
       "       [1.08664125e-01],\n",
       "       [6.10042214e-02],\n",
       "       [7.49268457e-02],\n",
       "       [5.43128908e-01],\n",
       "       [7.99771212e-03],\n",
       "       [2.42967019e-03],\n",
       "       [1.70119762e-01],\n",
       "       [2.32962772e-01],\n",
       "       [1.53281435e-01],\n",
       "       [8.36539373e-04],\n",
       "       [1.82417825e-01],\n",
       "       [2.86809385e-01],\n",
       "       [1.72069808e-03],\n",
       "       [2.16916166e-02],\n",
       "       [1.84244290e-02],\n",
       "       [2.76328176e-02],\n",
       "       [6.26131237e-01],\n",
       "       [1.02979958e-01],\n",
       "       [1.61979143e-02],\n",
       "       [8.52978136e-03],\n",
       "       [6.45366609e-01],\n",
       "       [1.21749437e-03],\n",
       "       [2.53369570e-01],\n",
       "       [5.98422885e-01],\n",
       "       [4.89110127e-02],\n",
       "       [3.52276593e-01],\n",
       "       [7.06809983e-02],\n",
       "       [1.39516303e-02],\n",
       "       [1.10592914e-03],\n",
       "       [2.38993429e-02],\n",
       "       [4.98338759e-01],\n",
       "       [4.92765546e-01],\n",
       "       [8.72704685e-02],\n",
       "       [3.82191509e-01],\n",
       "       [4.57549887e-03],\n",
       "       [2.79765669e-02],\n",
       "       [5.37846908e-02],\n",
       "       [7.80272856e-02],\n",
       "       [2.43188486e-01],\n",
       "       [3.12843442e-01],\n",
       "       [7.64452741e-02],\n",
       "       [8.81434008e-02],\n",
       "       [1.35310158e-01],\n",
       "       [1.87050536e-01],\n",
       "       [7.16261208e-01],\n",
       "       [4.11541373e-01],\n",
       "       [1.13778189e-01],\n",
       "       [1.61404371e-01],\n",
       "       [6.40054464e-01],\n",
       "       [3.81164581e-01],\n",
       "       [1.03260636e+00],\n",
       "       [7.90530741e-02],\n",
       "       [2.91316271e-01],\n",
       "       [1.88597932e-01],\n",
       "       [4.23770994e-01],\n",
       "       [2.61641264e-01],\n",
       "       [5.22160865e-02],\n",
       "       [3.32127422e-01],\n",
       "       [1.13031663e-01],\n",
       "       [3.23276281e-01],\n",
       "       [1.96626768e-01],\n",
       "       [6.80640936e-01],\n",
       "       [5.32958051e-03],\n",
       "       [2.13514760e-01],\n",
       "       [9.06713784e-01],\n",
       "       [1.81768537e-02],\n",
       "       [3.40938061e-01],\n",
       "       [3.91416639e-01],\n",
       "       [3.93960886e-02],\n",
       "       [4.59965132e-03],\n",
       "       [1.38368569e-02],\n",
       "       [1.13953929e-02],\n",
       "       [2.26509675e-01],\n",
       "       [1.25006723e+00],\n",
       "       [4.24522370e-01],\n",
       "       [4.53733932e-03],\n",
       "       [9.80541587e-01],\n",
       "       [1.40317269e-02],\n",
       "       [7.88967490e-01],\n",
       "       [3.19452472e-02],\n",
       "       [4.17464823e-01],\n",
       "       [1.11156772e-03],\n",
       "       [4.93519306e-01],\n",
       "       [3.09280097e-01],\n",
       "       [2.45416120e-01],\n",
       "       [1.59518532e-02],\n",
       "       [7.10616052e-01],\n",
       "       [6.54002179e-06],\n",
       "       [1.97173905e+00],\n",
       "       [1.23523991e-04],\n",
       "       [3.08335036e-01],\n",
       "       [4.65023033e-02],\n",
       "       [4.31186669e-02],\n",
       "       [3.36360157e-01],\n",
       "       [5.56569314e-04],\n",
       "       [3.92838180e-01],\n",
       "       [1.88609168e-01],\n",
       "       [6.97695687e-02],\n",
       "       [1.39680775e-02],\n",
       "       [2.97098637e-01],\n",
       "       [2.75518775e-01],\n",
       "       [5.40530264e-01],\n",
       "       [7.76028857e-02],\n",
       "       [6.84338152e-01],\n",
       "       [2.66068995e-01],\n",
       "       [1.38936611e-02],\n",
       "       [2.09595978e-01],\n",
       "       [2.29431033e-01],\n",
       "       [3.39105994e-01],\n",
       "       [3.13208848e-01],\n",
       "       [2.08086580e-01],\n",
       "       [3.28385970e-03],\n",
       "       [2.24196762e-01],\n",
       "       [2.48688255e-02],\n",
       "       [8.01263750e-01],\n",
       "       [4.44636494e-01],\n",
       "       [1.79036885e-01],\n",
       "       [9.25342292e-02],\n",
       "       [5.67990683e-05],\n",
       "       [4.72929934e-03],\n",
       "       [1.35192517e-02],\n",
       "       [3.45959842e-01],\n",
       "       [5.35689116e-01],\n",
       "       [4.22801636e-02],\n",
       "       [3.43692191e-02],\n",
       "       [2.65965313e-02],\n",
       "       [2.93385357e-01],\n",
       "       [3.86703074e-01],\n",
       "       [6.39982402e-01],\n",
       "       [1.21459298e-01],\n",
       "       [1.27448097e-01],\n",
       "       [1.99881747e-01],\n",
       "       [3.64701082e-05],\n",
       "       [2.03911245e-01],\n",
       "       [3.16219598e-01],\n",
       "       [1.97410793e-03],\n",
       "       [8.32570717e-02],\n",
       "       [1.78867236e-01],\n",
       "       [1.41003400e-01],\n",
       "       [1.35865510e-01],\n",
       "       [2.40405977e-01],\n",
       "       [8.22629556e-02],\n",
       "       [7.74450541e-01],\n",
       "       [8.77489429e-03],\n",
       "       [3.41030322e-02],\n",
       "       [2.70113170e-01],\n",
       "       [3.19811642e-01],\n",
       "       [3.55894506e-01],\n",
       "       [2.26640612e-01],\n",
       "       [6.24881983e-02],\n",
       "       [7.72303939e-01],\n",
       "       [1.71145067e-01],\n",
       "       [3.05227786e-02],\n",
       "       [6.73214570e-02],\n",
       "       [4.35111625e-03],\n",
       "       [1.59497419e-03],\n",
       "       [3.22010249e-01],\n",
       "       [2.86905374e-02],\n",
       "       [8.20121020e-02],\n",
       "       [5.21179065e-02],\n",
       "       [4.26838058e-04],\n",
       "       [1.11697964e-01],\n",
       "       [8.36812630e-02],\n",
       "       [4.54896361e-01],\n",
       "       [1.16114214e-03],\n",
       "       [1.34692676e-02],\n",
       "       [2.15891317e-01],\n",
       "       [1.92797422e+00],\n",
       "       [1.30121425e-01],\n",
       "       [3.26217376e-02],\n",
       "       [2.15352267e-01],\n",
       "       [1.97489008e-01],\n",
       "       [9.27912130e-04],\n",
       "       [9.42039210e-03],\n",
       "       [2.81096995e-02],\n",
       "       [6.39802933e-01],\n",
       "       [2.93693066e-01],\n",
       "       [3.51020485e-01],\n",
       "       [5.15959501e-01],\n",
       "       [3.48784655e-01],\n",
       "       [1.32596448e-01],\n",
       "       [6.56703040e-02],\n",
       "       [1.07775998e+00],\n",
       "       [6.72716737e-01],\n",
       "       [1.39760360e-01],\n",
       "       [2.97918767e-02],\n",
       "       [1.29497737e-01],\n",
       "       [1.18703011e-03],\n",
       "       [2.96899050e-01],\n",
       "       [2.16128170e-01],\n",
       "       [2.13452935e-01],\n",
       "       [1.55361399e-01],\n",
       "       [9.02029127e-02],\n",
       "       [6.61244869e-01],\n",
       "       [2.02878192e-03],\n",
       "       [5.87127134e-02],\n",
       "       [1.01223566e-01],\n",
       "       [1.77009970e-01],\n",
       "       [5.40773235e-02],\n",
       "       [6.16484821e-01],\n",
       "       [4.96223629e-01],\n",
       "       [4.39079385e-03],\n",
       "       [2.10088503e-04],\n",
       "       [1.24796070e-01],\n",
       "       [5.06638549e-02],\n",
       "       [4.39051874e-02],\n",
       "       [1.53211445e-01],\n",
       "       [9.91975889e-02],\n",
       "       [1.61703914e-01],\n",
       "       [5.07481337e-01],\n",
       "       [4.66364287e-02],\n",
       "       [3.83660823e-01],\n",
       "       [1.58909559e-01],\n",
       "       [2.14039400e-01],\n",
       "       [1.19530782e-02],\n",
       "       [3.60090166e-01],\n",
       "       [8.74034036e-03],\n",
       "       [7.06082722e-03],\n",
       "       [2.89306253e-01],\n",
       "       [2.33528912e-01],\n",
       "       [5.78212887e-02],\n",
       "       [1.11468486e-03],\n",
       "       [3.20315687e-03],\n",
       "       [8.32553506e-02],\n",
       "       [2.83081401e-02],\n",
       "       [2.40512028e-01],\n",
       "       [8.39605089e-03],\n",
       "       [5.28857037e-02],\n",
       "       [1.14976764e-01],\n",
       "       [8.86491179e-01],\n",
       "       [2.91338921e-01],\n",
       "       [7.94124722e-01],\n",
       "       [2.68994421e-02],\n",
       "       [1.14394039e-01],\n",
       "       [6.70132577e-01],\n",
       "       [3.60006392e-01],\n",
       "       [2.04459280e-01],\n",
       "       [1.98518913e-02],\n",
       "       [1.15921546e-03],\n",
       "       [4.99539435e-01],\n",
       "       [7.66628757e-02],\n",
       "       [6.55587465e-02],\n",
       "       [7.20793754e-03],\n",
       "       [9.21515077e-02],\n",
       "       [1.24825336e-01],\n",
       "       [3.91340181e-02],\n",
       "       [1.40886186e-04],\n",
       "       [6.00287676e-01],\n",
       "       [5.28286874e-01],\n",
       "       [1.60184756e-01],\n",
       "       [5.23481285e-03],\n",
       "       [9.60120142e-01],\n",
       "       [6.83543146e-01],\n",
       "       [2.96782777e-02],\n",
       "       [2.99562722e-01],\n",
       "       [1.23699312e-03],\n",
       "       [5.79719245e-01],\n",
       "       [1.99378774e-01],\n",
       "       [1.14726432e-01],\n",
       "       [5.25570571e-01],\n",
       "       [4.84290235e-02],\n",
       "       [2.02853844e-01],\n",
       "       [4.95550275e-01],\n",
       "       [2.45975465e-01],\n",
       "       [2.27794256e-02],\n",
       "       [1.04063459e-01],\n",
       "       [3.70122910e-01],\n",
       "       [1.34953726e-02],\n",
       "       [1.73549250e-01],\n",
       "       [4.35200512e-01],\n",
       "       [5.41780777e-02],\n",
       "       [2.66335994e-01],\n",
       "       [3.03165894e-02],\n",
       "       [9.54240710e-02],\n",
       "       [1.59306809e-01],\n",
       "       [1.40176564e-02],\n",
       "       [2.25592345e-01],\n",
       "       [6.82381690e-01],\n",
       "       [3.43031250e-02],\n",
       "       [6.81042612e-01],\n",
       "       [1.58640653e-01],\n",
       "       [3.71757746e-01],\n",
       "       [6.27242565e-01],\n",
       "       [6.26110315e-01],\n",
       "       [4.09593493e-01],\n",
       "       [3.99085075e-01],\n",
       "       [2.19797865e-01],\n",
       "       [4.90323901e-01],\n",
       "       [8.73414278e-02],\n",
       "       [8.40000249e-03],\n",
       "       [2.76386470e-01],\n",
       "       [5.10438740e-01],\n",
       "       [1.26974553e-01],\n",
       "       [7.23785535e-03],\n",
       "       [1.60922371e-02],\n",
       "       [4.90862364e-03],\n",
       "       [3.60613689e-02],\n",
       "       [2.88129687e-01],\n",
       "       [4.66080196e-02],\n",
       "       [1.81183941e-03],\n",
       "       [1.60799041e-01],\n",
       "       [1.30839658e+00],\n",
       "       [4.74000543e-01],\n",
       "       [8.82452168e-03],\n",
       "       [2.33849987e-01],\n",
       "       [1.03492570e+00],\n",
       "       [5.40082216e-01],\n",
       "       [2.49756943e-03],\n",
       "       [4.27674176e-03],\n",
       "       [3.10406566e-01],\n",
       "       [3.09635438e-02],\n",
       "       [1.06208641e-02],\n",
       "       [7.54963681e-02],\n",
       "       [1.05036078e-02],\n",
       "       [4.52802330e-03],\n",
       "       [2.68465370e-01],\n",
       "       [9.49624404e-02],\n",
       "       [2.29332037e-03],\n",
       "       [9.01401117e-02],\n",
       "       [3.55588824e-01],\n",
       "       [1.15177310e+00],\n",
       "       [5.05845936e-04],\n",
       "       [1.96263149e-01],\n",
       "       [2.81295419e-04],\n",
       "       [1.97277084e-01],\n",
       "       [1.53986132e-02],\n",
       "       [2.10171610e-01],\n",
       "       [1.35817379e-01],\n",
       "       [1.48851313e-02],\n",
       "       [1.82016373e-01],\n",
       "       [1.91362761e-02],\n",
       "       [1.24183707e-02],\n",
       "       [2.33200431e-01],\n",
       "       [4.87188458e-01],\n",
       "       [6.36905670e-01],\n",
       "       [4.28015850e-02],\n",
       "       [2.59943038e-01],\n",
       "       [1.74852222e-01],\n",
       "       [1.68817788e-02],\n",
       "       [9.77982506e-02],\n",
       "       [7.42800832e-02],\n",
       "       [9.43521634e-02],\n",
       "       [3.29431221e-02],\n",
       "       [2.24405266e-02],\n",
       "       [3.27982455e-02],\n",
       "       [1.50601771e-02],\n",
       "       [5.20221055e-01],\n",
       "       [1.55579196e-02],\n",
       "       [5.73323965e-01],\n",
       "       [1.61446676e-01],\n",
       "       [5.27066812e-02],\n",
       "       [3.57611477e-01],\n",
       "       [2.05668365e-03],\n",
       "       [7.88230300e-01],\n",
       "       [2.17454657e-02],\n",
       "       [2.26036951e-01],\n",
       "       [8.16272423e-02],\n",
       "       [3.28637153e-01],\n",
       "       [1.22773938e-01],\n",
       "       [2.33848747e-02],\n",
       "       [2.85306927e-02],\n",
       "       [9.56230834e-02],\n",
       "       [2.61936605e-01],\n",
       "       [4.55655903e-01],\n",
       "       [4.00614105e-02],\n",
       "       [7.28384554e-01],\n",
       "       [4.72025961e-01],\n",
       "       [7.37363771e-02],\n",
       "       [1.33781517e-02],\n",
       "       [6.69027045e-02],\n",
       "       [3.13351303e-01],\n",
       "       [1.26130797e-03],\n",
       "       [1.61209136e-01],\n",
       "       [1.95364475e-01],\n",
       "       [1.13005288e-01],\n",
       "       [4.58369642e-01],\n",
       "       [8.29829395e-01],\n",
       "       [2.76379995e-02],\n",
       "       [1.30869970e-01],\n",
       "       [2.04449799e-02],\n",
       "       [1.33770704e-01],\n",
       "       [3.19706625e-03],\n",
       "       [2.34054099e-03],\n",
       "       [1.99268743e-01],\n",
       "       [1.15821669e-02],\n",
       "       [4.34086323e-01],\n",
       "       [7.92759936e-03],\n",
       "       [3.13404500e-02],\n",
       "       [1.89713106e-01],\n",
       "       [4.66981441e-01],\n",
       "       [6.43010497e-01],\n",
       "       [6.97092295e-01],\n",
       "       [4.73371178e-01],\n",
       "       [2.89862789e-02],\n",
       "       [7.98882917e-03],\n",
       "       [3.45598231e-03],\n",
       "       [1.88632205e-01],\n",
       "       [6.24986053e-01],\n",
       "       [9.03080567e-04],\n",
       "       [6.60380125e-01],\n",
       "       [2.62132674e-01],\n",
       "       [1.94143683e-01],\n",
       "       [2.47061864e-01],\n",
       "       [5.26669249e-02],\n",
       "       [1.81125492e-01],\n",
       "       [1.07661635e-01],\n",
       "       [1.51037768e-01],\n",
       "       [7.43000128e-04],\n",
       "       [4.67296969e-03],\n",
       "       [1.44540191e-01],\n",
       "       [2.35791877e-01],\n",
       "       [3.22685093e-02],\n",
       "       [8.78807083e-02],\n",
       "       [3.62149000e-01],\n",
       "       [8.66515402e-05],\n",
       "       [3.00836295e-01],\n",
       "       [5.45089319e-02],\n",
       "       [1.00344583e-01],\n",
       "       [1.12458646e-01],\n",
       "       [4.34159279e-01],\n",
       "       [2.26531108e-03],\n",
       "       [4.62852359e-01],\n",
       "       [2.00798022e-05],\n",
       "       [3.38337136e-09],\n",
       "       [6.90958798e-02],\n",
       "       [1.13837868e-01],\n",
       "       [4.85448569e-01],\n",
       "       [2.50464794e-03],\n",
       "       [6.98840246e-02],\n",
       "       [3.38120908e-02],\n",
       "       [4.70037349e-02],\n",
       "       [2.68559396e-01],\n",
       "       [9.63701189e-01],\n",
       "       [2.50546001e-02],\n",
       "       [5.67579210e-01],\n",
       "       [5.72147608e-01],\n",
       "       [2.39049584e-01],\n",
       "       [1.79945484e-01],\n",
       "       [4.06593353e-01],\n",
       "       [7.13620102e-03],\n",
       "       [2.90248310e-03],\n",
       "       [8.01173225e-03],\n",
       "       [1.83663517e-01],\n",
       "       [4.26568747e-01],\n",
       "       [3.72346073e-01],\n",
       "       [5.94903063e-03],\n",
       "       [2.38026485e-01],\n",
       "       [1.90353796e-01],\n",
       "       [4.10702109e-01],\n",
       "       [2.24842757e-01],\n",
       "       [1.79780591e-02],\n",
       "       [2.67352071e-02],\n",
       "       [8.31649546e-03],\n",
       "       [6.17490895e-03],\n",
       "       [9.36755612e-02],\n",
       "       [1.37284577e-01],\n",
       "       [7.14246094e-01],\n",
       "       [2.45100752e-01],\n",
       "       [4.07111466e-01],\n",
       "       [2.46453732e-01],\n",
       "       [4.83125746e-02],\n",
       "       [6.15878180e-02],\n",
       "       [3.70483220e-01],\n",
       "       [6.78375438e-02],\n",
       "       [5.65522611e-01],\n",
       "       [2.66013861e-01],\n",
       "       [2.11738333e-01],\n",
       "       [8.43878835e-02],\n",
       "       [6.76861703e-01],\n",
       "       [1.01474822e-01],\n",
       "       [8.36499274e-01],\n",
       "       [5.27571067e-02],\n",
       "       [8.31741747e-03],\n",
       "       [5.86643331e-02],\n",
       "       [8.41252331e-04],\n",
       "       [9.41887498e-01],\n",
       "       [6.59376025e-01],\n",
       "       [4.27550018e-01],\n",
       "       [6.01424634e-01],\n",
       "       [5.27301133e-01],\n",
       "       [7.08210394e-02],\n",
       "       [5.65576293e-02],\n",
       "       [2.04801490e-03],\n",
       "       [4.35477942e-01],\n",
       "       [7.98608661e-02],\n",
       "       [8.99246573e-01],\n",
       "       [9.11302984e-01],\n",
       "       [7.16138259e-02],\n",
       "       [7.99256936e-02],\n",
       "       [4.01021719e-01],\n",
       "       [5.79519987e-01],\n",
       "       [2.20515862e-01],\n",
       "       [3.49877030e-01],\n",
       "       [1.52679309e-01],\n",
       "       [6.88731551e-01],\n",
       "       [3.40071589e-01],\n",
       "       [6.24494068e-02],\n",
       "       [9.41022560e-02],\n",
       "       [1.60342038e-01],\n",
       "       [1.17214605e-01],\n",
       "       [4.35002055e-03],\n",
       "       [5.21964430e-05],\n",
       "       [7.39093050e-02],\n",
       "       [2.29126570e-04],\n",
       "       [5.10224316e-04],\n",
       "       [5.07093251e-01],\n",
       "       [8.79569259e-03],\n",
       "       [4.01645809e-01],\n",
       "       [4.71130222e-01],\n",
       "       [5.81615698e-03],\n",
       "       [4.30095196e-01],\n",
       "       [6.43616378e-01],\n",
       "       [8.83334726e-02],\n",
       "       [1.38637424e-01],\n",
       "       [5.74302636e-02],\n",
       "       [4.34037261e-02],\n",
       "       [1.56977868e+00],\n",
       "       [2.12908283e-01],\n",
       "       [8.26826334e-01],\n",
       "       [2.75283128e-01],\n",
       "       [2.63249069e-01],\n",
       "       [1.51485369e-01],\n",
       "       [6.20073639e-03],\n",
       "       [1.11934006e-01],\n",
       "       [3.82001311e-01],\n",
       "       [1.19278720e-02],\n",
       "       [6.68139383e-02],\n",
       "       [2.90147185e-01],\n",
       "       [7.87198916e-02],\n",
       "       [1.01475203e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Change Batchsize & Network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_real = tf.math.real(a)\n",
    "a_imag = tf.math.imag(a)\n",
    "a_new = tf.concat([a_real, a_imag], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask = tf.cast(a, dtype=tf.bool)              \n",
    "no_zeros = tf.ragged.boolean_mask(a, boolean_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1000,   50], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
       "array([ 0.9038784 ,  0.84662837, -0.09585851, -0.663743  , -0.43639532,\n",
       "        0.8466283 ,  0.95462674, -0.0439431 , -0.8095745 , -0.05158594,\n",
       "       -0.09585851, -0.0439431 ,  0.02316958,  0.01710205,  0.14759119,\n",
       "       -0.663743  , -0.8095745 ,  0.01710205,  0.7057893 , -0.09472027,\n",
       "       -0.43639532, -0.05158594,  0.14759119, -0.09472027,  1.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_real[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
